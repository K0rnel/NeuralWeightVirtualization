{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WeightExperiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tYh3vcZu80YH",
        "outputId": "3a3e4349-bcfc-4188-e93d-cef45bb948f3"
      },
      "source": [
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow-gpu==1.13.1\n",
        "\n",
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.16.4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.4.0:\n",
            "  Successfully uninstalled tensorflow-2.4.0\n",
            "Collecting tensorflow-gpu==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K     |████████████████████████████████| 345.2MB 49kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.36.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.32.0)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 51.8MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 60.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.19.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.3.3)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (51.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.3.3)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.4.0)\n",
            "Installing collected packages: tensorboard, mock, tensorflow-estimator, keras-applications, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n",
            "Uninstalling numpy-1.19.4:\n",
            "  Successfully uninstalled numpy-1.19.4\n",
            "Collecting numpy==1.16.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 223kB/s \n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "Successfully installed numpy-1.16.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewwVmNyz89zK",
        "outputId": "e245b809-76cb-4992-8163-75e27627a90c"
      },
      "source": [
        "!git clone https://github.com/K0rnel/NeuralWeightVirtualization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NeuralWeightVirtualization'...\n",
            "remote: Enumerating objects: 201, done.\u001b[K\n",
            "remote: Counting objects: 100% (201/201), done.\u001b[K\n",
            "remote: Compressing objects: 100% (146/146), done.\u001b[K\n",
            "remote: Total 201 (delta 92), reused 147 (delta 50), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (201/201), 11.95 MiB | 27.37 MiB/s, done.\n",
            "Resolving deltas: 100% (92/92), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUYASWlZ8_I1",
        "outputId": "504b31a9-5de9-412c-92dd-d50b95b607f2"
      },
      "source": [
        "%cd NeuralWeightVirtualization"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/NeuralWeightVirtualization\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6inoEeC2-RZ0",
        "outputId": "d1e2a7bc-fdf7-48e3-b0dc-229584671fba"
      },
      "source": [
        "!sh download_dataset.sh"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1/9] Downloading CIFAR10 dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2414      0 --:--:-- --:--:-- --:--:--  2428\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  234M    0  234M    0     0  47.6M      0 --:--:--  0:00:04 --:--:-- 52.4M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    495      0 --:--:-- --:--:-- --:--:--   495\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100  781k  100  781k    0     0   562k      0  0:00:01  0:00:01 --:--:--  562k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2358      0 --:--:-- --:--:-- --:--:--  2358\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1171M    0 1171M    0     0   132M      0 --:--:--  0:00:08 --:--:--  140M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    491      0 --:--:-- --:--:-- --:--:--   490\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 3906k    0 3906k    0     0  2915k      0 --:--:--  0:00:01 --:--:--  373M\n",
            "\n",
            "[2/9] Downloading Google Speech Command V2 dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    226      0 --:--:--  0:00:01 --:--:--   226\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100 66.5M    0 66.5M    0     0  26.7M      0 --:--:--  0:00:02 --:--:-- 26.7M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    513      0 --:--:-- --:--:-- --:--:--   513\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 3009k    0 3009k    0     0  2552k      0 --:--:--  0:00:01 --:--:-- 2552k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2550      0 --:--:-- --:--:-- --:--:--  2550\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  513M    0  513M    0     0   108M      0 --:--:--  0:00:04 --:--:--  119M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    368      0 --:--:--  0:00:01 --:--:--   368\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 22.6M    0 22.6M    0     0  14.5M      0 --:--:--  0:00:01 --:--:-- 14.5M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    653      0 --:--:-- --:--:-- --:--:--   652\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 60.3M    0 60.3M    0     0  49.0M      0 --:--:--  0:00:01 --:--:--  248M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1728      0 --:--:-- --:--:-- --:--:--  1728\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 2729k    0 2729k    0     0  4346k      0 --:--:-- --:--:-- --:--:--  316M\n",
            "\n",
            "[3/9] Downloading GTSRB dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    264      0 --:--:--  0:00:01 --:--:--   264\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 98.6M    0 98.6M    0     0  44.9M      0 --:--:--  0:00:02 --:--:-- 44.9M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    423      0 --:--:-- --:--:-- --:--:--   422\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 4243k    0 4243k    0     0  3192k      0 --:--:--  0:00:01 --:--:-- 3192k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1533      0 --:--:-- --:--:-- --:--:--  1533\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  306M    0  306M    0     0  82.6M      0 --:--:--  0:00:03 --:--:--  109M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    454      0 --:--:-- --:--:-- --:--:--   454\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 12.8M    0 12.8M    0     0  8637k      0 --:--:--  0:00:01 --:--:-- 8637k\n",
            "\n",
            "[4/9] Downloading SVHN dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2000      0 --:--:-- --:--:-- --:--:--  2000\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  305M    0  305M    0     0   106M      0 --:--:--  0:00:02 --:--:--  156M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    346      0 --:--:--  0:00:01 --:--:--   346\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 1017k  100 1017k    0     0   655k      0  0:00:01  0:00:01 --:--:-- 11.8M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2503      0 --:--:-- --:--:-- --:--:--  2503\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  772M    0  772M    0     0  84.5M      0 --:--:--  0:00:09 --:--:-- 91.9M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    436      0 --:--:-- --:--:-- --:--:--   436\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 2575k    0 2575k    0     0  2010k      0 --:--:--  0:00:01 --:--:-- 50.3M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    357      0 --:--:--  0:00:01 --:--:--   357\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 85.8M    0 85.8M    0     0  46.6M      0 --:--:--  0:00:01 --:--:--  215M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1587      0 --:--:-- --:--:-- --:--:--  1593\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  286k  100  286k    0     0   459k      0 --:--:-- --:--:-- --:--:--  459k\n",
            "\n",
            "[5/9] Downloading US8K dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2666      0 --:--:-- --:--:-- --:--:--  2666\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  202M    0  202M    0     0  84.6M      0 --:--:--  0:00:02 --:--:--  129M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    731      0 --:--:-- --:--:-- --:--:--   729\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  422k  100  422k    0     0   474k      0 --:--:-- --:--:-- --:--:--  474k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2615      0 --:--:-- --:--:-- --:--:--  2615\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1826M    0 1826M    0     0  57.9M      0 --:--:--  0:00:31 --:--:-- 42.8M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1728      0 --:--:-- --:--:-- --:--:--  1721\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 3801k    0 3801k    0     0  6576k      0 --:--:-- --:--:-- --:--:-- 6576k\n",
            "\n",
            "[6/9] Downloading FMNIST dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    508      0 --:--:-- --:--:-- --:--:--   508\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 59.8M    0 59.8M    0     0  40.4M      0 --:--:--  0:00:01 --:--:--  347M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    758      0 --:--:-- --:--:-- --:--:--   758\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  390k  100  390k    0     0   447k      0 --:--:-- --:--:-- --:--:--  447k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2666      0 --:--:-- --:--:-- --:--:--  2666\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  358M    0  358M    0     0  81.2M      0 --:--:--  0:00:04 --:--:--  106M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    331      0 --:--:--  0:00:01 --:--:--   331\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 2343k    0 2343k    0     0  1353k      0 --:--:--  0:00:01 --:--:-- 1353k\n",
            "\n",
            "[7/9] Downloading HHAR dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    287      0 --:--:--  0:00:01 --:--:--   287\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 21.8M    0 21.8M    0     0  11.6M      0 --:--:--  0:00:01 --:--:-- 11.6M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1645      0 --:--:-- --:--:-- --:--:--  1645\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 57392  100 57392    0     0    99k      0 --:--:-- --:--:-- --:--:--   99k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2266      0 --:--:-- --:--:-- --:--:--  2266\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 2180M    0 2180M    0     0  53.5M      0 --:--:--  0:00:40 --:--:-- 46.0M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    375      0 --:--:--  0:00:01 --:--:--   375\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 5582k    0 5582k    0     0  3892k      0 --:--:--  0:00:01 --:--:-- 3892k\n",
            "\n",
            "[8/9] Downloading ESC10 dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    825      0 --:--:-- --:--:-- --:--:--   825\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 26.3M    0 26.3M    0     0  29.0M      0 --:--:-- --:--:-- --:--:-- 29.0M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1880      0 --:--:-- --:--:-- --:--:--  1880\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 28208  100 28208    0     0  48887      0 --:--:-- --:--:-- --:--:-- 48887\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2684      0 --:--:-- --:--:-- --:--:--  2684\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  237M    0  237M    0     0  92.8M      0 --:--:--  0:00:02 --:--:--  149M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1175      0 --:--:-- --:--:-- --:--:--  1179\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  246k  100  246k    0     0   343k      0 --:--:-- --:--:-- --:--:--  111M\n",
            "\n",
            "[9/9] Downloading OBS dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    205      0 --:--:--  0:00:01 --:--:--   205\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100 78.4M    0 78.4M    0     0  30.5M      0 --:--:--  0:00:02 --:--:-- 30.5M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1324      0 --:--:-- --:--:-- --:--:--  1320\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 91488  100 91488    0     0   140k      0 --:--:-- --:--:-- --:--:--  140k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2632      0 --:--:-- --:--:-- --:--:--  2632\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  156M    0  156M    0     0  89.6M      0 --:--:--  0:00:01 --:--:--  120M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    762      0 --:--:-- --:--:-- --:--:--   762\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  178k  100  178k    0     0   204k      0 --:--:-- --:--:-- --:--:-- 4255k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    155      0 --:--:--  0:00:02 --:--:--   155\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100 78.4M    0 78.4M    0     0  24.2M      0 --:--:--  0:00:03 --:--:--  321M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1758      0 --:--:-- --:--:-- --:--:--  1758\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 91488  100 91488    0     0   114k      0 --:--:-- --:--:-- --:--:--  114k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioCQsqsl9iGn",
        "outputId": "dedecc7a-b368-41b4-e7ee-dfffaec1c4d8"
      },
      "source": [
        "!python weight_virtualization.py -mode=a -network_path=mnist"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "add_vnn\n",
            "mnist/mnist_network_weight.npy\n",
            "compute_fisher\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx: 34449\n",
            "sample num:    1, data_idx: 32808\n",
            "sample num:    2, data_idx: 49151\n",
            "sample num:    3, data_idx:  2990\n",
            "sample num:    4, data_idx: 14515\n",
            "sample num:    5, data_idx: 28016\n",
            "sample num:    6, data_idx: 30048\n",
            "sample num:    7, data_idx: 29084\n",
            "sample num:    8, data_idx: 11381\n",
            "sample num:    9, data_idx: 37920\n",
            "sample num:   10, data_idx: 28370\n",
            "sample num:   11, data_idx: 53660\n",
            "sample num:   12, data_idx: 40930\n",
            "sample num:   13, data_idx: 32740\n",
            "sample num:   14, data_idx: 20824\n",
            "sample num:   15, data_idx: 10104\n",
            "sample num:   16, data_idx: 45099\n",
            "sample num:   17, data_idx: 54423\n",
            "sample num:   18, data_idx: 52803\n",
            "sample num:   19, data_idx: 21884\n",
            "sample num:   20, data_idx: 31887\n",
            "sample num:   21, data_idx: 28217\n",
            "sample num:   22, data_idx:   108\n",
            "sample num:   23, data_idx: 40143\n",
            "sample num:   24, data_idx: 29249\n",
            "sample num:   25, data_idx: 33473\n",
            "sample num:   26, data_idx: 45407\n",
            "sample num:   27, data_idx: 35219\n",
            "sample num:   28, data_idx: 51545\n",
            "sample num:   29, data_idx:  6966\n",
            "sample num:   30, data_idx:  7572\n",
            "sample num:   31, data_idx: 47087\n",
            "sample num:   32, data_idx: 53181\n",
            "sample num:   33, data_idx: 41484\n",
            "sample num:   34, data_idx: 12522\n",
            "sample num:   35, data_idx: 30189\n",
            "sample num:   36, data_idx:  3930\n",
            "sample num:   37, data_idx: 41807\n",
            "sample num:   38, data_idx:  9961\n",
            "sample num:   39, data_idx:  7109\n",
            "sample num:   40, data_idx: 47110\n",
            "sample num:   41, data_idx: 38452\n",
            "sample num:   42, data_idx:  2402\n",
            "sample num:   43, data_idx: 19142\n",
            "sample num:   44, data_idx: 38085\n",
            "sample num:   45, data_idx: 54293\n",
            "sample num:   46, data_idx: 17327\n",
            "sample num:   47, data_idx:   648\n",
            "sample num:   48, data_idx: 23284\n",
            "sample num:   49, data_idx: 14504\n",
            "sample num:   50, data_idx: 46591\n",
            "sample num:   51, data_idx: 20230\n",
            "sample num:   52, data_idx: 24737\n",
            "sample num:   53, data_idx: 50205\n",
            "sample num:   54, data_idx: 31108\n",
            "sample num:   55, data_idx:   285\n",
            "sample num:   56, data_idx:   686\n",
            "sample num:   57, data_idx: 37479\n",
            "sample num:   58, data_idx:  8642\n",
            "sample num:   59, data_idx: 52836\n",
            "sample num:   60, data_idx: 30541\n",
            "sample num:   61, data_idx: 21992\n",
            "sample num:   62, data_idx: 27167\n",
            "sample num:   63, data_idx: 39059\n",
            "sample num:   64, data_idx:  3888\n",
            "sample num:   65, data_idx: 38236\n",
            "sample num:   66, data_idx: 30526\n",
            "sample num:   67, data_idx: 31318\n",
            "sample num:   68, data_idx: 44601\n",
            "sample num:   69, data_idx: 40175\n",
            "sample num:   70, data_idx: 46096\n",
            "sample num:   71, data_idx: 11640\n",
            "sample num:   72, data_idx: 12363\n",
            "sample num:   73, data_idx: 38310\n",
            "sample num:   74, data_idx:  3722\n",
            "sample num:   75, data_idx: 22974\n",
            "sample num:   76, data_idx: 54683\n",
            "sample num:   77, data_idx: 27604\n",
            "sample num:   78, data_idx: 31900\n",
            "sample num:   79, data_idx: 12194\n",
            "sample num:   80, data_idx: 23222\n",
            "sample num:   81, data_idx: 39241\n",
            "sample num:   82, data_idx: 46364\n",
            "sample num:   83, data_idx: 29313\n",
            "sample num:   84, data_idx: 48721\n",
            "sample num:   85, data_idx: 28125\n",
            "sample num:   86, data_idx:  7616\n",
            "sample num:   87, data_idx: 31863\n",
            "sample num:   88, data_idx: 22674\n",
            "sample num:   89, data_idx: 27223\n",
            "sample num:   90, data_idx: 33295\n",
            "sample num:   91, data_idx: 10434\n",
            "sample num:   92, data_idx: 27761\n",
            "sample num:   93, data_idx: 23593\n",
            "sample num:   94, data_idx: 16288\n",
            "sample num:   95, data_idx: 47385\n",
            "sample num:   96, data_idx: 22776\n",
            "sample num:   97, data_idx: 38905\n",
            "sample num:   98, data_idx: 33265\n",
            "sample num:   99, data_idx: 14709\n",
            "mnist/mnist_network_fisher.npy\n",
            "[match_page_by_cost]\n",
            "occupation: 0\n",
            "len(page_list): 0\n",
            "len(network_page_list): 458\n",
            "cost: 0\n",
            "\n",
            "occupation: 1\n",
            "len(page_list): 0\n",
            "len(network_page_list): 458\n",
            "cost: 0\n",
            "\n",
            "occupation: 2\n",
            "len(page_list): 0\n",
            "len(network_page_list): 458\n",
            "cost: 0\n",
            "\n",
            "occupation: 3\n",
            "len(page_list): 383\n",
            "len(network_page_list): 458\n",
            "       0-th page\n",
            "     382-th page\n",
            "cost: 6.756028\n",
            "\n",
            "occupation: 4\n",
            "len(page_list): 338\n",
            "len(network_page_list): 75\n",
            "       0-th page\n",
            "      74-th page\n",
            "cost: 0.0035574336\n",
            "\n",
            "assing_page 111.391 ms\n",
            "[calculate_cost]\n",
            "toal_cost: 6.759626964816562\n",
            "458 pages allocated for 45706 weights\n",
            "total_network_cost: 97.16210011951625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOYWgRK7HG2O",
        "outputId": "c7613709-157a-484a-ecc9-ef3a21c1669a"
      },
      "source": [
        "!python weight_virtualization.py -mode=t -vnn_name=mnist"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "get_matching_loss\n",
            "v_train\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "step 0, training accuracy: 0.110000 original loss: 6.988606 matching loss: 0.045293\n",
            "step 0, Validation accuracy: 0.105000\n",
            "step 100, training accuracy: 0.840000 original loss: 5.257933 matching loss: 0.055840\n",
            "step 100, Validation accuracy: 0.863200\n",
            "get new weight for 0.8632\n",
            "step 200, training accuracy: 0.930000 original loss: 5.043331 matching loss: 0.049730\n",
            "step 200, Validation accuracy: 0.897800\n",
            "get new weight for 0.8978\n",
            "step 300, training accuracy: 0.910000 original loss: 4.968061 matching loss: 0.048522\n",
            "step 300, Validation accuracy: 0.920300\n",
            "get new weight for 0.9203\n",
            "step 400, training accuracy: 0.930000 original loss: 4.905015 matching loss: 0.047743\n",
            "step 400, Validation accuracy: 0.929200\n",
            "get new weight for 0.9292\n",
            "step 500, training accuracy: 0.960000 original loss: 4.853009 matching loss: 0.047150\n",
            "step 500, Validation accuracy: 0.938600\n",
            "get new weight for 0.9386\n",
            "step 600, training accuracy: 0.950000 original loss: 4.868930 matching loss: 0.046769\n",
            "step 600, Validation accuracy: 0.947100\n",
            "get new weight for 0.9471\n",
            "step 700, training accuracy: 0.930000 original loss: 4.840999 matching loss: 0.046250\n",
            "step 700, Validation accuracy: 0.947600\n",
            "get new weight for 0.9476\n",
            "step 800, training accuracy: 0.980000 original loss: 4.763228 matching loss: 0.045614\n",
            "step 800, Validation accuracy: 0.951600\n",
            "get new weight for 0.9516\n",
            "step 900, training accuracy: 0.950000 original loss: 4.827248 matching loss: 0.045194\n",
            "step 900, Validation accuracy: 0.956100\n",
            "get new weight for 0.9561\n",
            "step 1000, training accuracy: 0.930000 original loss: 4.838112 matching loss: 0.044706\n",
            "step 1000, Validation accuracy: 0.958400\n",
            "get new weight for 0.9584\n",
            "step 1100, training accuracy: 0.940000 original loss: 4.851841 matching loss: 0.044513\n",
            "step 1100, Validation accuracy: 0.956900\n",
            "step 1200, training accuracy: 0.980000 original loss: 4.726605 matching loss: 0.044349\n",
            "step 1200, Validation accuracy: 0.959200\n",
            "get new weight for 0.9592\n",
            "step 1300, training accuracy: 0.920000 original loss: 4.816740 matching loss: 0.044000\n",
            "step 1300, Validation accuracy: 0.962400\n",
            "get new weight for 0.9624\n",
            "step 1400, training accuracy: 0.960000 original loss: 4.758275 matching loss: 0.043724\n",
            "step 1400, Validation accuracy: 0.964100\n",
            "get new weight for 0.9641\n",
            "step 1500, training accuracy: 0.970000 original loss: 4.723261 matching loss: 0.043412\n",
            "step 1500, Validation accuracy: 0.964600\n",
            "get new weight for 0.9646\n",
            "step 1600, training accuracy: 0.940000 original loss: 4.808476 matching loss: 0.043212\n",
            "step 1600, Validation accuracy: 0.965400\n",
            "get new weight for 0.9654\n",
            "step 1700, training accuracy: 0.950000 original loss: 4.727497 matching loss: 0.042960\n",
            "step 1700, Validation accuracy: 0.967900\n",
            "get new weight for 0.9679\n",
            "step 1800, training accuracy: 0.980000 original loss: 4.695221 matching loss: 0.042689\n",
            "step 1800, Validation accuracy: 0.966900\n",
            "step 1900, training accuracy: 0.990000 original loss: 4.683136 matching loss: 0.042554\n",
            "step 1900, Validation accuracy: 0.969700\n",
            "get new weight for 0.9697\n",
            "step 2000, training accuracy: 0.970000 original loss: 4.721832 matching loss: 0.042485\n",
            "step 2000, Validation accuracy: 0.969700\n",
            "step 2100, training accuracy: 0.950000 original loss: 4.779380 matching loss: 0.042075\n",
            "step 2100, Validation accuracy: 0.971400\n",
            "get new weight for 0.9714\n",
            "step 2200, training accuracy: 1.000000 original loss: 4.673952 matching loss: 0.041857\n",
            "step 2200, Validation accuracy: 0.971100\n",
            "step 2300, training accuracy: 0.970000 original loss: 4.720159 matching loss: 0.041941\n",
            "step 2300, Validation accuracy: 0.966100\n",
            "step 2400, training accuracy: 0.970000 original loss: 4.721222 matching loss: 0.041860\n",
            "step 2400, Validation accuracy: 0.970100\n",
            "step 2500, training accuracy: 0.980000 original loss: 4.697057 matching loss: 0.041706\n",
            "step 2500, Validation accuracy: 0.972600\n",
            "get new weight for 0.9726\n",
            "step 2600, training accuracy: 0.980000 original loss: 4.690483 matching loss: 0.041572\n",
            "step 2600, Validation accuracy: 0.974100\n",
            "get new weight for 0.9741\n",
            "step 2700, training accuracy: 0.970000 original loss: 4.715220 matching loss: 0.041366\n",
            "step 2700, Validation accuracy: 0.972000\n",
            "step 2800, training accuracy: 0.970000 original loss: 4.745824 matching loss: 0.041332\n",
            "step 2800, Validation accuracy: 0.971000\n",
            "step 2900, training accuracy: 0.960000 original loss: 4.742610 matching loss: 0.041219\n",
            "step 2900, Validation accuracy: 0.974300\n",
            "get new weight for 0.9743\n",
            "step 3000, training accuracy: 1.000000 original loss: 4.631498 matching loss: 0.041066\n",
            "step 3000, Validation accuracy: 0.973600\n",
            "step 3100, training accuracy: 0.990000 original loss: 4.672959 matching loss: 0.041059\n",
            "step 3100, Validation accuracy: 0.974100\n",
            "step 3200, training accuracy: 0.960000 original loss: 4.722898 matching loss: 0.041072\n",
            "step 3200, Validation accuracy: 0.972000\n",
            "step 3300, training accuracy: 1.000000 original loss: 4.645442 matching loss: 0.040778\n",
            "step 3300, Validation accuracy: 0.976100\n",
            "get new weight for 0.9761\n",
            "step 3400, training accuracy: 1.000000 original loss: 4.644251 matching loss: 0.040672\n",
            "step 3400, Validation accuracy: 0.975800\n",
            "step 3500, training accuracy: 0.980000 original loss: 4.716704 matching loss: 0.040634\n",
            "step 3500, Validation accuracy: 0.977400\n",
            "get new weight for 0.9774\n",
            "step 3600, training accuracy: 0.970000 original loss: 4.724217 matching loss: 0.040538\n",
            "step 3600, Validation accuracy: 0.976700\n",
            "step 3700, training accuracy: 0.970000 original loss: 4.664244 matching loss: 0.040441\n",
            "step 3700, Validation accuracy: 0.973800\n",
            "step 3800, training accuracy: 0.980000 original loss: 4.731007 matching loss: 0.040574\n",
            "step 3800, Validation accuracy: 0.974700\n",
            "step 3900, training accuracy: 0.950000 original loss: 4.707967 matching loss: 0.040283\n",
            "step 3900, Validation accuracy: 0.976500\n",
            "step 4000, training accuracy: 0.990000 original loss: 4.677341 matching loss: 0.040273\n",
            "step 4000, Validation accuracy: 0.976700\n",
            "step 4100, training accuracy: 0.960000 original loss: 4.758967 matching loss: 0.040232\n",
            "step 4100, Validation accuracy: 0.975500\n",
            "step 4200, training accuracy: 0.980000 original loss: 4.695982 matching loss: 0.040125\n",
            "step 4200, Validation accuracy: 0.974800\n",
            "step 4300, training accuracy: 0.970000 original loss: 4.751909 matching loss: 0.040068\n",
            "step 4300, Validation accuracy: 0.977900\n",
            "get new weight for 0.9779\n",
            "step 4400, training accuracy: 0.980000 original loss: 4.676758 matching loss: 0.040329\n",
            "step 4400, Validation accuracy: 0.972200\n",
            "step 4500, training accuracy: 0.990000 original loss: 4.665381 matching loss: 0.040220\n",
            "step 4500, Validation accuracy: 0.974400\n",
            "step 4600, training accuracy: 0.990000 original loss: 4.650724 matching loss: 0.039991\n",
            "step 4600, Validation accuracy: 0.978300\n",
            "get new weight for 0.9783\n",
            "step 4700, training accuracy: 0.990000 original loss: 4.680963 matching loss: 0.040053\n",
            "step 4700, Validation accuracy: 0.976500\n",
            "step 4800, training accuracy: 0.990000 original loss: 4.649896 matching loss: 0.039869\n",
            "step 4800, Validation accuracy: 0.978000\n",
            "step 4900, training accuracy: 1.000000 original loss: 4.634058 matching loss: 0.040131\n",
            "step 4900, Validation accuracy: 0.977300\n",
            "step 4999, training accuracy: 1.000000 original loss: 4.641000 matching loss: 0.039954\n",
            "step 4999, Validation accuracy: 0.977200\n",
            "mnist/mnist_weight.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKNfgtDZ9nOk",
        "outputId": "95b8b02d-9342-4cca-8fad-59c2924a1a4c"
      },
      "source": [
        "!python weight_virtualization.py -mode=f -vnn_name=mnist"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compute_fisher\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx:  3766\n",
            "sample num:    1, data_idx: 32073\n",
            "sample num:    2, data_idx:   878\n",
            "sample num:    3, data_idx: 30205\n",
            "sample num:    4, data_idx:  8190\n",
            "sample num:    5, data_idx:  9134\n",
            "sample num:    6, data_idx: 14471\n",
            "sample num:    7, data_idx:  7857\n",
            "sample num:    8, data_idx: 12172\n",
            "sample num:    9, data_idx: 15258\n",
            "sample num:   10, data_idx:  7486\n",
            "sample num:   11, data_idx: 14986\n",
            "sample num:   12, data_idx:   102\n",
            "sample num:   13, data_idx: 48883\n",
            "sample num:   14, data_idx: 44959\n",
            "sample num:   15, data_idx:   789\n",
            "sample num:   16, data_idx: 41000\n",
            "sample num:   17, data_idx: 14302\n",
            "sample num:   18, data_idx: 47017\n",
            "sample num:   19, data_idx:  4591\n",
            "sample num:   20, data_idx: 49745\n",
            "sample num:   21, data_idx: 23442\n",
            "sample num:   22, data_idx: 22281\n",
            "sample num:   23, data_idx: 38751\n",
            "sample num:   24, data_idx: 35825\n",
            "sample num:   25, data_idx: 40591\n",
            "sample num:   26, data_idx: 52331\n",
            "sample num:   27, data_idx:   483\n",
            "sample num:   28, data_idx: 38802\n",
            "sample num:   29, data_idx: 24985\n",
            "sample num:   30, data_idx: 23042\n",
            "sample num:   31, data_idx: 49677\n",
            "sample num:   32, data_idx: 14983\n",
            "sample num:   33, data_idx: 53562\n",
            "sample num:   34, data_idx: 30206\n",
            "sample num:   35, data_idx:  1242\n",
            "sample num:   36, data_idx:  6007\n",
            "sample num:   37, data_idx: 48920\n",
            "sample num:   38, data_idx: 47977\n",
            "sample num:   39, data_idx: 27933\n",
            "sample num:   40, data_idx: 41151\n",
            "sample num:   41, data_idx: 29095\n",
            "sample num:   42, data_idx: 34841\n",
            "sample num:   43, data_idx: 26504\n",
            "sample num:   44, data_idx: 46803\n",
            "sample num:   45, data_idx: 33615\n",
            "sample num:   46, data_idx: 37297\n",
            "sample num:   47, data_idx: 50684\n",
            "sample num:   48, data_idx: 10306\n",
            "sample num:   49, data_idx: 48270\n",
            "sample num:   50, data_idx: 28711\n",
            "sample num:   51, data_idx: 38663\n",
            "sample num:   52, data_idx: 45710\n",
            "sample num:   53, data_idx: 25610\n",
            "sample num:   54, data_idx: 10570\n",
            "sample num:   55, data_idx: 23622\n",
            "sample num:   56, data_idx: 39663\n",
            "sample num:   57, data_idx:  7587\n",
            "sample num:   58, data_idx: 25760\n",
            "sample num:   59, data_idx: 20242\n",
            "sample num:   60, data_idx:  4045\n",
            "sample num:   61, data_idx: 52694\n",
            "sample num:   62, data_idx: 34610\n",
            "sample num:   63, data_idx: 27197\n",
            "sample num:   64, data_idx: 13622\n",
            "sample num:   65, data_idx: 22449\n",
            "sample num:   66, data_idx: 47994\n",
            "sample num:   67, data_idx:  8553\n",
            "sample num:   68, data_idx: 14939\n",
            "sample num:   69, data_idx: 18968\n",
            "sample num:   70, data_idx:  4585\n",
            "sample num:   71, data_idx: 31347\n",
            "sample num:   72, data_idx: 42977\n",
            "sample num:   73, data_idx: 22167\n",
            "sample num:   74, data_idx: 35820\n",
            "sample num:   75, data_idx: 17913\n",
            "sample num:   76, data_idx:  6110\n",
            "sample num:   77, data_idx: 11333\n",
            "sample num:   78, data_idx:  2376\n",
            "sample num:   79, data_idx: 50618\n",
            "sample num:   80, data_idx: 46751\n",
            "sample num:   81, data_idx:  6628\n",
            "sample num:   82, data_idx: 40040\n",
            "sample num:   83, data_idx: 19610\n",
            "sample num:   84, data_idx: 49181\n",
            "sample num:   85, data_idx: 41619\n",
            "sample num:   86, data_idx: 53730\n",
            "sample num:   87, data_idx: 37365\n",
            "sample num:   88, data_idx: 13862\n",
            "sample num:   89, data_idx: 10218\n",
            "sample num:   90, data_idx: 28343\n",
            "sample num:   91, data_idx: 50583\n",
            "sample num:   92, data_idx: 36744\n",
            "sample num:   93, data_idx: 25188\n",
            "sample num:   94, data_idx:  5860\n",
            "sample num:   95, data_idx: 10623\n",
            "sample num:   96, data_idx: 27692\n",
            "sample num:   97, data_idx: 14945\n",
            "sample num:   98, data_idx:  8184\n",
            "sample num:   99, data_idx: 17792\n",
            "mnist/mnist_fisher.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OlgjqibKI6X",
        "outputId": "a4555d8f-f8fd-4fbc-8aaf-f0d3ee55ad8d"
      },
      "source": [
        "!python weight_virtualization.py -mode=pf -vnn_name=mnist"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Figure size 640x480 with 1 Axes>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDmzsrxsNWCF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsXQCFFONWG6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-97bCL1NWKj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUA52bruNWNl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REPgQzCiNWQh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUAPsAFmNWTH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V18vLvMO_MZt",
        "outputId": "afaffc81-7ead-49dd-f2b6-deaf857dea46"
      },
      "source": [
        "!python weight_virtualization.py -mode=a -network_path=mnist\n",
        "!python weight_virtualization.py -mode=f -vnn_name=mnist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "add_vnn\n",
            "mnist/mnist_network_weight.npy\n",
            "compute_fisher\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx: 44578\n",
            "sample num:    1, data_idx: 49469\n",
            "sample num:    2, data_idx: 18594\n",
            "sample num:    3, data_idx: 53754\n",
            "sample num:    4, data_idx: 46429\n",
            "sample num:    5, data_idx: 39124\n",
            "sample num:    6, data_idx: 39549\n",
            "sample num:    7, data_idx:   298\n",
            "sample num:    8, data_idx: 17653\n",
            "sample num:    9, data_idx: 27441\n",
            "sample num:   10, data_idx:  9271\n",
            "sample num:   11, data_idx: 42788\n",
            "sample num:   12, data_idx: 34979\n",
            "sample num:   13, data_idx: 17683\n",
            "sample num:   14, data_idx: 50333\n",
            "sample num:   15, data_idx:  8721\n",
            "sample num:   16, data_idx: 11513\n",
            "sample num:   17, data_idx: 13039\n",
            "sample num:   18, data_idx: 50049\n",
            "sample num:   19, data_idx: 41761\n",
            "sample num:   20, data_idx: 35446\n",
            "sample num:   21, data_idx:  8726\n",
            "sample num:   22, data_idx: 43345\n",
            "sample num:   23, data_idx: 15587\n",
            "sample num:   24, data_idx: 26288\n",
            "sample num:   25, data_idx: 51230\n",
            "sample num:   26, data_idx: 36193\n",
            "sample num:   27, data_idx: 20671\n",
            "sample num:   28, data_idx: 13280\n",
            "sample num:   29, data_idx: 40592\n",
            "sample num:   30, data_idx:  2885\n",
            "sample num:   31, data_idx: 44648\n",
            "sample num:   32, data_idx: 24457\n",
            "sample num:   33, data_idx:  7094\n",
            "sample num:   34, data_idx:  7094\n",
            "sample num:   35, data_idx: 23826\n",
            "sample num:   36, data_idx: 31442\n",
            "sample num:   37, data_idx: 42751\n",
            "sample num:   38, data_idx: 27938\n",
            "sample num:   39, data_idx:  7944\n",
            "sample num:   40, data_idx: 41344\n",
            "sample num:   41, data_idx: 40918\n",
            "sample num:   42, data_idx: 17141\n",
            "sample num:   43, data_idx:  4714\n",
            "sample num:   44, data_idx: 14214\n",
            "sample num:   45, data_idx: 17914\n",
            "sample num:   46, data_idx: 31681\n",
            "sample num:   47, data_idx:  9773\n",
            "sample num:   48, data_idx: 10330\n",
            "sample num:   49, data_idx: 52055\n",
            "sample num:   50, data_idx: 54600\n",
            "sample num:   51, data_idx: 48740\n",
            "sample num:   52, data_idx: 24570\n",
            "sample num:   53, data_idx: 44419\n",
            "sample num:   54, data_idx: 17445\n",
            "sample num:   55, data_idx: 19044\n",
            "sample num:   56, data_idx: 54818\n",
            "sample num:   57, data_idx: 26118\n",
            "sample num:   58, data_idx: 32069\n",
            "sample num:   59, data_idx: 12173\n",
            "sample num:   60, data_idx: 23960\n",
            "sample num:   61, data_idx:  7038\n",
            "sample num:   62, data_idx: 24533\n",
            "sample num:   63, data_idx: 49880\n",
            "sample num:   64, data_idx: 34425\n",
            "sample num:   65, data_idx: 33533\n",
            "sample num:   66, data_idx: 34122\n",
            "sample num:   67, data_idx: 18499\n",
            "sample num:   68, data_idx: 18254\n",
            "sample num:   69, data_idx: 19304\n",
            "sample num:   70, data_idx:  1742\n",
            "sample num:   71, data_idx: 38099\n",
            "sample num:   72, data_idx: 31805\n",
            "sample num:   73, data_idx: 33182\n",
            "sample num:   74, data_idx:  3678\n",
            "sample num:   75, data_idx:  2019\n",
            "sample num:   76, data_idx: 34697\n",
            "sample num:   77, data_idx: 30767\n",
            "sample num:   78, data_idx: 31116\n",
            "sample num:   79, data_idx: 54187\n",
            "sample num:   80, data_idx: 19061\n",
            "sample num:   81, data_idx:  5183\n",
            "sample num:   82, data_idx: 54836\n",
            "sample num:   83, data_idx:  4823\n",
            "sample num:   84, data_idx: 39025\n",
            "sample num:   85, data_idx: 13588\n",
            "sample num:   86, data_idx: 39521\n",
            "sample num:   87, data_idx: 12934\n",
            "sample num:   88, data_idx:   853\n",
            "sample num:   89, data_idx: 45896\n",
            "sample num:   90, data_idx: 31899\n",
            "sample num:   91, data_idx: 52522\n",
            "sample num:   92, data_idx: 25033\n",
            "sample num:   93, data_idx: 15634\n",
            "sample num:   94, data_idx: 54412\n",
            "sample num:   95, data_idx: 29422\n",
            "sample num:   96, data_idx:  2095\n",
            "sample num:   97, data_idx: 54980\n",
            "sample num:   98, data_idx: 43399\n",
            "sample num:   99, data_idx: 20527\n",
            "mnist/mnist_network_fisher.npy\n",
            "[match_page_by_cost]\n",
            "occupation: 0\n",
            "len(page_list): 266\n",
            "len(network_page_list): 458\n",
            "       0-th page\n",
            "     265-th page\n",
            "cost: 0.0\n",
            "\n",
            "occupation: 1\n",
            "len(page_list): 455\n",
            "len(network_page_list): 192\n",
            "       0-th page\n",
            "     191-th page\n",
            "cost: 0.00036710603\n",
            "\n",
            "assing_page 233.915 ms\n",
            "[calculate_cost]\n",
            "toal_cost: 0.0003671060458145803\n",
            "458 pages allocated for 45706 weights\n",
            "total_network_cost: 0.0007531867013312876\n",
            "compute_fisher\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx: 39902\n",
            "sample num:    1, data_idx: 15032\n",
            "sample num:    2, data_idx: 43318\n",
            "sample num:    3, data_idx: 44944\n",
            "sample num:    4, data_idx:  4456\n",
            "sample num:    5, data_idx: 39113\n",
            "sample num:    6, data_idx: 34759\n",
            "sample num:    7, data_idx: 46815\n",
            "sample num:    8, data_idx: 29271\n",
            "sample num:    9, data_idx: 45352\n",
            "sample num:   10, data_idx: 51576\n",
            "sample num:   11, data_idx: 26397\n",
            "sample num:   12, data_idx:  3277\n",
            "sample num:   13, data_idx: 24184\n",
            "sample num:   14, data_idx: 33506\n",
            "sample num:   15, data_idx: 48050\n",
            "sample num:   16, data_idx: 18733\n",
            "sample num:   17, data_idx:  1831\n",
            "sample num:   18, data_idx:  9737\n",
            "sample num:   19, data_idx: 47969\n",
            "sample num:   20, data_idx: 24460\n",
            "sample num:   21, data_idx: 53310\n",
            "sample num:   22, data_idx: 12150\n",
            "sample num:   23, data_idx: 32724\n",
            "sample num:   24, data_idx:  6709\n",
            "sample num:   25, data_idx: 33876\n",
            "sample num:   26, data_idx: 20980\n",
            "sample num:   27, data_idx: 51174\n",
            "sample num:   28, data_idx: 16062\n",
            "sample num:   29, data_idx: 43704\n",
            "sample num:   30, data_idx: 32010\n",
            "sample num:   31, data_idx: 14991\n",
            "sample num:   32, data_idx:  4674\n",
            "sample num:   33, data_idx: 33110\n",
            "sample num:   34, data_idx: 48237\n",
            "sample num:   35, data_idx: 34528\n",
            "sample num:   36, data_idx: 52327\n",
            "sample num:   37, data_idx: 16327\n",
            "sample num:   38, data_idx: 52809\n",
            "sample num:   39, data_idx: 47255\n",
            "sample num:   40, data_idx: 18587\n",
            "sample num:   41, data_idx: 21799\n",
            "sample num:   42, data_idx: 32226\n",
            "sample num:   43, data_idx: 36179\n",
            "sample num:   44, data_idx: 15013\n",
            "sample num:   45, data_idx: 17053\n",
            "sample num:   46, data_idx: 12805\n",
            "sample num:   47, data_idx:  6333\n",
            "sample num:   48, data_idx: 48941\n",
            "sample num:   49, data_idx: 38950\n",
            "sample num:   50, data_idx: 36786\n",
            "sample num:   51, data_idx: 35684\n",
            "sample num:   52, data_idx: 21444\n",
            "sample num:   53, data_idx: 44440\n",
            "sample num:   54, data_idx: 53970\n",
            "sample num:   55, data_idx: 39382\n",
            "sample num:   56, data_idx: 43813\n",
            "sample num:   57, data_idx: 40264\n",
            "sample num:   58, data_idx:    13\n",
            "sample num:   59, data_idx: 15592\n",
            "sample num:   60, data_idx: 39726\n",
            "sample num:   61, data_idx: 35799\n",
            "sample num:   62, data_idx:  2422\n",
            "sample num:   63, data_idx:  6633\n",
            "sample num:   64, data_idx: 13486\n",
            "sample num:   65, data_idx: 31622\n",
            "sample num:   66, data_idx: 47694\n",
            "sample num:   67, data_idx: 28613\n",
            "sample num:   68, data_idx: 11727\n",
            "sample num:   69, data_idx: 23679\n",
            "sample num:   70, data_idx:  4172\n",
            "sample num:   71, data_idx: 52040\n",
            "sample num:   72, data_idx: 15636\n",
            "sample num:   73, data_idx: 41954\n",
            "sample num:   74, data_idx:  1569\n",
            "sample num:   75, data_idx:  3788\n",
            "sample num:   76, data_idx:  9618\n",
            "sample num:   77, data_idx: 16484\n",
            "sample num:   78, data_idx: 12121\n",
            "sample num:   79, data_idx: 27439\n",
            "sample num:   80, data_idx: 31072\n",
            "sample num:   81, data_idx: 32801\n",
            "sample num:   82, data_idx:  1587\n",
            "sample num:   83, data_idx: 15056\n",
            "sample num:   84, data_idx: 11574\n",
            "sample num:   85, data_idx: 54122\n",
            "sample num:   86, data_idx: 47610\n",
            "sample num:   87, data_idx: 49163\n",
            "sample num:   88, data_idx: 11503\n",
            "sample num:   89, data_idx:  9136\n",
            "sample num:   90, data_idx: 52977\n",
            "sample num:   91, data_idx:  8060\n",
            "sample num:   92, data_idx: 25884\n",
            "sample num:   93, data_idx: 29304\n",
            "sample num:   94, data_idx: 14772\n",
            "sample num:   95, data_idx:  8560\n",
            "sample num:   96, data_idx:  4110\n",
            "sample num:   97, data_idx: 44787\n",
            "sample num:   98, data_idx: 36222\n",
            "sample num:   99, data_idx: 42977\n",
            "mnist/mnist_fisher.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afwOVc3gDQ5u",
        "outputId": "cc79cfc0-137e-42e6-8aee-a01eb3525591"
      },
      "source": [
        "!python weight_virtualization.py -mode=a -network_path=obs\n",
        "!python weight_virtualization.py -mode=f -vnn_name=obs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "add_vnn\n",
            "obs/obs_network_weight.npy\n",
            "compute_fisher\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx:  4836\n",
            "sample num:    1, data_idx:  2186\n",
            "sample num:    2, data_idx:  3460\n",
            "sample num:    3, data_idx:  3238\n",
            "sample num:    4, data_idx:  4740\n",
            "sample num:    5, data_idx:  4691\n",
            "sample num:    6, data_idx:  1374\n",
            "sample num:    7, data_idx:   799\n",
            "sample num:    8, data_idx:  2037\n",
            "sample num:    9, data_idx:  5106\n",
            "sample num:   10, data_idx:   637\n",
            "sample num:   11, data_idx:  5396\n",
            "sample num:   12, data_idx:  1609\n",
            "sample num:   13, data_idx:  4936\n",
            "sample num:   14, data_idx:  2953\n",
            "sample num:   15, data_idx:  3175\n",
            "sample num:   16, data_idx:  5490\n",
            "sample num:   17, data_idx:  1600\n",
            "sample num:   18, data_idx:  3483\n",
            "sample num:   19, data_idx:  2272\n",
            "sample num:   20, data_idx:  5647\n",
            "sample num:   21, data_idx:   331\n",
            "sample num:   22, data_idx:   965\n",
            "sample num:   23, data_idx:  4584\n",
            "sample num:   24, data_idx:  1230\n",
            "sample num:   25, data_idx:  3898\n",
            "sample num:   26, data_idx:  5659\n",
            "sample num:   27, data_idx:  3127\n",
            "sample num:   28, data_idx:  2213\n",
            "sample num:   29, data_idx:   681\n",
            "sample num:   30, data_idx:  5505\n",
            "sample num:   31, data_idx:  1759\n",
            "sample num:   32, data_idx:  5549\n",
            "sample num:   33, data_idx:  2168\n",
            "sample num:   34, data_idx:  2785\n",
            "sample num:   35, data_idx:  2469\n",
            "sample num:   36, data_idx:  5533\n",
            "sample num:   37, data_idx:  5280\n",
            "sample num:   38, data_idx:  4289\n",
            "sample num:   39, data_idx:  3866\n",
            "sample num:   40, data_idx:  4954\n",
            "sample num:   41, data_idx:  3135\n",
            "sample num:   42, data_idx:    51\n",
            "sample num:   43, data_idx:  2449\n",
            "sample num:   44, data_idx:   517\n",
            "sample num:   45, data_idx:  2715\n",
            "sample num:   46, data_idx:   359\n",
            "sample num:   47, data_idx:  3254\n",
            "sample num:   48, data_idx:    68\n",
            "sample num:   49, data_idx:  4680\n",
            "sample num:   50, data_idx:  2607\n",
            "sample num:   51, data_idx:   932\n",
            "sample num:   52, data_idx:  1950\n",
            "sample num:   53, data_idx:  3168\n",
            "sample num:   54, data_idx:  1599\n",
            "sample num:   55, data_idx:  2466\n",
            "sample num:   56, data_idx:  3218\n",
            "sample num:   57, data_idx:  5666\n",
            "sample num:   58, data_idx:   460\n",
            "sample num:   59, data_idx:   830\n",
            "sample num:   60, data_idx:  4344\n",
            "sample num:   61, data_idx:  2126\n",
            "sample num:   62, data_idx:  3929\n",
            "sample num:   63, data_idx:  1156\n",
            "sample num:   64, data_idx:   836\n",
            "sample num:   65, data_idx:  4431\n",
            "sample num:   66, data_idx:  2320\n",
            "sample num:   67, data_idx:  4095\n",
            "sample num:   68, data_idx:  4809\n",
            "sample num:   69, data_idx:  5354\n",
            "sample num:   70, data_idx:  1072\n",
            "sample num:   71, data_idx:  4854\n",
            "sample num:   72, data_idx:  4608\n",
            "sample num:   73, data_idx:  4959\n",
            "sample num:   74, data_idx:   413\n",
            "sample num:   75, data_idx:  1826\n",
            "sample num:   76, data_idx:  1183\n",
            "sample num:   77, data_idx:  3007\n",
            "sample num:   78, data_idx:  3767\n",
            "sample num:   79, data_idx:  2797\n",
            "sample num:   80, data_idx:  4092\n",
            "sample num:   81, data_idx:  4947\n",
            "sample num:   82, data_idx:  1279\n",
            "sample num:   83, data_idx:   739\n",
            "sample num:   84, data_idx:   639\n",
            "sample num:   85, data_idx:  3763\n",
            "sample num:   86, data_idx:  1324\n",
            "sample num:   87, data_idx:  1012\n",
            "sample num:   88, data_idx:   403\n",
            "sample num:   89, data_idx:  3937\n",
            "sample num:   90, data_idx:  2727\n",
            "sample num:   91, data_idx:  2512\n",
            "sample num:   92, data_idx:  2816\n",
            "sample num:   93, data_idx:  4790\n",
            "sample num:   94, data_idx:   982\n",
            "sample num:   95, data_idx:  4488\n",
            "sample num:   96, data_idx:  1985\n",
            "sample num:   97, data_idx:  1009\n",
            "sample num:   98, data_idx:  1487\n",
            "sample num:   99, data_idx:  4228\n",
            "obs/obs_network_fisher.npy\n",
            "[match_page_by_cost]\n",
            "occupation: 0\n",
            "len(page_list): 0\n",
            "len(network_page_list): 721\n",
            "cost: 0\n",
            "\n",
            "occupation: 1\n",
            "len(page_list): 529\n",
            "len(network_page_list): 721\n",
            "       0-th page\n",
            "     528-th page\n",
            "cost: 0.393489\n",
            "\n",
            "occupation: 2\n",
            "len(page_list): 192\n",
            "len(network_page_list): 192\n",
            "       0-th page\n",
            "     191-th page\n",
            "cost: 0.00024278136\n",
            "\n",
            "assing_page 151.437 ms\n",
            "[calculate_cost]\n",
            "toal_cost: 0.39373392192572965\n",
            "721 pages allocated for 72012 weights\n",
            "total_network_cost: 17.984374307154212\n",
            "compute_fisher\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx:  1704\n",
            "sample num:    1, data_idx:  4081\n",
            "sample num:    2, data_idx:  4700\n",
            "sample num:    3, data_idx:  5028\n",
            "sample num:    4, data_idx:  4632\n",
            "sample num:    5, data_idx:  5061\n",
            "sample num:    6, data_idx:  1212\n",
            "sample num:    7, data_idx:  2167\n",
            "sample num:    8, data_idx:  5143\n",
            "sample num:    9, data_idx:  4181\n",
            "sample num:   10, data_idx:  1713\n",
            "sample num:   11, data_idx:  4117\n",
            "sample num:   12, data_idx:  4624\n",
            "sample num:   13, data_idx:  1583\n",
            "sample num:   14, data_idx:  1672\n",
            "sample num:   15, data_idx:  1599\n",
            "sample num:   16, data_idx:  5294\n",
            "sample num:   17, data_idx:   457\n",
            "sample num:   18, data_idx:  1429\n",
            "sample num:   19, data_idx:   650\n",
            "sample num:   20, data_idx:   474\n",
            "sample num:   21, data_idx:  1106\n",
            "sample num:   22, data_idx:  4983\n",
            "sample num:   23, data_idx:   184\n",
            "sample num:   24, data_idx:  2408\n",
            "sample num:   25, data_idx:  3044\n",
            "sample num:   26, data_idx:  2232\n",
            "sample num:   27, data_idx:  1211\n",
            "sample num:   28, data_idx:  3944\n",
            "sample num:   29, data_idx:  2756\n",
            "sample num:   30, data_idx:   161\n",
            "sample num:   31, data_idx:  1402\n",
            "sample num:   32, data_idx:  1698\n",
            "sample num:   33, data_idx:  4115\n",
            "sample num:   34, data_idx:  1997\n",
            "sample num:   35, data_idx:  4514\n",
            "sample num:   36, data_idx:  4922\n",
            "sample num:   37, data_idx:  4287\n",
            "sample num:   38, data_idx:   783\n",
            "sample num:   39, data_idx:  5492\n",
            "sample num:   40, data_idx:  1968\n",
            "sample num:   41, data_idx:  4154\n",
            "sample num:   42, data_idx:   144\n",
            "sample num:   43, data_idx:  5425\n",
            "sample num:   44, data_idx:  5407\n",
            "sample num:   45, data_idx:  4402\n",
            "sample num:   46, data_idx:   731\n",
            "sample num:   47, data_idx:  5401\n",
            "sample num:   48, data_idx:  3903\n",
            "sample num:   49, data_idx:  1432\n",
            "sample num:   50, data_idx:  2924\n",
            "sample num:   51, data_idx:  5076\n",
            "sample num:   52, data_idx:  3984\n",
            "sample num:   53, data_idx:   224\n",
            "sample num:   54, data_idx:  4665\n",
            "sample num:   55, data_idx:  1919\n",
            "sample num:   56, data_idx:  3490\n",
            "sample num:   57, data_idx:   363\n",
            "sample num:   58, data_idx:  4618\n",
            "sample num:   59, data_idx:   346\n",
            "sample num:   60, data_idx:  2289\n",
            "sample num:   61, data_idx:  2462\n",
            "sample num:   62, data_idx:  3181\n",
            "sample num:   63, data_idx:  2955\n",
            "sample num:   64, data_idx:  2572\n",
            "sample num:   65, data_idx:  5675\n",
            "sample num:   66, data_idx:  1427\n",
            "sample num:   67, data_idx:  2192\n",
            "sample num:   68, data_idx:  4939\n",
            "sample num:   69, data_idx:   693\n",
            "sample num:   70, data_idx:  1709\n",
            "sample num:   71, data_idx:   176\n",
            "sample num:   72, data_idx:  4978\n",
            "sample num:   73, data_idx:   219\n",
            "sample num:   74, data_idx:   129\n",
            "sample num:   75, data_idx:  4430\n",
            "sample num:   76, data_idx:  2803\n",
            "sample num:   77, data_idx:  2109\n",
            "sample num:   78, data_idx:   418\n",
            "sample num:   79, data_idx:  3320\n",
            "sample num:   80, data_idx:  3823\n",
            "sample num:   81, data_idx:  4717\n",
            "sample num:   82, data_idx:   483\n",
            "sample num:   83, data_idx:  5229\n",
            "sample num:   84, data_idx:  1524\n",
            "sample num:   85, data_idx:  1608\n",
            "sample num:   86, data_idx:  4465\n",
            "sample num:   87, data_idx:  2135\n",
            "sample num:   88, data_idx:  5571\n",
            "sample num:   89, data_idx:  2439\n",
            "sample num:   90, data_idx:  3328\n",
            "sample num:   91, data_idx:  2013\n",
            "sample num:   92, data_idx:  1549\n",
            "sample num:   93, data_idx:   485\n",
            "sample num:   94, data_idx:   262\n",
            "sample num:   95, data_idx:   266\n",
            "sample num:   96, data_idx:  1937\n",
            "sample num:   97, data_idx:  3306\n",
            "sample num:   98, data_idx:  1472\n",
            "sample num:   99, data_idx:  4028\n",
            "obs/obs_fisher.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1eO93mkJ1xf"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzWpiS03DSb3",
        "outputId": "5ef32fdf-185e-4e0f-9e87-051b6588aa88"
      },
      "source": [
        "!python weight_virtualization.py -mode=pf vnn_name=obs"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: weight_virtualization.py [-h] [-mode MODE] [-network_path NETWORK_PATH]\n",
            "                                [-vnn_name VNN_NAME] [-iter ITER]\n",
            "weight_virtualization.py: error: unrecognized arguments: vnn_name=obs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzxBOGKnJNZQ"
      },
      "source": [
        "!touch test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxeRh9a7J9NO",
        "outputId": "4cada3da-c010-4f07-a982-a822bd26e2e5"
      },
      "source": [
        "!python test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Figure size 640x480 with 1 Axes>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K225BEajKPoh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}