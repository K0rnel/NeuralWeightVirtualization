{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TenNets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pq4XZ_IANwN2",
        "outputId": "1760cbb1-2cd1-4163-974e-9ca53515106b"
      },
      "source": [
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow-gpu==1.13.1\n",
        "\n",
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.16.4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.4.0:\n",
            "  Successfully uninstalled tensorflow-2.4.0\n",
            "Collecting tensorflow-gpu==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K     |████████████████████████████████| 345.2MB 30kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.3.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.36.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 48.0MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 60.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.19.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (51.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.10.0)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.4.0)\n",
            "Installing collected packages: tensorboard, keras-applications, mock, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n",
            "Uninstalling numpy-1.19.4:\n",
            "  Successfully uninstalled numpy-1.19.4\n",
            "Collecting numpy==1.16.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 216kB/s \n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "Successfully installed numpy-1.16.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqhh07JKOPQS",
        "outputId": "0777f486-a20c-4d22-865c-7af0c3809925"
      },
      "source": [
        "!git clone https://github.com/K0rnel/NeuralWeightVirtualization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NeuralWeightVirtualization'...\n",
            "remote: Enumerating objects: 201, done.\u001b[K\n",
            "remote: Counting objects: 100% (201/201), done.\u001b[K\n",
            "remote: Compressing objects: 100% (146/146), done.\u001b[K\n",
            "remote: Total 201 (delta 92), reused 147 (delta 50), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (201/201), 11.95 MiB | 38.84 MiB/s, done.\n",
            "Resolving deltas: 100% (92/92), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whmtzJYhOZGf",
        "outputId": "61e9cbc7-e6f1-47b8-c0b8-d580587ddf1a"
      },
      "source": [
        "%cd NeuralWeightVirtualization"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/NeuralWeightVirtualization\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia8tt4ZjOZZ3",
        "outputId": "fe223fda-d252-44e2-a162-310cb884fc82"
      },
      "source": [
        "!sh download_dataset.sh"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1/9] Downloading CIFAR10 dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   3642      0 --:--:-- --:--:-- --:--:--  3642\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  234M    0  234M    0     0  73.6M      0 --:--:--  0:00:03 --:--:--  102M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2550      0 --:--:-- --:--:-- --:--:--  2566\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  781k  100  781k    0     0  2304k      0 --:--:-- --:--:-- --:--:-- 2304k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   4483      0 --:--:-- --:--:-- --:--:--  4483\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1171M    0 1171M    0     0   138M      0 --:--:--  0:00:08 --:--:--  151M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2978      0 --:--:-- --:--:-- --:--:--  2978\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 3906k    0 3906k    0     0  10.6M      0 --:--:-- --:--:-- --:--:-- 10.6M\n",
            "\n",
            "[2/9] Downloading Google Speech Command V2 dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    626      0 --:--:-- --:--:-- --:--:--   625\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 66.5M    0 66.5M    0     0  64.2M      0 --:--:--  0:00:01 --:--:-- 64.2M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   3457      0 --:--:-- --:--:-- --:--:--  3457\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 3009k    0 3009k    0     0  9146k      0 --:--:-- --:--:-- --:--:-- 9146k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   4857      0 --:--:-- --:--:-- --:--:--  4800\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  513M    0  513M    0     0   122M      0 --:--:--  0:00:04 --:--:--  152M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    480      0 --:--:-- --:--:-- --:--:--   479\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 22.6M    0 22.6M    0     0  19.7M      0 --:--:--  0:00:01 --:--:-- 19.7M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    651      0 --:--:-- --:--:-- --:--:--   651\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 60.3M    0 60.3M    0     0  58.0M      0 --:--:--  0:00:01 --:--:-- 58.0M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2813      0 --:--:-- --:--:-- --:--:--  2813\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 2729k    0 2729k    0     0  7911k      0 --:--:-- --:--:-- --:--:-- 7911k\n",
            "\n",
            "[3/9] Downloading GTSRB dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    487      0 --:--:-- --:--:-- --:--:--   486\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 98.6M    0 98.6M    0     0  73.5M      0 --:--:--  0:00:01 --:--:--  267M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    522      0 --:--:-- --:--:-- --:--:--   522\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 4243k    0 4243k    0     0  4230k      0 --:--:--  0:00:01 --:--:-- 4230k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   5100      0 --:--:-- --:--:-- --:--:--  5100\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  306M    0  306M    0     0   106M      0 --:--:--  0:00:02 --:--:--  125M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    528      0 --:--:-- --:--:-- --:--:--   527\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 12.8M    0 12.8M    0     0  11.6M      0 --:--:--  0:00:01 --:--:-- 11.6M\n",
            "\n",
            "[4/9] Downloading SVHN dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   4689      0 --:--:-- --:--:-- --:--:--  4689\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  305M    0  305M    0     0   141M      0 --:--:--  0:00:02 --:--:--  170M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1203      0 --:--:-- --:--:-- --:--:--  1203\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1017k  100 1017k    0     0  1771k      0 --:--:-- --:--:-- --:--:-- 1771k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   3371      0 --:--:-- --:--:-- --:--:--  3371\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  772M    0  772M    0     0  51.6M      0 --:--:--  0:00:14 --:--:-- 33.8M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   3187      0 --:--:-- --:--:-- --:--:--  3187\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 2575k    0 2575k    0     0  7575k      0 --:--:-- --:--:-- --:--:-- 7575k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    187      0 --:--:--  0:00:02 --:--:--   187\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100 85.8M    0 85.8M    0     0  32.8M      0 --:--:--  0:00:02 --:--:--  331M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   3547      0 --:--:-- --:--:-- --:--:--  3547\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  286k  100  286k    0     0   954k      0 --:--:-- --:--:-- --:--:--  954k\n",
            "\n",
            "[5/9] Downloading US8K dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2400      0 --:--:-- --:--:-- --:--:--  2400\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  202M    0  202M    0     0  51.2M      0 --:--:--  0:00:03 --:--:-- 61.0M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    723      0 --:--:-- --:--:-- --:--:--   723\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  422k  100  422k    0     0   563k      0 --:--:-- --:--:-- --:--:--  563k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   4163      0 --:--:-- --:--:-- --:--:--  4121\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1826M    0 1826M    0     0  48.2M      0 --:--:--  0:00:37 --:--:-- 40.9M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2372      0 --:--:-- --:--:-- --:--:--  2358\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 3801k    0 3801k    0     0   9.7M      0 --:--:-- --:--:-- --:--:--  9.7M\n",
            "\n",
            "[6/9] Downloading FMNIST dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    680      0 --:--:-- --:--:-- --:--:--   680\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 59.8M    0 59.8M    0     0  55.1M      0 --:--:--  0:00:01 --:--:--  238M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   3238      0 --:--:-- --:--:-- --:--:--  3238\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  390k  100  390k    0     0  1264k      0 --:--:-- --:--:-- --:--:-- 1264k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   3743      0 --:--:-- --:--:-- --:--:--  3743\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  358M    0  358M    0     0  85.9M      0 --:--:--  0:00:04 --:--:-- 96.1M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    450      0 --:--:-- --:--:-- --:--:--   450\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 2343k    0 2343k    0     0  1988k      0 --:--:--  0:00:01 --:--:-- 1988k\n",
            "\n",
            "[7/9] Downloading HHAR dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    400      0 --:--:--  0:00:01 --:--:--   400\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 21.8M    0 21.8M    0     0  16.7M      0 --:--:--  0:00:01 --:--:--  176M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   3371      0 --:--:-- --:--:-- --:--:--  3371\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 57392  100 57392    0     0   205k      0 --:--:-- --:--:-- --:--:--  205k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   4387      0 --:--:-- --:--:-- --:--:--  4387\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 2180M    0 2180M    0     0  47.4M      0 --:--:--  0:00:45 --:--:-- 39.2M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2472      0 --:--:-- --:--:-- --:--:--  2472\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 5582k    0 5582k    0     0  14.1M      0 --:--:-- --:--:-- --:--:-- 14.1M\n",
            "\n",
            "[8/9] Downloading ESC10 dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    446      0 --:--:-- --:--:-- --:--:--   445\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 26.3M    0 26.3M    0     0  21.9M      0 --:--:--  0:00:01 --:--:--  221M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2305      0 --:--:-- --:--:-- --:--:--  2305\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 28208  100 28208    0     0  85220      0 --:--:-- --:--:-- --:--:-- 85220\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   4039      0 --:--:-- --:--:-- --:--:--  4039\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  237M    0  237M    0     0  75.3M      0 --:--:--  0:00:03 --:--:-- 98.9M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   3457      0 --:--:-- --:--:-- --:--:--  3457\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  246k  100  246k    0     0   724k      0 --:--:-- --:--:-- --:--:-- 7584k\n",
            "\n",
            "[9/9] Downloading OBS dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    640      0 --:--:-- --:--:-- --:--:--   640\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 78.4M    0 78.4M    0     0  75.1M      0 --:--:--  0:00:01 --:--:--  314M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   3547      0 --:--:-- --:--:-- --:--:--  3547\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 91488  100 91488    0     0   258k      0 --:--:-- --:--:-- --:--:-- 1006k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   4434      0 --:--:-- --:--:-- --:--:--  4434\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  156M    0  156M    0     0   125M      0 --:--:--  0:00:01 --:--:--  221M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   3000      0 --:--:-- --:--:-- --:--:--  3022\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  178k  100  178k    0     0   563k      0 --:--:-- --:--:-- --:--:--  563k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    540      0 --:--:-- --:--:-- --:--:--   539\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 78.4M    0 78.4M    0     0  66.3M      0 --:--:--  0:00:01 --:--:-- 66.3M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   3610      0 --:--:-- --:--:-- --:--:--  3610\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 91488  100 91488    0     0   324k      0 --:--:-- --:--:-- --:--:--  324k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f5k0IbPOZhG",
        "outputId": "ffc3c371-7ee9-4564-9656-301c827b19b6"
      },
      "source": [
        "!python weight_virtualization.py -mode=a -network_path=mnist | tee -a mnist_matching_ten_nets.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init new weight pages\n",
            "add_vnn\n",
            "mnist/mnist_network_weight.npy\n",
            "compute_fisher\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx: 41424\n",
            "sample num:    1, data_idx: 41007\n",
            "sample num:    2, data_idx: 49954\n",
            "sample num:    3, data_idx: 11447\n",
            "sample num:    4, data_idx: 42798\n",
            "sample num:    5, data_idx: 18371\n",
            "sample num:    6, data_idx: 51478\n",
            "sample num:    7, data_idx: 10266\n",
            "sample num:    8, data_idx: 11419\n",
            "sample num:    9, data_idx: 31339\n",
            "sample num:   10, data_idx: 54720\n",
            "sample num:   11, data_idx: 45517\n",
            "sample num:   12, data_idx: 29569\n",
            "sample num:   13, data_idx: 25302\n",
            "sample num:   14, data_idx: 45494\n",
            "sample num:   15, data_idx:  5546\n",
            "sample num:   16, data_idx: 50849\n",
            "sample num:   17, data_idx: 48003\n",
            "sample num:   18, data_idx: 27442\n",
            "sample num:   19, data_idx: 40296\n",
            "sample num:   20, data_idx: 21290\n",
            "sample num:   21, data_idx: 43926\n",
            "sample num:   22, data_idx: 36400\n",
            "sample num:   23, data_idx: 21549\n",
            "sample num:   24, data_idx: 52969\n",
            "sample num:   25, data_idx: 40208\n",
            "sample num:   26, data_idx: 23924\n",
            "sample num:   27, data_idx: 44379\n",
            "sample num:   28, data_idx:  7402\n",
            "sample num:   29, data_idx: 53072\n",
            "sample num:   30, data_idx: 12169\n",
            "sample num:   31, data_idx: 13912\n",
            "sample num:   32, data_idx:  1621\n",
            "sample num:   33, data_idx: 44191\n",
            "sample num:   34, data_idx:  4092\n",
            "sample num:   35, data_idx: 32336\n",
            "sample num:   36, data_idx: 39180\n",
            "sample num:   37, data_idx: 37928\n",
            "sample num:   38, data_idx: 35411\n",
            "sample num:   39, data_idx: 10652\n",
            "sample num:   40, data_idx: 33232\n",
            "sample num:   41, data_idx: 37511\n",
            "sample num:   42, data_idx:  8054\n",
            "sample num:   43, data_idx: 31986\n",
            "sample num:   44, data_idx: 36779\n",
            "sample num:   45, data_idx: 54283\n",
            "sample num:   46, data_idx: 44169\n",
            "sample num:   47, data_idx: 41574\n",
            "sample num:   48, data_idx: 43741\n",
            "sample num:   49, data_idx: 26883\n",
            "sample num:   50, data_idx:  9218\n",
            "sample num:   51, data_idx: 10120\n",
            "sample num:   52, data_idx:  1522\n",
            "sample num:   53, data_idx: 34698\n",
            "sample num:   54, data_idx: 37628\n",
            "sample num:   55, data_idx:  1496\n",
            "sample num:   56, data_idx: 14573\n",
            "sample num:   57, data_idx: 31774\n",
            "sample num:   58, data_idx:  2166\n",
            "sample num:   59, data_idx: 44715\n",
            "sample num:   60, data_idx: 35620\n",
            "sample num:   61, data_idx: 12909\n",
            "sample num:   62, data_idx: 24052\n",
            "sample num:   63, data_idx: 28843\n",
            "sample num:   64, data_idx:  3998\n",
            "sample num:   65, data_idx: 45751\n",
            "sample num:   66, data_idx: 48410\n",
            "sample num:   67, data_idx: 50964\n",
            "sample num:   68, data_idx: 39050\n",
            "sample num:   69, data_idx: 20091\n",
            "sample num:   70, data_idx: 17624\n",
            "sample num:   71, data_idx: 54041\n",
            "sample num:   72, data_idx: 32023\n",
            "sample num:   73, data_idx: 32065\n",
            "sample num:   74, data_idx: 46092\n",
            "sample num:   75, data_idx: 43384\n",
            "sample num:   76, data_idx:  8503\n",
            "sample num:   77, data_idx: 18152\n",
            "sample num:   78, data_idx: 30866\n",
            "sample num:   79, data_idx: 52140\n",
            "sample num:   80, data_idx: 31779\n",
            "sample num:   81, data_idx: 29701\n",
            "sample num:   82, data_idx: 24274\n",
            "sample num:   83, data_idx: 33227\n",
            "sample num:   84, data_idx: 22369\n",
            "sample num:   85, data_idx: 22354\n",
            "sample num:   86, data_idx:  1477\n",
            "sample num:   87, data_idx: 53797\n",
            "sample num:   88, data_idx: 51060\n",
            "sample num:   89, data_idx: 16118\n",
            "sample num:   90, data_idx: 34607\n",
            "sample num:   91, data_idx: 25271\n",
            "sample num:   92, data_idx:  1398\n",
            "sample num:   93, data_idx: 16809\n",
            "sample num:   94, data_idx: 49852\n",
            "sample num:   95, data_idx: 48998\n",
            "sample num:   96, data_idx: 23257\n",
            "sample num:   97, data_idx: 26765\n",
            "sample num:   98, data_idx: 46594\n",
            "sample num:   99, data_idx: 46399\n",
            "mnist/mnist_network_fisher.npy\n",
            "[calculate_cost]\n",
            "toal_cost: 0.0\n",
            "458 pages allocated for 45706 weights\n",
            "total_network_cost: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rD_ehpaOZk3",
        "outputId": "ba64b899-85bd-4ac3-9b8f-601cf03954fe"
      },
      "source": [
        "!python weight_virtualization.py -mode=a -network_path=gsc | tee -a gsc_matching_ten_nets.txt\n",
        "!python weight_virtualization.py -mode=a -network_path=gtsrb | tee -a gtsrb_matching_ten_nets.txt\n",
        "!python weight_virtualization.py -mode=a -network_path=cifar10 | tee -a cifar10_matching_ten_nets.txt\n",
        "!python weight_virtualization.py -mode=a -network_path=svhn | tee -a svhn_matching_ten_nets.txt\n",
        "\n",
        "!python weight_virtualization.py -mode=a -network_path=fmnist | tee -a fmnist_matching_ten_nets.txt\n",
        "!python weight_virtualization.py -mode=a -network_path=us8k | tee -a us8k_matching_ten_nets.txt\n",
        "!python weight_virtualization.py -mode=a -network_path=hhar | tee -a hhar_matching_ten_nets.txt\n",
        "!python weight_virtualization.py -mode=a -network_path=esc10 | tee -a esc10_matching_ten_nets.txt\n",
        "!python weight_virtualization.py -mode=a -network_path=obs | tee -a obs_matching_ten_nets.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "add_vnn\n",
            "gsc/gsc_network_weight.npy\n",
            "compute_fisher\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx: 18653\n",
            "sample num:    1, data_idx: 42185\n",
            "sample num:    2, data_idx: 42071\n",
            "sample num:    3, data_idx:  7010\n",
            "sample num:    4, data_idx: 26595\n",
            "sample num:    5, data_idx: 55749\n",
            "sample num:    6, data_idx: 33154\n",
            "sample num:    7, data_idx: 74249\n",
            "sample num:    8, data_idx: 55977\n",
            "sample num:    9, data_idx: 63209\n",
            "sample num:   10, data_idx: 30039\n",
            "sample num:   11, data_idx: 30103\n",
            "sample num:   12, data_idx: 78842\n",
            "sample num:   13, data_idx: 21470\n",
            "sample num:   14, data_idx: 16769\n",
            "sample num:   15, data_idx:  9456\n",
            "sample num:   16, data_idx: 84472\n",
            "sample num:   17, data_idx: 26752\n",
            "sample num:   18, data_idx: 83991\n",
            "sample num:   19, data_idx: 51042\n",
            "sample num:   20, data_idx: 41113\n",
            "sample num:   21, data_idx: 74238\n",
            "sample num:   22, data_idx:  2317\n",
            "sample num:   23, data_idx: 83304\n",
            "sample num:   24, data_idx: 80171\n",
            "sample num:   25, data_idx: 65999\n",
            "sample num:   26, data_idx: 71506\n",
            "sample num:   27, data_idx: 82901\n",
            "sample num:   28, data_idx: 37847\n",
            "sample num:   29, data_idx: 64084\n",
            "sample num:   30, data_idx:  1460\n",
            "sample num:   31, data_idx: 54046\n",
            "sample num:   32, data_idx: 38298\n",
            "sample num:   33, data_idx: 27634\n",
            "sample num:   34, data_idx: 46336\n",
            "sample num:   35, data_idx: 78967\n",
            "sample num:   36, data_idx: 49122\n",
            "sample num:   37, data_idx: 15189\n",
            "sample num:   38, data_idx: 13423\n",
            "sample num:   39, data_idx: 19580\n",
            "sample num:   40, data_idx: 76836\n",
            "sample num:   41, data_idx: 34636\n",
            "sample num:   42, data_idx:  1934\n",
            "sample num:   43, data_idx: 48043\n",
            "sample num:   44, data_idx: 67446\n",
            "sample num:   45, data_idx: 14704\n",
            "sample num:   46, data_idx: 74124\n",
            "sample num:   47, data_idx: 39259\n",
            "sample num:   48, data_idx:  9940\n",
            "sample num:   49, data_idx: 30968\n",
            "sample num:   50, data_idx: 41228\n",
            "sample num:   51, data_idx: 22304\n",
            "sample num:   52, data_idx: 44952\n",
            "sample num:   53, data_idx: 42853\n",
            "sample num:   54, data_idx: 58055\n",
            "sample num:   55, data_idx: 72910\n",
            "sample num:   56, data_idx: 14784\n",
            "sample num:   57, data_idx: 70377\n",
            "sample num:   58, data_idx: 72755\n",
            "sample num:   59, data_idx: 25456\n",
            "sample num:   60, data_idx: 68073\n",
            "sample num:   61, data_idx: 46787\n",
            "sample num:   62, data_idx: 56767\n",
            "sample num:   63, data_idx: 61753\n",
            "sample num:   64, data_idx: 67132\n",
            "sample num:   65, data_idx: 17914\n",
            "sample num:   66, data_idx: 42790\n",
            "sample num:   67, data_idx: 54785\n",
            "sample num:   68, data_idx: 60488\n",
            "sample num:   69, data_idx: 42531\n",
            "sample num:   70, data_idx: 25276\n",
            "sample num:   71, data_idx: 55051\n",
            "sample num:   72, data_idx: 19901\n",
            "sample num:   73, data_idx: 29885\n",
            "sample num:   74, data_idx: 49280\n",
            "sample num:   75, data_idx: 58048\n",
            "sample num:   76, data_idx: 27345\n",
            "sample num:   77, data_idx: 36996\n",
            "sample num:   78, data_idx:  4507\n",
            "sample num:   79, data_idx: 82472\n",
            "sample num:   80, data_idx: 70736\n",
            "sample num:   81, data_idx:  7930\n",
            "sample num:   82, data_idx: 26076\n",
            "sample num:   83, data_idx:   715\n",
            "sample num:   84, data_idx: 22949\n",
            "sample num:   85, data_idx: 83025\n",
            "sample num:   86, data_idx: 31394\n",
            "sample num:   87, data_idx: 81471\n",
            "sample num:   88, data_idx:  1473\n",
            "sample num:   89, data_idx: 70899\n",
            "sample num:   90, data_idx: 17642\n",
            "sample num:   91, data_idx:  9822\n",
            "sample num:   92, data_idx:  7855\n",
            "sample num:   93, data_idx: 49131\n",
            "sample num:   94, data_idx:  9078\n",
            "sample num:   95, data_idx:  9554\n",
            "sample num:   96, data_idx: 36381\n",
            "sample num:   97, data_idx: 74619\n",
            "sample num:   98, data_idx: 18742\n",
            "sample num:   99, data_idx: 80332\n",
            "gsc/gsc_network_fisher.npy\n",
            "[match_page_by_cost]\n",
            "occupation: 0\n",
            "len(page_list): 263\n",
            "len(network_page_list): 656\n",
            "cost: 0.0\n",
            "\n",
            "occupation: 1\n",
            "len(page_list): 458\n",
            "len(network_page_list): 393\n",
            "cost: 0.005828534\n",
            "\n",
            "assing_page 272.485 ms\n",
            "[calculate_cost]\n",
            "toal_cost: 0.005829093428701526\n",
            "656 pages allocated for 65531 weights\n",
            "total_network_cost: 0.01178106851875782\n",
            "       0-th page\n",
            "     262-th page\n",
            "       0-th page\n",
            "     392-th page\n",
            "add_vnn\n",
            "gtsrb/gtsrb_network_weight.npy\n",
            "compute_fisher\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx: 36287\n",
            "sample num:    1, data_idx: 23796\n",
            "sample num:    2, data_idx: 23903\n",
            "sample num:    3, data_idx: 24965\n",
            "sample num:    4, data_idx: 18880\n",
            "sample num:    5, data_idx:  3083\n",
            "sample num:    6, data_idx: 22710\n",
            "sample num:    7, data_idx: 25817\n",
            "sample num:    8, data_idx: 17305\n",
            "sample num:    9, data_idx:  7361\n",
            "sample num:   10, data_idx: 18123\n",
            "sample num:   11, data_idx:  3706\n",
            "sample num:   12, data_idx:  5450\n",
            "sample num:   13, data_idx: 23465\n",
            "sample num:   14, data_idx:  1157\n",
            "sample num:   15, data_idx: 26965\n",
            "sample num:   16, data_idx: 14395\n",
            "sample num:   17, data_idx: 22833\n",
            "sample num:   18, data_idx:  1420\n",
            "sample num:   19, data_idx:     8\n",
            "sample num:   20, data_idx: 33148\n",
            "sample num:   21, data_idx: 26717\n",
            "sample num:   22, data_idx: 13620\n",
            "sample num:   23, data_idx: 25185\n",
            "sample num:   24, data_idx: 29568\n",
            "sample num:   25, data_idx: 20863\n",
            "sample num:   26, data_idx:  3070\n",
            "sample num:   27, data_idx:  1336\n",
            "sample num:   28, data_idx: 26040\n",
            "sample num:   29, data_idx: 21297\n",
            "sample num:   30, data_idx: 11422\n",
            "sample num:   31, data_idx: 28599\n",
            "sample num:   32, data_idx:  1014\n",
            "sample num:   33, data_idx: 33519\n",
            "sample num:   34, data_idx: 19184\n",
            "sample num:   35, data_idx: 27424\n",
            "sample num:   36, data_idx: 26652\n",
            "sample num:   37, data_idx: 13055\n",
            "sample num:   38, data_idx: 22627\n",
            "sample num:   39, data_idx: 12179\n",
            "sample num:   40, data_idx: 16811\n",
            "sample num:   41, data_idx: 26334\n",
            "sample num:   42, data_idx: 21070\n",
            "sample num:   43, data_idx: 27171\n",
            "sample num:   44, data_idx: 17686\n",
            "sample num:   45, data_idx:  8734\n",
            "sample num:   46, data_idx: 18395\n",
            "sample num:   47, data_idx: 26957\n",
            "sample num:   48, data_idx:  3277\n",
            "sample num:   49, data_idx: 31965\n",
            "sample num:   50, data_idx:  9951\n",
            "sample num:   51, data_idx: 31731\n",
            "sample num:   52, data_idx: 24895\n",
            "sample num:   53, data_idx: 36228\n",
            "sample num:   54, data_idx: 23188\n",
            "sample num:   55, data_idx:  3945\n",
            "sample num:   56, data_idx: 34909\n",
            "sample num:   57, data_idx: 21083\n",
            "sample num:   58, data_idx: 26755\n",
            "sample num:   59, data_idx: 15058\n",
            "sample num:   60, data_idx: 10856\n",
            "sample num:   61, data_idx: 13655\n",
            "sample num:   62, data_idx: 28474\n",
            "sample num:   63, data_idx: 31588\n",
            "sample num:   64, data_idx: 31734\n",
            "sample num:   65, data_idx: 31800\n",
            "sample num:   66, data_idx: 23195\n",
            "sample num:   67, data_idx: 33022\n",
            "sample num:   68, data_idx: 23273\n",
            "sample num:   69, data_idx:  6094\n",
            "sample num:   70, data_idx: 24333\n",
            "sample num:   71, data_idx: 10974\n",
            "sample num:   72, data_idx: 33107\n",
            "sample num:   73, data_idx:  2768\n",
            "sample num:   74, data_idx: 19324\n",
            "sample num:   75, data_idx:  5040\n",
            "sample num:   76, data_idx: 30011\n",
            "sample num:   77, data_idx: 26118\n",
            "sample num:   78, data_idx: 16377\n",
            "sample num:   79, data_idx: 17346\n",
            "sample num:   80, data_idx: 20019\n",
            "sample num:   81, data_idx: 29084\n",
            "sample num:   82, data_idx: 13694\n",
            "sample num:   83, data_idx: 36663\n",
            "sample num:   84, data_idx: 32940\n",
            "sample num:   85, data_idx:  8812\n",
            "sample num:   86, data_idx: 27071\n",
            "sample num:   87, data_idx: 21273\n",
            "sample num:   88, data_idx:  3004\n",
            "sample num:   89, data_idx: 30078\n",
            "sample num:   90, data_idx: 23408\n",
            "sample num:   91, data_idx: 10837\n",
            "sample num:   92, data_idx: 25911\n",
            "sample num:   93, data_idx: 19381\n",
            "sample num:   94, data_idx:  6339\n",
            "sample num:   95, data_idx: 37789\n",
            "sample num:   96, data_idx:  3908\n",
            "sample num:   97, data_idx: 28884\n",
            "sample num:   98, data_idx: 11815\n",
            "sample num:   99, data_idx: 36866\n",
            "gtsrb/gtsrb_network_fisher.npy\n",
            "[match_page_by_cost]\n",
            "occupation: 0\n",
            "len(page_list): 0\n",
            "len(network_page_list): 665\n",
            "cost: 0\n",
            "\n",
            "occupation: 1\n",
            "len(page_list): 328\n",
            "len(network_page_list): 665\n",
            "cost: 1.702558\n",
            "\n",
            "occupation: 2\n",
            "len(page_list): 393\n",
            "len(network_page_list): 337\n",
            "cost: 0.004514666\n",
            "\n",
            "assing_page 135.868 ms\n",
            "[calculate_cost]\n",
            "toal_cost: 1.707354855896483\n",
            "665 pages allocated for 66475 weights\n",
            "total_network_cost: 6.769909771159291\n",
            "       0-th page\n",
            "     327-th page\n",
            "       0-th page\n",
            "     336-th page\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x1f7e0000 @  0x7ffb7f18d1e7 0x7ffb7cad6ca1 0x7ffb7cb409c5 0x7ffb7cb4155e 0x7ffb7cbdaa6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "add_vnn\n",
            "cifar10/cifar10_network_weight.npy\n",
            "compute_fisher\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx:  7993\n",
            "sample num:    1, data_idx:  9542\n",
            "sample num:    2, data_idx: 45377\n",
            "sample num:    3, data_idx: 41356\n",
            "sample num:    4, data_idx: 28867\n",
            "sample num:    5, data_idx: 21696\n",
            "sample num:    6, data_idx:  7258\n",
            "sample num:    7, data_idx: 29833\n",
            "sample num:    8, data_idx:  5669\n",
            "sample num:    9, data_idx: 49117\n",
            "sample num:   10, data_idx: 23526\n",
            "sample num:   11, data_idx: 46608\n",
            "sample num:   12, data_idx: 10248\n",
            "sample num:   13, data_idx: 25986\n",
            "sample num:   14, data_idx: 15818\n",
            "sample num:   15, data_idx: 39789\n",
            "sample num:   16, data_idx: 18968\n",
            "sample num:   17, data_idx:  4105\n",
            "sample num:   18, data_idx:  7079\n",
            "sample num:   19, data_idx: 46602\n",
            "sample num:   20, data_idx: 23820\n",
            "sample num:   21, data_idx: 27168\n",
            "sample num:   22, data_idx: 18855\n",
            "sample num:   23, data_idx: 46959\n",
            "sample num:   24, data_idx:  3475\n",
            "sample num:   25, data_idx: 49164\n",
            "sample num:   26, data_idx:  7231\n",
            "sample num:   27, data_idx: 30884\n",
            "sample num:   28, data_idx: 43272\n",
            "sample num:   29, data_idx:  8909\n",
            "sample num:   30, data_idx: 22730\n",
            "sample num:   31, data_idx: 17587\n",
            "sample num:   32, data_idx:  5818\n",
            "sample num:   33, data_idx: 29638\n",
            "sample num:   34, data_idx:  8296\n",
            "sample num:   35, data_idx:  7992\n",
            "sample num:   36, data_idx: 25634\n",
            "sample num:   37, data_idx: 30777\n",
            "sample num:   38, data_idx:  1968\n",
            "sample num:   39, data_idx:  8625\n",
            "sample num:   40, data_idx:  7232\n",
            "sample num:   41, data_idx: 31144\n",
            "sample num:   42, data_idx: 41416\n",
            "sample num:   43, data_idx: 26165\n",
            "sample num:   44, data_idx: 41450\n",
            "sample num:   45, data_idx: 14025\n",
            "sample num:   46, data_idx: 17035\n",
            "sample num:   47, data_idx: 27532\n",
            "sample num:   48, data_idx: 29674\n",
            "sample num:   49, data_idx: 13815\n",
            "sample num:   50, data_idx: 45329\n",
            "sample num:   51, data_idx:  1550\n",
            "sample num:   52, data_idx: 47499\n",
            "sample num:   53, data_idx: 37719\n",
            "sample num:   54, data_idx: 11865\n",
            "sample num:   55, data_idx: 28846\n",
            "sample num:   56, data_idx:  9573\n",
            "sample num:   57, data_idx: 37592\n",
            "sample num:   58, data_idx: 18890\n",
            "sample num:   59, data_idx:  3662\n",
            "sample num:   60, data_idx: 26760\n",
            "sample num:   61, data_idx:  5049\n",
            "sample num:   62, data_idx: 31191\n",
            "sample num:   63, data_idx: 30195\n",
            "sample num:   64, data_idx:   147\n",
            "sample num:   65, data_idx: 10329\n",
            "sample num:   66, data_idx: 40782\n",
            "sample num:   67, data_idx: 40462\n",
            "sample num:   68, data_idx: 22343\n",
            "sample num:   69, data_idx:  7630\n",
            "sample num:   70, data_idx: 47017\n",
            "sample num:   71, data_idx: 41306\n",
            "sample num:   72, data_idx: 17430\n",
            "sample num:   73, data_idx: 23986\n",
            "sample num:   74, data_idx: 48615\n",
            "sample num:   75, data_idx:  5061\n",
            "sample num:   76, data_idx:  7345\n",
            "sample num:   77, data_idx: 17108\n",
            "sample num:   78, data_idx:  7069\n",
            "sample num:   79, data_idx: 33403\n",
            "sample num:   80, data_idx: 23660\n",
            "sample num:   81, data_idx: 37323\n",
            "sample num:   82, data_idx: 35955\n",
            "sample num:   83, data_idx:  5464\n",
            "sample num:   84, data_idx: 16488\n",
            "sample num:   85, data_idx: 35970\n",
            "sample num:   86, data_idx: 23067\n",
            "sample num:   87, data_idx: 28689\n",
            "sample num:   88, data_idx:  5545\n",
            "sample num:   89, data_idx: 40346\n",
            "sample num:   90, data_idx: 38604\n",
            "sample num:   91, data_idx: 22740\n",
            "sample num:   92, data_idx: 49769\n",
            "sample num:   93, data_idx: 12294\n",
            "sample num:   94, data_idx: 32288\n",
            "sample num:   95, data_idx:  7008\n",
            "sample num:   96, data_idx: 12240\n",
            "sample num:   97, data_idx: 43574\n",
            "sample num:   98, data_idx:  5637\n",
            "sample num:   99, data_idx:  2509\n",
            "cifar10/cifar10_network_fisher.npy\n",
            "[match_page_by_cost]\n",
            "occupation: 0\n",
            "len(page_list): 0\n",
            "len(network_page_list): 455\n",
            "cost: 0\n",
            "\n",
            "occupation: 1\n",
            "len(page_list): 0\n",
            "len(network_page_list): 455\n",
            "cost: 0\n",
            "\n",
            "occupation: 2\n",
            "len(page_list): 384\n",
            "len(network_page_list): 455\n",
            "cost: 16.461798\n",
            "\n",
            "occupation: 3\n",
            "len(page_list): 337\n",
            "len(network_page_list): 71\n",
            "cost: 0.00058196374\n",
            "\n",
            "assing_page 109.869 ms\n",
            "[calculate_cost]\n",
            "toal_cost: 16.462681311351844\n",
            "455 pages allocated for 45490 weights\n",
            "total_network_cost: 66.82044497318566\n",
            "       0-th page\n",
            "     383-th page\n",
            "       0-th page\n",
            "      70-th page\n",
            "add_vnn\n",
            "svhn/svhn_network_weight.npy\n",
            "compute_fisher\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx: 26544\n",
            "sample num:    1, data_idx: 64925\n",
            "sample num:    2, data_idx: 61915\n",
            "sample num:    3, data_idx: 29363\n",
            "sample num:    4, data_idx: 22928\n",
            "sample num:    5, data_idx: 59203\n",
            "sample num:    6, data_idx:  2544\n",
            "sample num:    7, data_idx:   589\n",
            "sample num:    8, data_idx: 54133\n",
            "sample num:    9, data_idx: 18958\n",
            "sample num:   10, data_idx: 41075\n",
            "sample num:   11, data_idx: 46469\n",
            "sample num:   12, data_idx: 17842\n",
            "sample num:   13, data_idx: 19471\n",
            "sample num:   14, data_idx:  1737\n",
            "sample num:   15, data_idx: 56757\n",
            "sample num:   16, data_idx: 30929\n",
            "sample num:   17, data_idx: 15713\n",
            "sample num:   18, data_idx: 46872\n",
            "sample num:   19, data_idx: 31411\n",
            "sample num:   20, data_idx:   420\n",
            "sample num:   21, data_idx: 35976\n",
            "sample num:   22, data_idx: 33513\n",
            "sample num:   23, data_idx: 30911\n",
            "sample num:   24, data_idx: 31395\n",
            "sample num:   25, data_idx: 18866\n",
            "sample num:   26, data_idx:  2842\n",
            "sample num:   27, data_idx: 51089\n",
            "sample num:   28, data_idx: 56593\n",
            "sample num:   29, data_idx: 27888\n",
            "sample num:   30, data_idx: 59940\n",
            "sample num:   31, data_idx:   106\n",
            "sample num:   32, data_idx: 24334\n",
            "sample num:   33, data_idx: 29802\n",
            "sample num:   34, data_idx: 15642\n",
            "sample num:   35, data_idx: 38122\n",
            "sample num:   36, data_idx: 19927\n",
            "sample num:   37, data_idx: 65369\n",
            "sample num:   38, data_idx:  6847\n",
            "sample num:   39, data_idx: 39300\n",
            "sample num:   40, data_idx: 41893\n",
            "sample num:   41, data_idx:  3952\n",
            "sample num:   42, data_idx:   776\n",
            "sample num:   43, data_idx: 38008\n",
            "sample num:   44, data_idx: 55414\n",
            "sample num:   45, data_idx: 22942\n",
            "sample num:   46, data_idx: 16383\n",
            "sample num:   47, data_idx: 41382\n",
            "sample num:   48, data_idx: 21564\n",
            "sample num:   49, data_idx: 15957\n",
            "sample num:   50, data_idx: 54377\n",
            "sample num:   51, data_idx: 54594\n",
            "sample num:   52, data_idx: 65576\n",
            "sample num:   53, data_idx: 25290\n",
            "sample num:   54, data_idx: 22028\n",
            "sample num:   55, data_idx: 24147\n",
            "sample num:   56, data_idx: 63084\n",
            "sample num:   57, data_idx: 24059\n",
            "sample num:   58, data_idx:   434\n",
            "sample num:   59, data_idx: 38375\n",
            "sample num:   60, data_idx:  9336\n",
            "sample num:   61, data_idx: 58131\n",
            "sample num:   62, data_idx: 51622\n",
            "sample num:   63, data_idx:  3651\n",
            "sample num:   64, data_idx: 42512\n",
            "sample num:   65, data_idx: 43745\n",
            "sample num:   66, data_idx: 11592\n",
            "sample num:   67, data_idx: 60516\n",
            "sample num:   68, data_idx: 55750\n",
            "sample num:   69, data_idx: 35777\n",
            "sample num:   70, data_idx: 39300\n",
            "sample num:   71, data_idx: 59344\n",
            "sample num:   72, data_idx: 27143\n",
            "sample num:   73, data_idx: 18505\n",
            "sample num:   74, data_idx:  7332\n",
            "sample num:   75, data_idx:  6018\n",
            "sample num:   76, data_idx: 34108\n",
            "sample num:   77, data_idx: 20720\n",
            "sample num:   78, data_idx: 65141\n",
            "sample num:   79, data_idx: 25988\n",
            "sample num:   80, data_idx:   797\n",
            "sample num:   81, data_idx: 48198\n",
            "sample num:   82, data_idx: 43051\n",
            "sample num:   83, data_idx: 12623\n",
            "sample num:   84, data_idx:   511\n",
            "sample num:   85, data_idx: 41662\n",
            "sample num:   86, data_idx: 14680\n",
            "sample num:   87, data_idx: 26420\n",
            "sample num:   88, data_idx: 23230\n",
            "sample num:   89, data_idx: 40474\n",
            "sample num:   90, data_idx: 35836\n",
            "sample num:   91, data_idx:  8416\n",
            "sample num:   92, data_idx: 28928\n",
            "sample num:   93, data_idx:  5325\n",
            "sample num:   94, data_idx: 41777\n",
            "sample num:   95, data_idx: 55046\n",
            "sample num:   96, data_idx: 27193\n",
            "sample num:   97, data_idx:    94\n",
            "sample num:   98, data_idx:  5570\n",
            "sample num:   99, data_idx: 59585\n",
            "svhn/svhn_network_fisher.npy\n",
            "[match_page_by_cost]\n",
            "occupation: 0\n",
            "len(page_list): 0\n",
            "len(network_page_list): 455\n",
            "cost: 0\n",
            "\n",
            "occupation: 1\n",
            "len(page_list): 0\n",
            "len(network_page_list): 455\n",
            "cost: 0\n",
            "\n",
            "occupation: 2\n",
            "len(page_list): 0\n",
            "len(network_page_list): 455\n",
            "cost: 0\n",
            "\n",
            "occupation: 3\n",
            "len(page_list): 650\n",
            "len(network_page_list): 455\n",
            "cost: 5.068161\n",
            "\n",
            "assing_page 98.579 ms\n",
            "[calculate_cost]\n",
            "toal_cost: 5.06817642615988\n",
            "455 pages allocated for 45490 weights\n",
            "total_network_cost: 90.31879177875817\n",
            "       0-th page\n",
            "     454-th page\n",
            "add_vnn\n",
            "fmnist/fmnist_network_weight.npy\n",
            "compute_fisher\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx: 14480\n",
            "sample num:    1, data_idx: 43827\n",
            "sample num:    2, data_idx: 54862\n",
            "sample num:    3, data_idx: 14521\n",
            "sample num:    4, data_idx:  4830\n",
            "sample num:    5, data_idx: 20269\n",
            "sample num:    6, data_idx: 47657\n",
            "sample num:    7, data_idx:  5755\n",
            "sample num:    8, data_idx: 45477\n",
            "sample num:    9, data_idx: 19956\n",
            "sample num:   10, data_idx: 50195\n",
            "sample num:   11, data_idx: 18146\n",
            "sample num:   12, data_idx: 20792\n",
            "sample num:   13, data_idx: 42388\n",
            "sample num:   14, data_idx: 56386\n",
            "sample num:   15, data_idx: 33489\n",
            "sample num:   16, data_idx: 15805\n",
            "sample num:   17, data_idx: 16348\n",
            "sample num:   18, data_idx: 45545\n",
            "sample num:   19, data_idx: 26949\n",
            "sample num:   20, data_idx: 13207\n",
            "sample num:   21, data_idx:  9377\n",
            "sample num:   22, data_idx: 59526\n",
            "sample num:   23, data_idx: 55097\n",
            "sample num:   24, data_idx: 27105\n",
            "sample num:   25, data_idx: 30559\n",
            "sample num:   26, data_idx: 23208\n",
            "sample num:   27, data_idx: 39170\n",
            "sample num:   28, data_idx: 12632\n",
            "sample num:   29, data_idx: 53958\n",
            "sample num:   30, data_idx: 46384\n",
            "sample num:   31, data_idx: 15081\n",
            "sample num:   32, data_idx:  1933\n",
            "sample num:   33, data_idx:  5311\n",
            "sample num:   34, data_idx: 38533\n",
            "sample num:   35, data_idx: 37043\n",
            "sample num:   36, data_idx: 24470\n",
            "sample num:   37, data_idx: 50891\n",
            "sample num:   38, data_idx:  6766\n",
            "sample num:   39, data_idx: 20942\n",
            "sample num:   40, data_idx: 25853\n",
            "sample num:   41, data_idx: 34783\n",
            "sample num:   42, data_idx: 26516\n",
            "sample num:   43, data_idx: 56470\n",
            "sample num:   44, data_idx: 39926\n",
            "sample num:   45, data_idx: 32043\n",
            "sample num:   46, data_idx: 21335\n",
            "sample num:   47, data_idx: 56325\n",
            "sample num:   48, data_idx: 52633\n",
            "sample num:   49, data_idx: 25625\n",
            "sample num:   50, data_idx: 49566\n",
            "sample num:   51, data_idx: 31887\n",
            "sample num:   52, data_idx: 37427\n",
            "sample num:   53, data_idx: 59567\n",
            "sample num:   54, data_idx: 59646\n",
            "sample num:   55, data_idx: 52084\n",
            "sample num:   56, data_idx: 43816\n",
            "sample num:   57, data_idx:  6714\n",
            "sample num:   58, data_idx: 58060\n",
            "sample num:   59, data_idx:   641\n",
            "sample num:   60, data_idx: 31949\n",
            "sample num:   61, data_idx: 45343\n",
            "sample num:   62, data_idx: 11632\n",
            "sample num:   63, data_idx: 46591\n",
            "sample num:   64, data_idx: 50748\n",
            "sample num:   65, data_idx: 18321\n",
            "sample num:   66, data_idx:  1771\n",
            "sample num:   67, data_idx: 56354\n",
            "sample num:   68, data_idx: 31923\n",
            "sample num:   69, data_idx:  9643\n",
            "sample num:   70, data_idx:  4378\n",
            "sample num:   71, data_idx: 24821\n",
            "sample num:   72, data_idx: 37137\n",
            "sample num:   73, data_idx: 36280\n",
            "sample num:   74, data_idx: 31377\n",
            "sample num:   75, data_idx: 23913\n",
            "sample num:   76, data_idx: 18319\n",
            "sample num:   77, data_idx: 40087\n",
            "sample num:   78, data_idx: 44126\n",
            "sample num:   79, data_idx: 56343\n",
            "sample num:   80, data_idx: 27039\n",
            "sample num:   81, data_idx: 42897\n",
            "sample num:   82, data_idx:   110\n",
            "sample num:   83, data_idx: 59261\n",
            "sample num:   84, data_idx: 25018\n",
            "sample num:   85, data_idx:  8870\n",
            "sample num:   86, data_idx: 19905\n",
            "sample num:   87, data_idx: 10408\n",
            "sample num:   88, data_idx: 55779\n",
            "sample num:   89, data_idx: 30891\n",
            "sample num:   90, data_idx: 56053\n",
            "sample num:   91, data_idx: 48408\n",
            "sample num:   92, data_idx: 46956\n",
            "sample num:   93, data_idx: 15479\n",
            "sample num:   94, data_idx: 17498\n",
            "sample num:   95, data_idx:  3058\n",
            "sample num:   96, data_idx: 30750\n",
            "sample num:   97, data_idx: 37910\n",
            "sample num:   98, data_idx: 22415\n",
            "sample num:   99, data_idx:  5360\n",
            "fmnist/fmnist_network_fisher.npy\n",
            "[match_page_by_cost]\n",
            "occupation: 0\n",
            "len(page_list): 0\n",
            "len(network_page_list): 700\n",
            "cost: 0\n",
            "\n",
            "occupation: 1\n",
            "len(page_list): 0\n",
            "len(network_page_list): 700\n",
            "cost: 0\n",
            "\n",
            "occupation: 2\n",
            "len(page_list): 0\n",
            "len(network_page_list): 700\n",
            "cost: 0\n",
            "\n",
            "occupation: 3\n",
            "len(page_list): 195\n",
            "len(network_page_list): 700\n",
            "cost: 2.8814466\n",
            "\n",
            "occupation: 4\n",
            "len(page_list): 526\n",
            "len(network_page_list): 505\n",
            "cost: 0.036928706\n",
            "\n",
            "assing_page 155.312 ms\n",
            "[calculate_cost]\n",
            "toal_cost: 2.918409009192146\n",
            "700 pages allocated for 69966 weights\n",
            "total_network_cost: 120.3590757586062\n",
            "       0-th page\n",
            "     194-th page\n",
            "       0-th page\n",
            "     504-th page\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x20dc6000 @  0x7faa670be1e7 0x7faa64a07ca1 0x7faa64a719c5 0x7faa64a7255e 0x7faa64b0ba6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "add_vnn\n",
            "us8k/us8k_network_weight.npy\n",
            "compute_fisher\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx: 24134\n",
            "sample num:    1, data_idx: 25025\n",
            "sample num:    2, data_idx: 18782\n",
            "sample num:    3, data_idx: 16023\n",
            "sample num:    4, data_idx: 13321\n",
            "sample num:    5, data_idx:  2012\n",
            "sample num:    6, data_idx:  3123\n",
            "sample num:    7, data_idx: 29896\n",
            "sample num:    8, data_idx:  4851\n",
            "sample num:    9, data_idx: 13635\n",
            "sample num:   10, data_idx:  8160\n",
            "sample num:   11, data_idx: 15598\n",
            "sample num:   12, data_idx: 43303\n",
            "sample num:   13, data_idx:    83\n",
            "sample num:   14, data_idx: 44723\n",
            "sample num:   15, data_idx: 48210\n",
            "sample num:   16, data_idx: 18532\n",
            "sample num:   17, data_idx: 28428\n",
            "sample num:   18, data_idx: 44840\n",
            "sample num:   19, data_idx:  6642\n",
            "sample num:   20, data_idx:  1656\n",
            "sample num:   21, data_idx:  9710\n",
            "sample num:   22, data_idx: 26673\n",
            "sample num:   23, data_idx:  6165\n",
            "sample num:   24, data_idx: 42228\n",
            "sample num:   25, data_idx: 13457\n",
            "sample num:   26, data_idx: 39684\n",
            "sample num:   27, data_idx: 22500\n",
            "sample num:   28, data_idx: 17111\n",
            "sample num:   29, data_idx: 17212\n",
            "sample num:   30, data_idx: 33798\n",
            "sample num:   31, data_idx: 21884\n",
            "sample num:   32, data_idx: 38994\n",
            "sample num:   33, data_idx: 23544\n",
            "sample num:   34, data_idx: 42061\n",
            "sample num:   35, data_idx: 48376\n",
            "sample num:   36, data_idx: 23037\n",
            "sample num:   37, data_idx: 42449\n",
            "sample num:   38, data_idx:  1467\n",
            "sample num:   39, data_idx: 15885\n",
            "sample num:   40, data_idx: 34845\n",
            "sample num:   41, data_idx:   751\n",
            "sample num:   42, data_idx: 39995\n",
            "sample num:   43, data_idx: 41067\n",
            "sample num:   44, data_idx: 19742\n",
            "sample num:   45, data_idx: 39048\n",
            "sample num:   46, data_idx: 16672\n",
            "sample num:   47, data_idx: 25270\n",
            "sample num:   48, data_idx: 32310\n",
            "sample num:   49, data_idx: 19166\n",
            "sample num:   50, data_idx: 39270\n",
            "sample num:   51, data_idx: 35267\n",
            "sample num:   52, data_idx: 38856\n",
            "sample num:   53, data_idx: 28180\n",
            "sample num:   54, data_idx: 31085\n",
            "sample num:   55, data_idx: 43843\n",
            "sample num:   56, data_idx: 18268\n",
            "sample num:   57, data_idx: 12481\n",
            "sample num:   58, data_idx: 33250\n",
            "sample num:   59, data_idx: 44773\n",
            "sample num:   60, data_idx:  7802\n",
            "sample num:   61, data_idx:   694\n",
            "sample num:   62, data_idx: 45406\n",
            "sample num:   63, data_idx: 27788\n",
            "sample num:   64, data_idx: 39266\n",
            "sample num:   65, data_idx: 48190\n",
            "sample num:   66, data_idx: 17424\n",
            "sample num:   67, data_idx:  6224\n",
            "sample num:   68, data_idx: 21768\n",
            "sample num:   69, data_idx: 18854\n",
            "sample num:   70, data_idx: 44801\n",
            "sample num:   71, data_idx: 34216\n",
            "sample num:   72, data_idx: 13616\n",
            "sample num:   73, data_idx: 18981\n",
            "sample num:   74, data_idx: 43543\n",
            "sample num:   75, data_idx: 31181\n",
            "sample num:   76, data_idx: 18057\n",
            "sample num:   77, data_idx: 47248\n",
            "sample num:   78, data_idx: 16255\n",
            "sample num:   79, data_idx: 33745\n",
            "sample num:   80, data_idx: 39889\n",
            "sample num:   81, data_idx: 16113\n",
            "sample num:   82, data_idx: 42948\n",
            "sample num:   83, data_idx: 10256\n",
            "sample num:   84, data_idx:  1262\n",
            "sample num:   85, data_idx:   777\n",
            "sample num:   86, data_idx: 24577\n",
            "sample num:   87, data_idx:  1141\n",
            "sample num:   88, data_idx:  2791\n",
            "sample num:   89, data_idx: 16473\n",
            "sample num:   90, data_idx: 39706\n",
            "sample num:   91, data_idx: 19938\n",
            "sample num:   92, data_idx: 19590\n",
            "sample num:   93, data_idx: 11113\n",
            "sample num:   94, data_idx: 33952\n",
            "sample num:   95, data_idx: 23175\n",
            "sample num:   96, data_idx: 47442\n",
            "sample num:   97, data_idx:  4896\n",
            "sample num:   98, data_idx: 28069\n",
            "sample num:   99, data_idx:  2823\n",
            "us8k/us8k_network_fisher.npy\n",
            "[match_page_by_cost]\n",
            "occupation: 0\n",
            "len(page_list): 0\n",
            "len(network_page_list): 669\n",
            "cost: 0\n",
            "\n",
            "occupation: 1\n",
            "len(page_list): 0\n",
            "len(network_page_list): 669\n",
            "cost: 0\n",
            "\n",
            "occupation: 2\n",
            "len(page_list): 0\n",
            "len(network_page_list): 669\n",
            "cost: 0\n",
            "\n",
            "occupation: 3\n",
            "len(page_list): 0\n",
            "len(network_page_list): 669\n",
            "cost: 0\n",
            "\n",
            "occupation: 4\n",
            "len(page_list): 216\n",
            "len(network_page_list): 669\n",
            "cost: 10.47843\n",
            "\n",
            "occupation: 5\n",
            "len(page_list): 505\n",
            "len(network_page_list): 453\n",
            "cost: 0.06512604\n",
            "\n",
            "assing_page 156.214 ms\n",
            "[calculate_cost]\n",
            "toal_cost: 10.546675992263772\n",
            "669 pages allocated for 66854 weights\n",
            "total_network_cost: 226.2776500917971\n",
            "       0-th page\n",
            "     215-th page\n",
            "       0-th page\n",
            "     452-th page\n",
            "tcmalloc: large alloc 2286338048 bytes == 0x70fe000 @  0x7f081f1d41e7 0x7f081cb1dca1 0x7f081cb879c5 0x7f081cb8855e 0x7f081cc21a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "add_vnn\n",
            "hhar/hhar_network_weight.npy\n",
            "compute_fisher\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx: 113756\n",
            "sample num:    1, data_idx: 111904\n",
            "sample num:    2, data_idx: 21084\n",
            "sample num:    3, data_idx: 53484\n",
            "sample num:    4, data_idx: 113855\n",
            "sample num:    5, data_idx: 59680\n",
            "sample num:    6, data_idx: 46156\n",
            "sample num:    7, data_idx: 114291\n",
            "sample num:    8, data_idx: 77704\n",
            "sample num:    9, data_idx: 38744\n",
            "sample num:   10, data_idx:  5521\n",
            "sample num:   11, data_idx: 98369\n",
            "sample num:   12, data_idx: 98681\n",
            "sample num:   13, data_idx: 99337\n",
            "sample num:   14, data_idx: 110079\n",
            "sample num:   15, data_idx: 118493\n",
            "sample num:   16, data_idx: 34774\n",
            "sample num:   17, data_idx: 91650\n",
            "sample num:   18, data_idx: 25043\n",
            "sample num:   19, data_idx: 56978\n",
            "sample num:   20, data_idx: 65632\n",
            "sample num:   21, data_idx: 10172\n",
            "sample num:   22, data_idx: 17479\n",
            "sample num:   23, data_idx: 102705\n",
            "sample num:   24, data_idx: 100420\n",
            "sample num:   25, data_idx: 107748\n",
            "sample num:   26, data_idx: 76654\n",
            "sample num:   27, data_idx: 66710\n",
            "sample num:   28, data_idx: 68076\n",
            "sample num:   29, data_idx: 33738\n",
            "sample num:   30, data_idx:  6896\n",
            "sample num:   31, data_idx: 60421\n",
            "sample num:   32, data_idx: 60084\n",
            "sample num:   33, data_idx: 52022\n",
            "sample num:   34, data_idx: 28829\n",
            "sample num:   35, data_idx: 80977\n",
            "sample num:   36, data_idx: 97145\n",
            "sample num:   37, data_idx: 99992\n",
            "sample num:   38, data_idx: 84469\n",
            "sample num:   39, data_idx: 43988\n",
            "sample num:   40, data_idx: 97259\n",
            "sample num:   41, data_idx: 43121\n",
            "sample num:   42, data_idx: 118453\n",
            "sample num:   43, data_idx: 25923\n",
            "sample num:   44, data_idx:  2344\n",
            "sample num:   45, data_idx: 62901\n",
            "sample num:   46, data_idx: 31600\n",
            "sample num:   47, data_idx: 113269\n",
            "sample num:   48, data_idx: 39397\n",
            "sample num:   49, data_idx: 65179\n",
            "sample num:   50, data_idx: 30587\n",
            "sample num:   51, data_idx:  2241\n",
            "sample num:   52, data_idx: 13918\n",
            "sample num:   53, data_idx: 104324\n",
            "sample num:   54, data_idx: 82594\n",
            "sample num:   55, data_idx: 113947\n",
            "sample num:   56, data_idx: 75331\n",
            "sample num:   57, data_idx: 89266\n",
            "sample num:   58, data_idx: 113071\n",
            "sample num:   59, data_idx: 58368\n",
            "sample num:   60, data_idx: 90233\n",
            "sample num:   61, data_idx: 66126\n",
            "sample num:   62, data_idx: 28275\n",
            "sample num:   63, data_idx: 82184\n",
            "sample num:   64, data_idx: 85891\n",
            "sample num:   65, data_idx: 60393\n",
            "sample num:   66, data_idx: 29389\n",
            "sample num:   67, data_idx: 62221\n",
            "sample num:   68, data_idx: 101387\n",
            "sample num:   69, data_idx:  4987\n",
            "sample num:   70, data_idx: 47793\n",
            "sample num:   71, data_idx: 88707\n",
            "sample num:   72, data_idx: 16750\n",
            "sample num:   73, data_idx: 80824\n",
            "sample num:   74, data_idx: 91815\n",
            "sample num:   75, data_idx: 36065\n",
            "sample num:   76, data_idx: 91965\n",
            "sample num:   77, data_idx: 45207\n",
            "sample num:   78, data_idx: 18526\n",
            "sample num:   79, data_idx: 53425\n",
            "sample num:   80, data_idx: 24772\n",
            "sample num:   81, data_idx: 94450\n",
            "sample num:   82, data_idx: 50009\n",
            "sample num:   83, data_idx: 86602\n",
            "sample num:   84, data_idx: 27457\n",
            "sample num:   85, data_idx: 35139\n",
            "sample num:   86, data_idx: 83074\n",
            "sample num:   87, data_idx: 80897\n",
            "sample num:   88, data_idx: 36074\n",
            "sample num:   89, data_idx: 43560\n",
            "sample num:   90, data_idx: 50322\n",
            "sample num:   91, data_idx: 74732\n",
            "sample num:   92, data_idx: 79028\n",
            "sample num:   93, data_idx: 14291\n",
            "sample num:   94, data_idx: 44549\n",
            "sample num:   95, data_idx: 111724\n",
            "sample num:   96, data_idx: 102679\n",
            "sample num:   97, data_idx: 35066\n",
            "sample num:   98, data_idx: 101554\n",
            "sample num:   99, data_idx: 22402\n",
            "hhar/hhar_network_fisher.npy\n",
            "[match_page_by_cost]\n",
            "occupation: 0\n",
            "len(page_list): 0\n",
            "len(network_page_list): 652\n",
            "cost: 0\n",
            "\n",
            "occupation: 1\n",
            "len(page_list): 0\n",
            "len(network_page_list): 652\n",
            "cost: 0\n",
            "\n",
            "occupation: 2\n",
            "len(page_list): 0\n",
            "len(network_page_list): 652\n",
            "cost: 0\n",
            "\n",
            "occupation: 3\n",
            "len(page_list): 0\n",
            "len(network_page_list): 652\n",
            "cost: 0\n",
            "\n",
            "occupation: 4\n",
            "len(page_list): 0\n",
            "len(network_page_list): 652\n",
            "cost: 0\n",
            "\n",
            "occupation: 5\n",
            "len(page_list): 268\n",
            "len(network_page_list): 652\n",
            "cost: 14.110185\n",
            "\n",
            "occupation: 6\n",
            "len(page_list): 453\n",
            "len(network_page_list): 384\n",
            "cost: 0.027189953\n",
            "\n",
            "assing_page 148.220 ms\n",
            "[calculate_cost]\n",
            "toal_cost: 14.137383703109663\n",
            "652 pages allocated for 65114 weights\n",
            "total_network_cost: 330.24888918176293\n",
            "       0-th page\n",
            "     267-th page\n",
            "       0-th page\n",
            "     383-th page\n",
            "add_vnn\n",
            "esc10/esc10_network_weight.npy\n",
            "compute_fisher\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx:  1099\n",
            "sample num:    1, data_idx:  1584\n",
            "sample num:    2, data_idx:  6106\n",
            "sample num:    3, data_idx:   474\n",
            "sample num:    4, data_idx:  6286\n",
            "sample num:    5, data_idx:   398\n",
            "sample num:    6, data_idx:  2025\n",
            "sample num:    7, data_idx:  1680\n",
            "sample num:    8, data_idx:  1781\n",
            "sample num:    9, data_idx:  6201\n",
            "sample num:   10, data_idx:  4280\n",
            "sample num:   11, data_idx:  4369\n",
            "sample num:   12, data_idx:  3929\n",
            "sample num:   13, data_idx:  3482\n",
            "sample num:   14, data_idx:  6037\n",
            "sample num:   15, data_idx:  5795\n",
            "sample num:   16, data_idx:   930\n",
            "sample num:   17, data_idx:  4810\n",
            "sample num:   18, data_idx:  4258\n",
            "sample num:   19, data_idx:   508\n",
            "sample num:   20, data_idx:  1652\n",
            "sample num:   21, data_idx:  5305\n",
            "sample num:   22, data_idx:  5258\n",
            "sample num:   23, data_idx:  2458\n",
            "sample num:   24, data_idx:   588\n",
            "sample num:   25, data_idx:  5286\n",
            "sample num:   26, data_idx:  3447\n",
            "sample num:   27, data_idx:   483\n",
            "sample num:   28, data_idx:  3191\n",
            "sample num:   29, data_idx:  4654\n",
            "sample num:   30, data_idx:  4464\n",
            "sample num:   31, data_idx:  3012\n",
            "sample num:   32, data_idx:  1294\n",
            "sample num:   33, data_idx:  4829\n",
            "sample num:   34, data_idx:   865\n",
            "sample num:   35, data_idx:  2598\n",
            "sample num:   36, data_idx:   256\n",
            "sample num:   37, data_idx:   194\n",
            "sample num:   38, data_idx:  6305\n",
            "sample num:   39, data_idx:  5694\n",
            "sample num:   40, data_idx:  1275\n",
            "sample num:   41, data_idx:  1483\n",
            "sample num:   42, data_idx:  1181\n",
            "sample num:   43, data_idx:  3501\n",
            "sample num:   44, data_idx:  2397\n",
            "sample num:   45, data_idx:  1689\n",
            "sample num:   46, data_idx:  4136\n",
            "sample num:   47, data_idx:  1930\n",
            "sample num:   48, data_idx:  4729\n",
            "sample num:   49, data_idx:  4720\n",
            "sample num:   50, data_idx:  3323\n",
            "sample num:   51, data_idx:  5129\n",
            "sample num:   52, data_idx:  3796\n",
            "sample num:   53, data_idx:   687\n",
            "sample num:   54, data_idx:  6057\n",
            "sample num:   55, data_idx:  1026\n",
            "sample num:   56, data_idx:  5243\n",
            "sample num:   57, data_idx:  2517\n",
            "sample num:   58, data_idx:    48\n",
            "sample num:   59, data_idx:   108\n",
            "sample num:   60, data_idx:  5135\n",
            "sample num:   61, data_idx:  1356\n",
            "sample num:   62, data_idx:  4294\n",
            "sample num:   63, data_idx:  1496\n",
            "sample num:   64, data_idx:  5002\n",
            "sample num:   65, data_idx:  2431\n",
            "sample num:   66, data_idx:  3637\n",
            "sample num:   67, data_idx:  3746\n",
            "sample num:   68, data_idx:  2926\n",
            "sample num:   69, data_idx:   605\n",
            "sample num:   70, data_idx:  3454\n",
            "sample num:   71, data_idx:  3045\n",
            "sample num:   72, data_idx:  3005\n",
            "sample num:   73, data_idx:  5139\n",
            "sample num:   74, data_idx:  4842\n",
            "sample num:   75, data_idx:   883\n",
            "sample num:   76, data_idx:    98\n",
            "sample num:   77, data_idx:  4961\n",
            "sample num:   78, data_idx:  2353\n",
            "sample num:   79, data_idx:   956\n",
            "sample num:   80, data_idx:  4540\n",
            "sample num:   81, data_idx:  3671\n",
            "sample num:   82, data_idx:  1922\n",
            "sample num:   83, data_idx:  4083\n",
            "sample num:   84, data_idx:   952\n",
            "sample num:   85, data_idx:  2170\n",
            "sample num:   86, data_idx:  3064\n",
            "sample num:   87, data_idx:  2671\n",
            "sample num:   88, data_idx:  3869\n",
            "sample num:   89, data_idx:  4361\n",
            "sample num:   90, data_idx:  3524\n",
            "sample num:   91, data_idx:    23\n",
            "sample num:   92, data_idx:   524\n",
            "sample num:   93, data_idx:   131\n",
            "sample num:   94, data_idx:  1792\n",
            "sample num:   95, data_idx:  1735\n",
            "sample num:   96, data_idx:  3795\n",
            "sample num:   97, data_idx:  6069\n",
            "sample num:   98, data_idx:  1005\n",
            "sample num:   99, data_idx:    78\n",
            "esc10/esc10_network_fisher.npy\n",
            "[match_page_by_cost]\n",
            "occupation: 0\n",
            "len(page_list): 0\n",
            "len(network_page_list): 652\n",
            "cost: 0\n",
            "\n",
            "occupation: 1\n",
            "len(page_list): 0\n",
            "len(network_page_list): 652\n",
            "cost: 0\n",
            "\n",
            "occupation: 2\n",
            "len(page_list): 0\n",
            "len(network_page_list): 652\n",
            "cost: 0\n",
            "\n",
            "occupation: 3\n",
            "len(page_list): 0\n",
            "len(network_page_list): 652\n",
            "cost: 0\n",
            "\n",
            "occupation: 4\n",
            "len(page_list): 0\n",
            "len(network_page_list): 652\n",
            "cost: 0\n",
            "\n",
            "occupation: 5\n",
            "len(page_list): 0\n",
            "len(network_page_list): 652\n",
            "cost: 0\n",
            "\n",
            "occupation: 6\n",
            "len(page_list): 337\n",
            "len(network_page_list): 652\n",
            "cost: 14.747878\n",
            "\n",
            "occupation: 7\n",
            "len(page_list): 384\n",
            "len(network_page_list): 315\n",
            "cost: 0.057228465\n",
            "\n",
            "assing_page 154.032 ms\n",
            "[calculate_cost]\n",
            "toal_cost: 14.805109965753218\n",
            "652 pages allocated for 65154 weights\n",
            "total_network_cost: 400.50482806935906\n",
            "       0-th page\n",
            "     336-th page\n",
            "       0-th page\n",
            "     314-th page\n",
            "add_vnn\n",
            "obs/obs_network_weight.npy\n",
            "compute_fisher\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx:  2019\n",
            "sample num:    1, data_idx:  3019\n",
            "sample num:    2, data_idx:  1381\n",
            "sample num:    3, data_idx:   130\n",
            "sample num:    4, data_idx:   555\n",
            "sample num:    5, data_idx:  1938\n",
            "sample num:    6, data_idx:  2329\n",
            "sample num:    7, data_idx:  4551\n",
            "sample num:    8, data_idx:    98\n",
            "sample num:    9, data_idx:  3036\n",
            "sample num:   10, data_idx:  4005\n",
            "sample num:   11, data_idx:  1816\n",
            "sample num:   12, data_idx:  4405\n",
            "sample num:   13, data_idx:  4349\n",
            "sample num:   14, data_idx:  3942\n",
            "sample num:   15, data_idx:  3101\n",
            "sample num:   16, data_idx:   797\n",
            "sample num:   17, data_idx:   622\n",
            "sample num:   18, data_idx:  3400\n",
            "sample num:   19, data_idx:   490\n",
            "sample num:   20, data_idx:  5076\n",
            "sample num:   21, data_idx:  3857\n",
            "sample num:   22, data_idx:  5381\n",
            "sample num:   23, data_idx:  5023\n",
            "sample num:   24, data_idx:  4102\n",
            "sample num:   25, data_idx:  2350\n",
            "sample num:   26, data_idx:  5389\n",
            "sample num:   27, data_idx:  4532\n",
            "sample num:   28, data_idx:  4532\n",
            "sample num:   29, data_idx:  5422\n",
            "sample num:   30, data_idx:  1532\n",
            "sample num:   31, data_idx:   901\n",
            "sample num:   32, data_idx:  4873\n",
            "sample num:   33, data_idx:  5131\n",
            "sample num:   34, data_idx:  4781\n",
            "sample num:   35, data_idx:  4200\n",
            "sample num:   36, data_idx:  3378\n",
            "sample num:   37, data_idx:  4122\n",
            "sample num:   38, data_idx:  3676\n",
            "sample num:   39, data_idx:   449\n",
            "sample num:   40, data_idx:  5673\n",
            "sample num:   41, data_idx:  3173\n",
            "sample num:   42, data_idx:  5152\n",
            "sample num:   43, data_idx:    20\n",
            "sample num:   44, data_idx:  2893\n",
            "sample num:   45, data_idx:  4260\n",
            "sample num:   46, data_idx:   568\n",
            "sample num:   47, data_idx:  1849\n",
            "sample num:   48, data_idx:    36\n",
            "sample num:   49, data_idx:   539\n",
            "sample num:   50, data_idx:   867\n",
            "sample num:   51, data_idx:  1181\n",
            "sample num:   52, data_idx:  2113\n",
            "sample num:   53, data_idx:  4077\n",
            "sample num:   54, data_idx:  5407\n",
            "sample num:   55, data_idx:  5461\n",
            "sample num:   56, data_idx:  1467\n",
            "sample num:   57, data_idx:  4292\n",
            "sample num:   58, data_idx:  1004\n",
            "sample num:   59, data_idx:     8\n",
            "sample num:   60, data_idx:  4529\n",
            "sample num:   61, data_idx:  2761\n",
            "sample num:   62, data_idx:  4555\n",
            "sample num:   63, data_idx:   942\n",
            "sample num:   64, data_idx:  4505\n",
            "sample num:   65, data_idx:  1396\n",
            "sample num:   66, data_idx:  3848\n",
            "sample num:   67, data_idx:  5251\n",
            "sample num:   68, data_idx:   226\n",
            "sample num:   69, data_idx:  4886\n",
            "sample num:   70, data_idx:  3727\n",
            "sample num:   71, data_idx:  4658\n",
            "sample num:   72, data_idx:  1151\n",
            "sample num:   73, data_idx:  2072\n",
            "sample num:   74, data_idx:  2685\n",
            "sample num:   75, data_idx:  4237\n",
            "sample num:   76, data_idx:  2454\n",
            "sample num:   77, data_idx:  3755\n",
            "sample num:   78, data_idx:  3352\n",
            "sample num:   79, data_idx:  3921\n",
            "sample num:   80, data_idx:   555\n",
            "sample num:   81, data_idx:  5037\n",
            "sample num:   82, data_idx:  2047\n",
            "sample num:   83, data_idx:  1251\n",
            "sample num:   84, data_idx:   817\n",
            "sample num:   85, data_idx:  3671\n",
            "sample num:   86, data_idx:  3019\n",
            "sample num:   87, data_idx:   735\n",
            "sample num:   88, data_idx:  2959\n",
            "sample num:   89, data_idx:  5389\n",
            "sample num:   90, data_idx:   295\n",
            "sample num:   91, data_idx:  2476\n",
            "sample num:   92, data_idx:  2787\n",
            "sample num:   93, data_idx:  3540\n",
            "sample num:   94, data_idx:  3357\n",
            "sample num:   95, data_idx:  2493\n",
            "sample num:   96, data_idx:  3115\n",
            "sample num:   97, data_idx:  4991\n",
            "sample num:   98, data_idx:  5058\n",
            "sample num:   99, data_idx:  3406\n",
            "obs/obs_network_fisher.npy\n",
            "[match_page_by_cost]\n",
            "occupation: 0\n",
            "len(page_list): 0\n",
            "len(network_page_list): 721\n",
            "cost: 0\n",
            "\n",
            "occupation: 1\n",
            "len(page_list): 0\n",
            "len(network_page_list): 721\n",
            "cost: 0\n",
            "\n",
            "occupation: 2\n",
            "len(page_list): 0\n",
            "len(network_page_list): 721\n",
            "cost: 0\n",
            "\n",
            "occupation: 3\n",
            "len(page_list): 0\n",
            "len(network_page_list): 721\n",
            "cost: 0\n",
            "\n",
            "occupation: 4\n",
            "len(page_list): 0\n",
            "len(network_page_list): 721\n",
            "cost: 0\n",
            "\n",
            "occupation: 5\n",
            "len(page_list): 0\n",
            "len(network_page_list): 721\n",
            "cost: 0\n",
            "\n",
            "occupation: 6\n",
            "len(page_list): 0\n",
            "len(network_page_list): 721\n",
            "cost: 0\n",
            "\n",
            "occupation: 7\n",
            "len(page_list): 406\n",
            "len(network_page_list): 721\n",
            "cost: 2.009109\n",
            "\n",
            "occupation: 8\n",
            "len(page_list): 315\n",
            "len(network_page_list): 315\n",
            "cost: 0.0077413325\n",
            "\n",
            "assing_page 164.333 ms\n",
            "[calculate_cost]\n",
            "toal_cost: 2.0168505017127245\n",
            "721 pages allocated for 72012 weights\n",
            "total_network_cost: 446.00150099769235\n",
            "       0-th page\n",
            "     405-th page\n",
            "       0-th page\n",
            "     314-th page\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5CVS9N1Po_4",
        "outputId": "fb4785ba-feba-4a1e-fd44-588cb7ad7e1e"
      },
      "source": [
        "!bash ./joint_optimization.sh"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1-th joint optimization\n",
            "MNIST performance\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Inference accuracy: 0.184800\n",
            "GSC performance\n",
            "Inference accuracy: 0.168832\n",
            "GTSRB performance\n",
            "Inference accuracy: 0.090578\n",
            "CIFAR10 performance\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x4e56000 @  0x7ffbd8dd81e7 0x7ffbd6721ca1 0x7ffbd678b9c5 0x7ffbd678c55e 0x7ffbd6825a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.270500\n",
            "SVHN performance\n",
            "Inference accuracy: 0.418101\n",
            "US8K performance\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x49e6000 @  0x7fcb4f0bf1e7 0x7fcb4ca08ca1 0x7fcb4ca729c5 0x7fcb4ca7355e 0x7fcb4cb0ca6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.200185\n",
            "FMNIST performance\n",
            "Inference accuracy: 0.251400\n",
            "HHAR performance\n",
            "tcmalloc: large alloc 2286338048 bytes == 0x531c000 @  0x7fa0fe3f31e7 0x7fa0fbd3cca1 0x7fa0fbda69c5 0x7fa0fbda755e 0x7fa0fbe40a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.502934\n",
            "EC10 performance\n",
            "Inference accuracy: 0.690883\n",
            "OBS performance\n",
            "Inference accuracy: 0.994046\n",
            "2-th joint optimization\n",
            "MNIST performance\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Inference accuracy: 0.437600\n",
            "GSC performance\n",
            "Inference accuracy: 0.345934\n",
            "GTSRB performance\n",
            "Inference accuracy: 0.317419\n",
            "CIFAR10 performance\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x4e56000 @  0x7ff4929341e7 0x7ff49027dca1 0x7ff4902e79c5 0x7ff4902e855e 0x7ff490381a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.416300\n",
            "SVHN performance\n",
            "Inference accuracy: 0.652697\n",
            "US8K performance\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x4f50000 @  0x7f4a3f68c1e7 0x7f4a3cfd5ca1 0x7f4a3d03f9c5 0x7f4a3d04055e 0x7f4a3d0d9a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.308418\n",
            "FMNIST performance\n",
            "Inference accuracy: 0.458300\n",
            "HHAR performance\n",
            "tcmalloc: large alloc 2286338048 bytes == 0x57dc000 @  0x7fddac5d11e7 0x7fdda9f1aca1 0x7fdda9f849c5 0x7fdda9f8555e 0x7fddaa01ea6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.647946\n",
            "EC10 performance\n",
            "Inference accuracy: 0.777778\n",
            "OBS performance\n",
            "Inference accuracy: 0.201051\n",
            "3-th joint optimization\n",
            "MNIST performance\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Inference accuracy: 0.483100\n",
            "GSC performance\n",
            "Inference accuracy: 0.491958\n",
            "GTSRB performance\n",
            "Inference accuracy: 0.464212\n",
            "CIFAR10 performance\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x5138000 @  0x7ffaf5f151e7 0x7ffaf385eca1 0x7ffaf38c89c5 0x7ffaf38c955e 0x7ffaf3962a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.487800\n",
            "SVHN performance\n",
            "Inference accuracy: 0.762177\n",
            "US8K performance\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x4922000 @  0x7f8e618c81e7 0x7f8e5f211ca1 0x7f8e5f27b9c5 0x7f8e5f27c55e 0x7f8e5f315a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.340796\n",
            "FMNIST performance\n",
            "Inference accuracy: 0.772100\n",
            "HHAR performance\n",
            "tcmalloc: large alloc 2286338048 bytes == 0x6400000 @  0x7f80974b01e7 0x7f8094df9ca1 0x7f8094e639c5 0x7f8094e6455e 0x7f8094efda6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.875105\n",
            "EC10 performance\n",
            "Inference accuracy: 0.777778\n",
            "OBS performance\n",
            "Inference accuracy: 0.627320\n",
            "4-th joint optimization\n",
            "MNIST performance\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Inference accuracy: 0.710400\n",
            "GSC performance\n",
            "Inference accuracy: 0.562108\n",
            "GTSRB performance\n",
            "Inference accuracy: 0.589786\n",
            "CIFAR10 performance\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x5f2c000 @  0x7f5f6c5441e7 0x7f5f69e8dca1 0x7f5f69ef79c5 0x7f5f69ef855e 0x7f5f69f91a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.511600\n",
            "SVHN performance\n",
            "Inference accuracy: 0.783920\n",
            "US8K performance\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x5ac8000 @  0x7f785ea6d1e7 0x7f785c3b6ca1 0x7f785c4209c5 0x7f785c42155e 0x7f785c4baa6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.369473\n",
            "FMNIST performance\n",
            "Inference accuracy: 0.817500\n",
            "HHAR performance\n",
            "tcmalloc: large alloc 2286338048 bytes == 0x5f20000 @  0x7f793fbcc1e7 0x7f793d515ca1 0x7f793d57f9c5 0x7f793d58055e 0x7f793d619a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.862531\n",
            "EC10 performance\n",
            "Inference accuracy: 0.783476\n",
            "OBS performance\n",
            "Inference accuracy: 0.274956\n",
            "5-th joint optimization\n",
            "MNIST performance\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Inference accuracy: 0.569800\n",
            "GSC performance\n",
            "Inference accuracy: 0.584552\n",
            "GTSRB performance\n",
            "Inference accuracy: 0.608076\n",
            "CIFAR10 performance\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x675c000 @  0x7f8aec1a81e7 0x7f8ae9af1ca1 0x7f8ae9b5b9c5 0x7f8ae9b5c55e 0x7f8ae9bf5a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.512900\n",
            "SVHN performance\n",
            "Inference accuracy: 0.773586\n",
            "US8K performance\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x4e2c000 @  0x7f2275b661e7 0x7f22734afca1 0x7f22735199c5 0x7f227351a55e 0x7f22735b3a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.369473\n",
            "FMNIST performance\n",
            "Inference accuracy: 0.769000\n",
            "HHAR performance\n",
            "tcmalloc: large alloc 2286338048 bytes == 0x4ac2000 @  0x7f084a76f1e7 0x7f08480b8ca1 0x7f08481229c5 0x7f084812355e 0x7f08481bca6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.853311\n",
            "EC10 performance\n",
            "Inference accuracy: 0.777778\n",
            "OBS performance\n",
            "Inference accuracy: 0.134851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZG9nw21t6of"
      },
      "source": [
        "import time\n",
        "beginning = time.time()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud4gWexMV3HL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cba7749-153c-4c68-83a1-0d619c4ad7d5"
      },
      "source": [
        "# 6-10\n",
        "!bash ./joint_optimization.sh"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1-th joint optimization\n",
            "MNIST performance\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Inference accuracy: 0.532900\n",
            "GSC performance\n",
            "Inference accuracy: 0.618810\n",
            "GTSRB performance\n",
            "Inference accuracy: 0.670071\n",
            "CIFAR10 performance\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x63a8000 @  0x7fd422c111e7 0x7fd42055aca1 0x7fd4205c49c5 0x7fd4205c555e 0x7fd42065ea6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.519800\n",
            "SVHN performance\n",
            "Inference accuracy: 0.805317\n",
            "US8K performance\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x5920000 @  0x7f6a49e0c1e7 0x7f6a47755ca1 0x7f6a477bf9c5 0x7f6a477c055e 0x7f6a47859a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.347271\n",
            "FMNIST performance\n",
            "Inference accuracy: 0.786900\n",
            "HHAR performance\n",
            "tcmalloc: large alloc 2286338048 bytes == 0x4a96000 @  0x7f29801311e7 0x7f297da7aca1 0x7f297dae49c5 0x7f297dae555e 0x7f297db7ea6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.874267\n",
            "EC10 performance\n",
            "Inference accuracy: 0.774929\n",
            "OBS performance\n",
            "Inference accuracy: 0.112084\n",
            "2-th joint optimization\n",
            "MNIST performance\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Inference accuracy: 0.650100\n",
            "GSC performance\n",
            "Inference accuracy: 0.652612\n",
            "GTSRB performance\n",
            "Inference accuracy: 0.739588\n",
            "CIFAR10 performance\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x66ec000 @  0x7f97d8e841e7 0x7f97d67cdca1 0x7f97d68379c5 0x7f97d683855e 0x7f97d68d1a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.536600\n",
            "SVHN performance\n",
            "Inference accuracy: 0.815496\n",
            "US8K performance\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x6166000 @  0x7f32ffca51e7 0x7f32fd5eeca1 0x7f32fd6589c5 0x7f32fd65955e 0x7f32fd6f2a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.371138\n",
            "FMNIST performance\n",
            "Inference accuracy: 0.788800\n",
            "HHAR performance\n",
            "tcmalloc: large alloc 2286338048 bytes == 0x5082000 @  0x7f0549bdd1e7 0x7f0547526ca1 0x7f05475909c5 0x7f054759155e 0x7f054762aa6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.858340\n",
            "EC10 performance\n",
            "Inference accuracy: 0.786325\n",
            "OBS performance\n",
            "Inference accuracy: 0.098074\n",
            "3-th joint optimization\n",
            "MNIST performance\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Inference accuracy: 0.671500\n",
            "GSC performance\n",
            "Inference accuracy: 0.671422\n",
            "GTSRB performance\n",
            "Inference accuracy: 0.755978\n",
            "CIFAR10 performance\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x5106000 @  0x7f82ce6f01e7 0x7f82cc039ca1 0x7f82cc0a39c5 0x7f82cc0a455e 0x7f82cc13da6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.537100\n",
            "SVHN performance\n",
            "Inference accuracy: 0.814805\n",
            "US8K performance\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x58ce000 @  0x7f2867b2d1e7 0x7f2865476ca1 0x7f28654e09c5 0x7f28654e155e 0x7f286557aa6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.376688\n",
            "FMNIST performance\n",
            "Inference accuracy: 0.809800\n",
            "HHAR performance\n",
            "tcmalloc: large alloc 2286338048 bytes == 0x5716000 @  0x7feb0b01b1e7 0x7feb08964ca1 0x7feb089ce9c5 0x7feb089cf55e 0x7feb08a68a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.890193\n",
            "EC10 performance\n",
            "Inference accuracy: 0.776353\n",
            "OBS performance\n",
            "Inference accuracy: 0.085464\n",
            "4-th joint optimization\n",
            "MNIST performance\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Inference accuracy: 0.098000\n",
            "GSC performance\n",
            "Inference accuracy: 0.014993\n",
            "GTSRB performance\n",
            "Inference accuracy: 0.004751\n",
            "CIFAR10 performance\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x4e2c000 @  0x7f1ca68921e7 0x7f1ca41dbca1 0x7f1ca42459c5 0x7f1ca424655e 0x7f1ca42dfa6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.100000\n",
            "SVHN performance\n",
            "Inference accuracy: 0.066994\n",
            "US8K performance\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x661e000 @  0x7f2138d361e7 0x7f213667fca1 0x7f21366e99c5 0x7f21366ea55e 0x7f2136783a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.103608\n",
            "FMNIST performance\n",
            "Inference accuracy: 0.100000\n",
            "HHAR performance\n",
            "tcmalloc: large alloc 2286338048 bytes == 0x6642000 @  0x7f671ffdc1e7 0x7f671d925ca1 0x7f671d98f9c5 0x7f671d99055e 0x7f671da29a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.098910\n",
            "EC10 performance\n",
            "Inference accuracy: 0.128205\n",
            "OBS performance\n",
            "Inference accuracy: 0.077058\n",
            "5-th joint optimization\n",
            "MNIST performance\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Inference accuracy: 0.098000\n",
            "GSC performance\n",
            "Inference accuracy: 0.014993\n",
            "GTSRB performance\n",
            "Inference accuracy: 0.004751\n",
            "CIFAR10 performance\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x5084000 @  0x7ff2824b51e7 0x7ff27fdfeca1 0x7ff27fe689c5 0x7ff27fe6955e 0x7ff27ff02a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.100000\n",
            "SVHN performance\n",
            "Inference accuracy: 0.066994\n",
            "US8K performance\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x4e34000 @  0x7f6a4eb091e7 0x7f6a4c452ca1 0x7f6a4c4bc9c5 0x7f6a4c4bd55e 0x7f6a4c556a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.103608\n",
            "FMNIST performance\n",
            "Inference accuracy: 0.100000\n",
            "HHAR performance\n",
            "tcmalloc: large alloc 2286338048 bytes == 0x5a24000 @  0x7f1820c311e7 0x7f181e57aca1 0x7f181e5e49c5 0x7f181e5e555e 0x7f181e67ea6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.098910\n",
            "EC10 performance\n",
            "Inference accuracy: 0.128205\n",
            "OBS performance\n",
            "Inference accuracy: 0.077058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKJVcHDsuGXL",
        "outputId": "8dee045c-1135-4ccd-cfe5-4bf376aab4b0"
      },
      "source": [
        "!python in-memory_execute.py | tee -a in_memory_execution_three_nets.txtduration = time.time() - beginning \n",
        "print(\"Time elapsed\", duration)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time elapsed 3969.3265335559845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZq55fMH_gg4"
      },
      "source": [
        "import time\n",
        "beginning = time.time()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UchJZMmaV298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "outputId": "7e89a093-35f0-4f22-d1cc-a012ec0e77ac"
      },
      "source": [
        "# 11-15\n",
        "!bash ./joint_optimization.sh"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1-th joint optimization\n",
            "MNIST performance\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Inference accuracy: 0.098000\n",
            "GSC performance\n",
            "Inference accuracy: 0.014993\n",
            "GTSRB performance\n",
            "Inference accuracy: 0.004751\n",
            "CIFAR10 performance\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x4e3c000 @  0x7f831fa1a1e7 0x7f831d363ca1 0x7f831d3cd9c5 0x7f831d3ce55e 0x7f831d467a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.100000\n",
            "SVHN performance\n",
            "Inference accuracy: 0.066994\n",
            "US8K performance\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x5d3c000 @  0x7f80f62061e7 0x7f80f3b4fca1 0x7f80f3bb99c5 0x7f80f3bba55e 0x7f80f3c53a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.103608\n",
            "FMNIST performance\n",
            "Inference accuracy: 0.100000\n",
            "HHAR performance\n",
            "tcmalloc: large alloc 2286338048 bytes == 0x6606000 @  0x7f6404fdd1e7 0x7f6402926ca1 0x7f64029909c5 0x7f640299155e 0x7f6402a2aa6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.098910\n",
            "EC10 performance\n",
            "Inference accuracy: 0.128205\n",
            "OBS performance\n",
            "Inference accuracy: 0.077058\n",
            "2-th joint optimization\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-85b05f15e468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 11-15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash ./joint_optimization.sh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m   result = _run_command(\n\u001b[0;32m--> 440\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    441\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_monitor_process\u001b[0;34m(parent_pty, epoll, p, cmd, update_stdin_widget)\u001b[0m\n\u001b[1;32m    220\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_poll_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_poll_process\u001b[0;34m(parent_pty, epoll, p, cmd, decoder, state)\u001b[0m\n\u001b[1;32m    267\u001b[0m   \u001b[0moutput_available\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m   \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m   \u001b[0minput_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHLBJM2W_hGX"
      },
      "source": [
        "duration = time.time() - beginning \n",
        "print(\"Time elapsed\", duration)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNvcors-V3MA"
      },
      "source": [
        "# 16-20\n",
        "!bash ./joint_optimization.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u9uyO5-V3PL"
      },
      "source": [
        "!python weight_virtualization.py -mode=e -vnn_name=mnist\n",
        "!python weight_virtualization.py -mode=e -vnn_name=gsc\n",
        "!python weight_virtualization.py -mode=e -vnn_name=gtsrb\n",
        "!python weight_virtualization.py -mode=e -vnn_name=cifar10\n",
        "!python weight_virtualization.py -mode=e -vnn_name=svhn\n",
        "!python weight_virtualization.py -mode=e -vnn_name=fmnist\n",
        "!python weight_virtualization.py -mode=e -vnn_name=us8k\n",
        "!python weight_virtualization.py -mode=e -vnn_name=hhar\n",
        "!python weight_virtualization.py -mode=e -vnn_name=esc10\n",
        "!python weight_virtualization.py -mode=e -vnn_name=obs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLIMQhpTt307"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8sHGRaut3x-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKbfMYfVt3vC",
        "outputId": "e96d7500-24f4-424a-dc1d-ebb3a27787cd"
      },
      "source": [
        "!python weight_virtualization.py -mode=t -vnn_name=gsc"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "get_matching_loss\n",
            "v_train\n",
            "step 0, training accuracy: 0.040000 original loss: nan matching loss: nan\n",
            "step 0, Validation accuracy: 0.014993\n",
            "step 100, training accuracy: 0.020000 original loss: nan matching loss: nan\n",
            "step 100, Validation accuracy: 0.014993\n",
            "step 200, training accuracy: 0.000000 original loss: nan matching loss: nan\n",
            "step 200, Validation accuracy: 0.014993\n",
            "step 300, training accuracy: 0.010000 original loss: nan matching loss: nan\n",
            "step 300, Validation accuracy: 0.014993\n",
            "step 400, training accuracy: 0.030000 original loss: nan matching loss: nan\n",
            "step 400, Validation accuracy: 0.014993\n",
            "step 500, training accuracy: 0.010000 original loss: nan matching loss: nan\n",
            "step 500, Validation accuracy: 0.014993\n",
            "step 600, training accuracy: 0.030000 original loss: nan matching loss: nan\n",
            "step 600, Validation accuracy: 0.014993\n",
            "step 700, training accuracy: 0.020000 original loss: nan matching loss: nan\n",
            "step 700, Validation accuracy: 0.014993\n",
            "step 800, training accuracy: 0.020000 original loss: nan matching loss: nan\n",
            "step 800, Validation accuracy: 0.014993\n",
            "step 900, training accuracy: 0.030000 original loss: nan matching loss: nan\n",
            "step 900, Validation accuracy: 0.014993\n",
            "step 1000, training accuracy: 0.020000 original loss: nan matching loss: nan\n",
            "step 1000, Validation accuracy: 0.014993\n",
            "step 1100, training accuracy: 0.000000 original loss: nan matching loss: nan\n",
            "step 1100, Validation accuracy: 0.014993\n",
            "step 1200, training accuracy: 0.010000 original loss: nan matching loss: nan\n",
            "step 1200, Validation accuracy: 0.014993\n",
            "step 1300, training accuracy: 0.010000 original loss: nan matching loss: nan\n",
            "step 1300, Validation accuracy: 0.014993\n",
            "step 1400, training accuracy: 0.010000 original loss: nan matching loss: nan\n",
            "step 1400, Validation accuracy: 0.014993\n",
            "step 1500, training accuracy: 0.000000 original loss: nan matching loss: nan\n",
            "step 1500, Validation accuracy: 0.014993\n",
            "step 1600, training accuracy: 0.020000 original loss: nan matching loss: nan\n",
            "step 1600, Validation accuracy: 0.014993\n",
            "step 1700, training accuracy: 0.020000 original loss: nan matching loss: nan\n",
            "step 1700, Validation accuracy: 0.014993\n",
            "step 1800, training accuracy: 0.000000 original loss: nan matching loss: nan\n",
            "step 1800, Validation accuracy: 0.014993\n",
            "step 1900, training accuracy: 0.010000 original loss: nan matching loss: nan\n",
            "step 1900, Validation accuracy: 0.014993\n",
            "step 2000, training accuracy: 0.020000 original loss: nan matching loss: nan\n",
            "step 2000, Validation accuracy: 0.014993\n",
            "step 2100, training accuracy: 0.010000 original loss: nan matching loss: nan\n",
            "step 2100, Validation accuracy: 0.014993\n",
            "step 2200, training accuracy: 0.010000 original loss: nan matching loss: nan\n",
            "step 2200, Validation accuracy: 0.014993\n",
            "step 2300, training accuracy: 0.020000 original loss: nan matching loss: nan\n",
            "step 2300, Validation accuracy: 0.014993\n",
            "step 2400, training accuracy: 0.020000 original loss: nan matching loss: nan\n",
            "step 2400, Validation accuracy: 0.014993\n",
            "step 2500, training accuracy: 0.010000 original loss: nan matching loss: nan\n",
            "step 2500, Validation accuracy: 0.014993\n",
            "step 2600, training accuracy: 0.000000 original loss: nan matching loss: nan\n",
            "step 2600, Validation accuracy: 0.014993\n",
            "step 2700, training accuracy: 0.010000 original loss: nan matching loss: nan\n",
            "step 2700, Validation accuracy: 0.014993\n",
            "step 2800, training accuracy: 0.020000 original loss: nan matching loss: nan\n",
            "step 2800, Validation accuracy: 0.014993\n",
            "step 2900, training accuracy: 0.030000 original loss: nan matching loss: nan\n",
            "step 2900, Validation accuracy: 0.014993\n",
            "step 3000, training accuracy: 0.020000 original loss: nan matching loss: nan\n",
            "step 3000, Validation accuracy: 0.014993\n",
            "step 3100, training accuracy: 0.000000 original loss: nan matching loss: nan\n",
            "step 3100, Validation accuracy: 0.014993\n",
            "step 3200, training accuracy: 0.010000 original loss: nan matching loss: nan\n",
            "step 3200, Validation accuracy: 0.014993\n",
            "step 3300, training accuracy: 0.030000 original loss: nan matching loss: nan\n",
            "step 3300, Validation accuracy: 0.014993\n",
            "step 3400, training accuracy: 0.010000 original loss: nan matching loss: nan\n",
            "step 3400, Validation accuracy: 0.014993\n",
            "step 3500, training accuracy: 0.000000 original loss: nan matching loss: nan\n",
            "step 3500, Validation accuracy: 0.014993\n",
            "step 3600, training accuracy: 0.040000 original loss: nan matching loss: nan\n",
            "step 3600, Validation accuracy: 0.014993\n",
            "step 3700, training accuracy: 0.010000 original loss: nan matching loss: nan\n",
            "step 3700, Validation accuracy: 0.014993\n",
            "step 3800, training accuracy: 0.020000 original loss: nan matching loss: nan\n",
            "step 3800, Validation accuracy: 0.014993\n",
            "step 3900, training accuracy: 0.020000 original loss: nan matching loss: nan\n",
            "step 3900, Validation accuracy: 0.014993\n",
            "step 4000, training accuracy: 0.020000 original loss: nan matching loss: nan\n",
            "step 4000, Validation accuracy: 0.014993\n",
            "step 4100, training accuracy: 0.000000 original loss: nan matching loss: nan\n",
            "step 4100, Validation accuracy: 0.014993\n",
            "step 4200, training accuracy: 0.050000 original loss: nan matching loss: nan\n",
            "step 4200, Validation accuracy: 0.014993\n",
            "step 4300, training accuracy: 0.030000 original loss: nan matching loss: nan\n",
            "step 4300, Validation accuracy: 0.014993\n",
            "step 4400, training accuracy: 0.020000 original loss: nan matching loss: nan\n",
            "step 4400, Validation accuracy: 0.014993\n",
            "step 4500, training accuracy: 0.020000 original loss: nan matching loss: nan\n",
            "step 4500, Validation accuracy: 0.014993\n",
            "step 4600, training accuracy: 0.010000 original loss: nan matching loss: nan\n",
            "step 4600, Validation accuracy: 0.014993\n",
            "step 4700, training accuracy: 0.020000 original loss: nan matching loss: nan\n",
            "step 4700, Validation accuracy: 0.014993\n",
            "step 4800, training accuracy: 0.000000 original loss: nan matching loss: nan\n",
            "step 4800, Validation accuracy: 0.014993\n",
            "step 4900, training accuracy: 0.020000 original loss: nan matching loss: nan\n",
            "step 4900, Validation accuracy: 0.014993\n",
            "step 4999, training accuracy: 0.010000 original loss: nan matching loss: nan\n",
            "step 4999, Validation accuracy: 0.014993\n",
            "gsc/gsc_weight.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ_md0h4t3sL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYUh5uywt3pC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDz1mD3KD3wU",
        "outputId": "0a36507d-93b0-448f-ff58-9577f6ab613b"
      },
      "source": [
        "!python in-memory_execute.py | tee -a in_memory_execution_ten_nets.txt"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 2286338048 bytes == 0x2976a000 @  0x7efda39491e7 0x7efda14d2ca1 0x7efda153c9c5 0x7efda153d55e 0x7efda15d6a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x7efacfdba000 @  0x7efda39491e7 0x7efda14d2ca1 0x7efda153c9c5 0x7efda153d55e 0x7efda15d6a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "virtual_weight address: 139625080291328\n",
            "init virtual_weight 7.468 ms\n",
            "[VNN 0][cifar10] init page table 4.496 ms\n",
            "[VNN 1][esc10] init page table 3.997 ms\n",
            "[VNN 2][fmnist] init page table 3.715 ms\n",
            "[VNN 3][gsc] init page table 3.554 ms\n",
            "[VNN 4][gtsrb] init page table 3.585 ms\n",
            "[VNN 5][hhar] init page table 3.703 ms\n",
            "[VNN 6][mnist] init page table 3.648 ms\n",
            "[VNN 7][obs] init page table 3.863 ms\n",
            "[VNN 8][svhn] init page table 3.731 ms\n",
            "[VNN 9][us8k] init page table 3.751 ms\n",
            "tf.global_variables_initializer 1683.635 ms\n",
            "[Executing] hhar\n",
            "weights load time : 0.309 ms\n",
            "DNN execution time: 2498.174 ms\n",
            "Inference accuracy: 0.098910\n",
            "[Executing] gtsrb\n",
            "weights load time : 0.347 ms\n",
            "DNN execution time: 783.085 ms\n",
            "Inference accuracy: 0.004751\n",
            "[Executing] svhn\n",
            "weights load time : 0.289 ms\n",
            "DNN execution time: 1134.541 ms\n",
            "Inference accuracy: 0.066994\n",
            "[Executing] hhar\n",
            "weights load time : 0.232 ms\n",
            "DNN execution time: 20.259 ms\n",
            "Inference accuracy: 0.098910\n",
            "[Executing] obs\n",
            "weights load time : 0.304 ms\n",
            "DNN execution time: 925.869 ms\n",
            "Inference accuracy: 0.077058\n",
            "[Executing] us8k\n",
            "weights load time : 0.257 ms\n",
            "DNN execution time: 966.242 ms\n",
            "Inference accuracy: 0.103608\n",
            "[Executing] us8k\n",
            "weights load time : 0.175 ms\n",
            "DNN execution time: 97.728 ms\n",
            "Inference accuracy: 0.103608\n",
            "[Executing] us8k\n",
            "weights load time : 0.245 ms\n",
            "DNN execution time: 97.169 ms\n",
            "Inference accuracy: 0.103608\n",
            "[Executing] esc10\n",
            "weights load time : 0.273 ms\n",
            "DNN execution time: 422.489 ms\n",
            "Inference accuracy: 0.128205\n",
            "[Executing] obs\n",
            "weights load time : 0.240 ms\n",
            "DNN execution time: 88.772 ms\n",
            "Inference accuracy: 0.077058\n",
            "[Executing] esc10\n",
            "weights load time : 0.218 ms\n",
            "DNN execution time: 16.022 ms\n",
            "Inference accuracy: 0.128205\n",
            "[Executing] esc10\n",
            "weights load time : 0.221 ms\n",
            "DNN execution time: 15.451 ms\n",
            "Inference accuracy: 0.128205\n",
            "[Executing] svhn\n",
            "weights load time : 0.258 ms\n",
            "DNN execution time: 129.602 ms\n",
            "Inference accuracy: 0.066994\n",
            "[Executing] svhn\n",
            "weights load time : 0.204 ms\n",
            "DNN execution time: 125.724 ms\n",
            "Inference accuracy: 0.066994\n",
            "[Executing] us8k\n",
            "weights load time : 0.171 ms\n",
            "DNN execution time: 98.586 ms\n",
            "Inference accuracy: 0.103608\n",
            "[Executing] us8k\n",
            "weights load time : 0.175 ms\n",
            "DNN execution time: 96.976 ms\n",
            "Inference accuracy: 0.103608\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "[Executing] mnist\n",
            "weights load time : 0.490 ms\n",
            "DNN execution time: 715.345 ms\n",
            "Inference accuracy: 0.098000\n",
            "[Executing] gtsrb\n",
            "weights load time : 0.291 ms\n",
            "DNN execution time: 61.756 ms\n",
            "Inference accuracy: 0.004751\n",
            "[Executing] esc10\n",
            "weights load time : 0.202 ms\n",
            "DNN execution time: 21.006 ms\n",
            "Inference accuracy: 0.128205\n",
            "[Executing] esc10\n",
            "weights load time : 0.182 ms\n",
            "DNN execution time: 14.264 ms\n",
            "Inference accuracy: 0.128205\n",
            "[Executing] cifar10\n",
            "weights load time : 4.906 ms\n",
            "DNN execution time: 794.516 ms\n",
            "Inference accuracy: 0.100000\n",
            "[Executing] obs\n",
            "weights load time : 0.197 ms\n",
            "DNN execution time: 89.964 ms\n",
            "Inference accuracy: 0.077058\n",
            "[Executing] gtsrb\n",
            "weights load time : 0.196 ms\n",
            "DNN execution time: 65.785 ms\n",
            "Inference accuracy: 0.004751\n",
            "[Executing] hhar\n",
            "weights load time : 0.250 ms\n",
            "DNN execution time: 21.606 ms\n",
            "Inference accuracy: 0.098910\n",
            "[Executing] svhn\n",
            "weights load time : 0.191 ms\n",
            "DNN execution time: 132.343 ms\n",
            "Inference accuracy: 0.066994\n",
            "[Executing] hhar\n",
            "weights load time : 0.176 ms\n",
            "DNN execution time: 17.340 ms\n",
            "Inference accuracy: 0.098910\n",
            "[Executing] svhn\n",
            "weights load time : 0.198 ms\n",
            "DNN execution time: 124.720 ms\n",
            "Inference accuracy: 0.066994\n",
            "[Executing] us8k\n",
            "weights load time : 0.186 ms\n",
            "DNN execution time: 141.540 ms\n",
            "Inference accuracy: 0.103608\n",
            "[Executing] gsc\n",
            "weights load time : 0.302 ms\n",
            "DNN execution time: 815.319 ms\n",
            "Inference accuracy: 0.014993\n",
            "[Executing] gtsrb\n",
            "weights load time : 0.239 ms\n",
            "DNN execution time: 88.328 ms\n",
            "Inference accuracy: 0.004751\n",
            "total weights load time : 11.922 ms\n",
            "total DNN execution time: 10620.519 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSqPWh0ZEFD0",
        "outputId": "06320cfa-51b5-4bb4-a1c5-c3fc438632c6"
      },
      "source": [
        "!python baseline_execute.py | tee -a baseline_execution_ten_nets.txt"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1228800000 bytes == 0xb2d78000 @  0x7f34dfcff1e7 0x7f34dd888ca1 0x7f34dd8f29c5 0x7f34dd8f355e 0x7f34dd98ca6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "tcmalloc: large alloc 2286338048 bytes == 0x156042000 @  0x7f34dfcff1e7 0x7f34dd888ca1 0x7f34dd8f29c5 0x7f34dd8f355e 0x7f34dd98ca6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x7f318db12000 @  0x7f34dfcff1e7 0x7f34dd888ca1 0x7f34dd8f29c5 0x7f34dd8f355e 0x7f34dd98ca6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "[Executing] mnist\n",
            "weights load time : 83.578 ms\n",
            "DNN execution time: 12664.413 ms\n",
            "Inference accuracy: 0.980800\n",
            "[Executing] fmnist\n",
            "weights load time : 94.949 ms\n",
            "DNN execution time: 787.147 ms\n",
            "Inference accuracy: 0.874900\n",
            "[Executing] cifar10\n",
            "weights load time : 69.775 ms\n",
            "DNN execution time: 515.315 ms\n",
            "Inference accuracy: 0.555200\n",
            "[Executing] svhn\n",
            "weights load time : 129.116 ms\n",
            "DNN execution time: 904.194 ms\n",
            "Inference accuracy: 0.814843\n",
            "[Executing] svhn\n",
            "weights load time : 125.559 ms\n",
            "DNN execution time: 181.548 ms\n",
            "Inference accuracy: 0.814843\n",
            "[Executing] hhar\n",
            "weights load time : 69.093 ms\n",
            "DNN execution time: 313.694 ms\n",
            "Inference accuracy: 0.898575\n",
            "[Executing] gsc\n",
            "weights load time : 57.279 ms\n",
            "DNN execution time: 498.571 ms\n",
            "Inference accuracy: 0.694684\n",
            "[Executing] cifar10\n",
            "weights load time : 73.544 ms\n",
            "DNN execution time: 175.581 ms\n",
            "Inference accuracy: 0.555200\n",
            "[Executing] hhar\n",
            "weights load time : 66.229 ms\n",
            "DNN execution time: 47.177 ms\n",
            "Inference accuracy: 0.898575\n",
            "[Executing] esc10\n",
            "weights load time : 117.893 ms\n",
            "DNN execution time: 173.277 ms\n",
            "Inference accuracy: 0.816239\n",
            "[Executing] hhar\n",
            "weights load time : 63.421 ms\n",
            "DNN execution time: 47.036 ms\n",
            "Inference accuracy: 0.898575\n",
            "[Executing] cifar10\n",
            "weights load time : 68.075 ms\n",
            "DNN execution time: 123.307 ms\n",
            "Inference accuracy: 0.555200\n",
            "[Executing] us8k\n",
            "weights load time : 76.200 ms\n",
            "DNN execution time: 712.786 ms\n",
            "Inference accuracy: 0.439408\n",
            "[Executing] cifar10\n",
            "weights load time : 65.647 ms\n",
            "DNN execution time: 142.164 ms\n",
            "Inference accuracy: 0.555200\n",
            "[Executing] us8k\n",
            "weights load time : 70.658 ms\n",
            "DNN execution time: 130.592 ms\n",
            "Inference accuracy: 0.439408\n",
            "[Executing] obs\n",
            "weights load time : 70.403 ms\n",
            "DNN execution time: 720.139 ms\n",
            "Inference accuracy: 0.999650\n",
            "[Executing] cifar10\n",
            "weights load time : 68.874 ms\n",
            "DNN execution time: 177.049 ms\n",
            "Inference accuracy: 0.555200\n",
            "[Executing] svhn\n",
            "weights load time : 137.030 ms\n",
            "DNN execution time: 195.273 ms\n",
            "Inference accuracy: 0.814843\n",
            "[Executing] svhn\n",
            "weights load time : 133.256 ms\n",
            "DNN execution time: 181.381 ms\n",
            "Inference accuracy: 0.814843\n",
            "[Executing] obs\n",
            "weights load time : 58.821 ms\n",
            "DNN execution time: 102.929 ms\n",
            "Inference accuracy: 0.999650\n",
            "[Executing] gtsrb\n",
            "weights load time : 70.017 ms\n",
            "DNN execution time: 593.631 ms\n",
            "Inference accuracy: 0.928029\n",
            "[Executing] cifar10\n",
            "weights load time : 71.265 ms\n",
            "DNN execution time: 193.442 ms\n",
            "Inference accuracy: 0.555200\n",
            "[Executing] us8k\n",
            "weights load time : 71.930 ms\n",
            "DNN execution time: 136.983 ms\n",
            "Inference accuracy: 0.439408\n",
            "[Executing] esc10\n",
            "weights load time : 131.983 ms\n",
            "DNN execution time: 74.857 ms\n",
            "Inference accuracy: 0.816239\n",
            "[Executing] gsc\n",
            "weights load time : 58.692 ms\n",
            "DNN execution time: 69.143 ms\n",
            "Inference accuracy: 0.694684\n",
            "[Executing] hhar\n",
            "weights load time : 67.203 ms\n",
            "DNN execution time: 50.660 ms\n",
            "Inference accuracy: 0.898575\n",
            "[Executing] fmnist\n",
            "weights load time : 104.593 ms\n",
            "DNN execution time: 136.458 ms\n",
            "Inference accuracy: 0.874900\n",
            "[Executing] mnist\n",
            "weights load time : 67.118 ms\n",
            "DNN execution time: 64.422 ms\n",
            "Inference accuracy: 0.980800\n",
            "[Executing] hhar\n",
            "weights load time : 62.438 ms\n",
            "DNN execution time: 49.685 ms\n",
            "Inference accuracy: 0.898575\n",
            "[Executing] svhn\n",
            "weights load time : 150.128 ms\n",
            "DNN execution time: 217.476 ms\n",
            "Inference accuracy: 0.814843\n",
            "total weights load time : 2554.767 ms\n",
            "total DNN execution time: 20380.330 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBII3iLut3fR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ethum8Dt3Zq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzJDQWLensyi",
        "outputId": "c6db5362-8141-484e-834f-eed7eed66a6d"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XRvw9Nzns3S",
        "outputId": "1e32dcf2-3d3a-4aac-a1c3-449c638e1b91"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NeuralWeightVirtualization  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPK04Aouns7c",
        "outputId": "b15559e8-358c-4f40-853a-04868f707c7b"
      },
      "source": [
        "!zip -r ./NeuralWeightVirtualization.zip ./NeuralWeightVirtualization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: NeuralWeightVirtualization/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/weight_page_occupation.npy (deflated 60%)\n",
            "  adding: NeuralWeightVirtualization/hhar_matching_ten_nets.txt (deflated 78%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation.so (deflated 64%)\n",
            "  adding: NeuralWeightVirtualization/cifar10_data.py (deflated 72%)\n",
            "  adding: NeuralWeightVirtualization/GSC_v2_test_data.npy (deflated 6%)\n",
            "  adding: NeuralWeightVirtualization/cifar10_accuracy_ten_nets.txt (deflated 63%)\n",
            "  adding: NeuralWeightVirtualization/svhn/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/svhn/svhn_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/svhn/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/svhn/svhn_network_fisher.npy (deflated 22%)\n",
            "  adding: NeuralWeightVirtualization/svhn/svhn_network_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/svhn/svhn.meta (deflated 93%)\n",
            "  adding: NeuralWeightVirtualization/svhn/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/svhn/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/svhn/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/svhn/svhn.data-00000-of-00001 (deflated 8%)\n",
            "  adding: NeuralWeightVirtualization/svhn/svhn.index (deflated 47%)\n",
            "  adding: NeuralWeightVirtualization/svhn/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/hhar_train_label.npy (deflated 98%)\n",
            "  adding: NeuralWeightVirtualization/cifar10.vnn (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/cifar10_test_data.npy (deflated 82%)\n",
            "  adding: NeuralWeightVirtualization/L46_Project_Notebook.ipynb (deflated 86%)\n",
            "  adding: NeuralWeightVirtualization/esc10_test_data.npy (deflated 8%)\n",
            "  adding: NeuralWeightVirtualization/mnist.accuracy (deflated 9%)\n",
            "  adding: NeuralWeightVirtualization/fmnist_matching_ten_nets.txt (deflated 78%)\n",
            "  adding: NeuralWeightVirtualization/fmnist_test_data.npy (deflated 88%)\n",
            "  adding: NeuralWeightVirtualization/virtual_weight_page.npy (deflated 7%)\n",
            "  adding: NeuralWeightVirtualization/svhn_accuracy_ten_nets.txt (deflated 58%)\n",
            "  adding: NeuralWeightVirtualization/mnist_matching_ten_nets.txt (deflated 77%)\n",
            "  adding: NeuralWeightVirtualization/obstacle_train_data.npy (deflated 85%)\n",
            "  adding: NeuralWeightVirtualization/svhn_validation_label.npy (deflated 97%)\n",
            "  adding: NeuralWeightVirtualization/joint_optimization.sh (deflated 84%)\n",
            "  adding: NeuralWeightVirtualization/esc10/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/esc10/esc10.index (deflated 46%)\n",
            "  adding: NeuralWeightVirtualization/esc10/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/esc10/esc10.meta (deflated 93%)\n",
            "  adding: NeuralWeightVirtualization/esc10/esc10.data-00000-of-00001 (deflated 7%)\n",
            "  adding: NeuralWeightVirtualization/esc10/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/esc10/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/esc10/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/esc10/esc10_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/esc10/esc10_network_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/esc10/esc10_network_fisher.npy (deflated 21%)\n",
            "  adding: NeuralWeightVirtualization/esc10/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/svhn.vnn (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/hhar.accuracy (deflated 21%)\n",
            "  adding: NeuralWeightVirtualization/cifar10_train_label.npy (deflated 98%)\n",
            "  adding: NeuralWeightVirtualization/hhar_test_label.npy (deflated 98%)\n",
            "  adding: NeuralWeightVirtualization/svhn_test_label.npy (deflated 97%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/gtsrb_network_fisher.npy (deflated 22%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/gtsrb.meta (deflated 90%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/gtsrb.data-00000-of-00001 (deflated 7%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/gtsrb_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/gtsrb_network_weight.npy (deflated 26%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/gtsrb.index (deflated 47%)\n",
            "  adding: NeuralWeightVirtualization/GTSRB_data.py (deflated 71%)\n",
            "  adding: NeuralWeightVirtualization/GSC_v2_validation_label.npy (deflated 99%)\n",
            "  adding: NeuralWeightVirtualization/GTSRB_train_label.npy (deflated 99%)\n",
            "  adding: NeuralWeightVirtualization/weight_virtualization.py (deflated 82%)\n",
            "  adding: NeuralWeightVirtualization/obstacle_test_data.npy (deflated 85%)\n",
            "  adding: NeuralWeightVirtualization/MNIST_data/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/MNIST_data/t10k-labels-idx1-ubyte.gz (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/MNIST_data/t10k-images-idx3-ubyte.gz (deflated 0%)\n",
            "  adding: NeuralWeightVirtualization/MNIST_data/train-images-idx3-ubyte.gz (deflated 0%)\n",
            "  adding: NeuralWeightVirtualization/MNIST_data/train-labels-idx1-ubyte.gz (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/obstacle_train_label.npy (deflated 100%)\n",
            "  adding: NeuralWeightVirtualization/US8K_test_label.npy (deflated 100%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb_matching_ten_nets.txt (deflated 77%)\n",
            "  adding: NeuralWeightVirtualization/gsc.accuracy (deflated 19%)\n",
            "  adding: NeuralWeightVirtualization/baseline_execute.py (deflated 62%)\n",
            "  adding: NeuralWeightVirtualization/gsc_accuracy_ten_nets.txt (deflated 56%)\n",
            "  adding: NeuralWeightVirtualization/README.md (deflated 73%)\n",
            "  adding: NeuralWeightVirtualization/cifar10_test_label.npy (deflated 98%)\n",
            "  adding: NeuralWeightVirtualization/GSC_v2_data.py (deflated 70%)\n",
            "  adding: NeuralWeightVirtualization/hhar_test_data.npy (deflated 37%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/GSC_v2_data.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/GTSRB_data.cpython-36.pyc (deflated 47%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/obstacle_data.cpython-36.pyc (deflated 54%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/esc10_data.cpython-36.pyc (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/mnist_data.cpython-36.pyc (deflated 48%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/svhn_data.cpython-36.pyc (deflated 54%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/fmnist_data.cpython-36.pyc (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/hhar_data.cpython-36.pyc (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/cifar10_data.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/us8k_data.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/mnist_accuracy_ten_nets.txt (deflated 88%)\n",
            "  adding: NeuralWeightVirtualization/svhn_train_label.npy (deflated 97%)\n",
            "  adding: NeuralWeightVirtualization/err.log (deflated 89%)\n",
            "  adding: NeuralWeightVirtualization/hhar_data.py (deflated 71%)\n",
            "  adding: NeuralWeightVirtualization/mnist_data.py (deflated 53%)\n",
            "  adding: NeuralWeightVirtualization/hhar_accuracy_ten_nets.txt (deflated 57%)\n",
            "  adding: NeuralWeightVirtualization/us8k/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/us8k/us8k.index (deflated 45%)\n",
            "  adding: NeuralWeightVirtualization/us8k/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/us8k/us8k_network_fisher.npy (deflated 22%)\n",
            "  adding: NeuralWeightVirtualization/us8k/us8k_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/us8k/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/us8k/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/us8k/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/us8k/us8k_network_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/us8k/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/us8k/us8k.data-00000-of-00001 (deflated 8%)\n",
            "  adding: NeuralWeightVirtualization/us8k/us8k.meta (deflated 92%)\n",
            "  adding: NeuralWeightVirtualization/fmnist_data.py (deflated 72%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb.accuracy (deflated 18%)\n",
            "  adding: NeuralWeightVirtualization/GSC_v2_test_label.npy (deflated 99%)\n",
            "  adding: NeuralWeightVirtualization/GTSRB_test_data.npy (deflated 79%)\n",
            "  adding: NeuralWeightVirtualization/obs_matching_ten_nets.txt (deflated 80%)\n",
            "  adding: NeuralWeightVirtualization/esc10_matching_ten_nets.txt (deflated 80%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb.vnn (deflated 51%)\n",
            "  adding: NeuralWeightVirtualization/gsc/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/gsc/gsc.meta (deflated 90%)\n",
            "  adding: NeuralWeightVirtualization/gsc/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/gsc/gsc.data-00000-of-00001 (deflated 8%)\n",
            "  adding: NeuralWeightVirtualization/gsc/gsc_network_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/gsc/gsc_network_fisher.npy (deflated 22%)\n",
            "  adding: NeuralWeightVirtualization/gsc/gsc_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/gsc/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/gsc/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/gsc/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/gsc/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/gsc/gsc.index (deflated 44%)\n",
            "  adding: NeuralWeightVirtualization/obstacle_validation_label.npy (deflated 100%)\n",
            "  adding: NeuralWeightVirtualization/hhar_train_data.npy (deflated 38%)\n",
            "  adding: NeuralWeightVirtualization/fmnist_test_label.npy (deflated 97%)\n",
            "  adding: NeuralWeightVirtualization/esc10_accuracy_ten_nets.txt (deflated 58%)\n",
            "  adding: NeuralWeightVirtualization/obstacle_data.py (deflated 76%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/cifar10.data-00000-of-00001 (deflated 8%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/cifar10_network_fisher.npy (deflated 22%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/cifar10_network_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/cifar10_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/cifar10.index (deflated 47%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/cifar10.meta (deflated 91%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb_accuracy_ten_nets.txt (deflated 56%)\n",
            "  adding: NeuralWeightVirtualization/GSC_v2_train_data.npy (deflated 6%)\n",
            "  adding: NeuralWeightVirtualization/GTSRB_train_data.npy (deflated 79%)\n",
            "  adding: NeuralWeightVirtualization/esc10.vnn (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/cifar10_train_data.npy (deflated 82%)\n",
            "  adding: NeuralWeightVirtualization/svhn.accuracy (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/US8K_train_data.npy (deflated 61%)\n",
            "  adding: NeuralWeightVirtualization/us8k.accuracy (deflated 22%)\n",
            "  adding: NeuralWeightVirtualization/us8k_accuracy_ten_nets.txt (deflated 57%)\n",
            "  adding: NeuralWeightVirtualization/us8k_matching_ten_nets.txt (deflated 78%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/tf_operation.so (deflated 64%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/weight_loader.cu.o (deflated 64%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/build_tf_operation.sh (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/tf_operation.cu (deflated 82%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/weight_loader.c (deflated 59%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/weight_loader.cu (deflated 54%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/tf_operation.cu.o (deflated 64%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/build_tf_operation_nano.sh (deflated 47%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/build_weight_loader_nano.sh (deflated 43%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/tf_operation.cc (deflated 85%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/build_weight_loader.sh (deflated 43%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/weight_loader.so (deflated 68%)\n",
            "  adding: NeuralWeightVirtualization/fmnist_train_label.npy (deflated 97%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/fmnist_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/fmnist_network_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/fmnist.meta (deflated 93%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/fmnist_network_fisher.npy (deflated 21%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/fmnist.index (deflated 46%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/fmnist.data-00000-of-00001 (deflated 7%)\n",
            "  adding: NeuralWeightVirtualization/esc10.accuracy (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/svhn_validation_data.npy (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/cifar10_matching_ten_nets.txt (deflated 77%)\n",
            "  adding: NeuralWeightVirtualization/us8k.vnn (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/hhar/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/hhar/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/hhar/hhar.data-00000-of-00001 (deflated 6%)\n",
            "  adding: NeuralWeightVirtualization/hhar/hhar_network_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/hhar/hhar_network_fisher.npy (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/hhar/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/hhar/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/hhar/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/hhar/hhar.index (deflated 45%)\n",
            "  adding: NeuralWeightVirtualization/hhar/hhar_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/hhar/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/hhar/hhar.meta (deflated 92%)\n",
            "  adding: NeuralWeightVirtualization/fmnist_train_data.npy (deflated 88%)\n",
            "  adding: NeuralWeightVirtualization/out_ten_nets.log (deflated 86%)\n",
            "  adding: NeuralWeightVirtualization/obs.vnn (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/svhn_matching_ten_nets.txt (deflated 78%)\n",
            "  adding: NeuralWeightVirtualization/hhar.vnn (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/GSC_v2_validation_data.npy (deflated 6%)\n",
            "  adding: NeuralWeightVirtualization/.gitignore (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/obs/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/obs/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/obs/obs_network_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/obs/obs.meta (deflated 91%)\n",
            "  adding: NeuralWeightVirtualization/obs/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/obs/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/obs/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/obs/obs.index (deflated 48%)\n",
            "  adding: NeuralWeightVirtualization/obs/obs.data-00000-of-00001 (deflated 7%)\n",
            "  adding: NeuralWeightVirtualization/obs/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/obs/obs_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/obs/obs_network_fisher.npy (deflated 21%)\n",
            "  adding: NeuralWeightVirtualization/obs_accuracy_ten_nets.txt (deflated 62%)\n",
            "  adding: NeuralWeightVirtualization/fmnist_accuracy_ten_nets.txt (deflated 61%)\n",
            "  adding: NeuralWeightVirtualization/download_dataset.sh (deflated 87%)\n",
            "  adding: NeuralWeightVirtualization/GSC_v2_train_label.npy (deflated 99%)\n",
            "  adding: NeuralWeightVirtualization/obstacle_validation_data.npy (deflated 85%)\n",
            "  adding: NeuralWeightVirtualization/mnist/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/mnist/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/mnist/mnist_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/mnist/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/mnist/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/mnist/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/mnist/mnist.meta (deflated 91%)\n",
            "  adding: NeuralWeightVirtualization/mnist/mnist.data-00000-of-00001 (deflated 7%)\n",
            "  adding: NeuralWeightVirtualization/mnist/mnist.index (deflated 46%)\n",
            "  adding: NeuralWeightVirtualization/mnist/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/mnist/mnist_network_fisher.npy (deflated 21%)\n",
            "  adding: NeuralWeightVirtualization/mnist/mnist_network_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/in-memory_execute.py (deflated 70%)\n",
            "  adding: NeuralWeightVirtualization/.git/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/description (deflated 14%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/post-update.sample (deflated 27%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/pre-commit.sample (deflated 43%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/update.sample (deflated 68%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/pre-rebase.sample (deflated 59%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/fsmonitor-watchman.sample (deflated 53%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/pre-push.sample (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/commit-msg.sample (deflated 44%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/pre-receive.sample (deflated 40%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
            "  adding: NeuralWeightVirtualization/.git/info/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/info/exclude (deflated 28%)\n",
            "  adding: NeuralWeightVirtualization/.git/logs/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/logs/refs/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/logs/refs/remotes/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/logs/refs/remotes/origin/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/logs/refs/remotes/origin/HEAD (deflated 27%)\n",
            "  adding: NeuralWeightVirtualization/.git/logs/refs/heads/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/logs/refs/heads/master (deflated 27%)\n",
            "  adding: NeuralWeightVirtualization/.git/logs/HEAD (deflated 27%)\n",
            "  adding: NeuralWeightVirtualization/.git/objects/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/objects/info/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/objects/pack/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/objects/pack/pack-db02d4b6051da394f5f82a8f658ce6ab7f24806b.idx (deflated 11%)\n",
            "  adding: NeuralWeightVirtualization/.git/objects/pack/pack-db02d4b6051da394f5f82a8f658ce6ab7f24806b.pack (deflated 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/index (deflated 56%)\n",
            "  adding: NeuralWeightVirtualization/.git/branches/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/refs/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/refs/remotes/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/refs/remotes/origin/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/refs/remotes/origin/HEAD (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/refs/heads/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/refs/heads/master (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/refs/tags/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/config (deflated 31%)\n",
            "  adding: NeuralWeightVirtualization/.git/packed-refs (deflated 10%)\n",
            "  adding: NeuralWeightVirtualization/.git/HEAD (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/US8K_test_data.npy (deflated 58%)\n",
            "  adding: NeuralWeightVirtualization/mnist.vnn (deflated 57%)\n",
            "  adding: NeuralWeightVirtualization/us8k_data.py (deflated 70%)\n",
            "  adding: NeuralWeightVirtualization/esc10_train_label.npy (deflated 97%)\n",
            "  adding: NeuralWeightVirtualization/esc10_data.py (deflated 71%)\n",
            "  adding: NeuralWeightVirtualization/svhn_data.py (deflated 67%)\n",
            "  adding: NeuralWeightVirtualization/cifar10.accuracy (deflated 17%)\n",
            "  adding: NeuralWeightVirtualization/sequential_optimization.sh (deflated 92%)\n",
            "  adding: NeuralWeightVirtualization/gsc_matching_ten_nets.txt (deflated 77%)\n",
            "  adding: NeuralWeightVirtualization/svhn_test_data.npy (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/esc10_test_label.npy (deflated 97%)\n",
            "  adding: NeuralWeightVirtualization/obstacle_test_label.npy (deflated 100%)\n",
            "  adding: NeuralWeightVirtualization/fmnist.accuracy (deflated 12%)\n",
            "  adding: NeuralWeightVirtualization/esc10_train_data.npy (deflated 8%)\n",
            "  adding: NeuralWeightVirtualization/fmnist.vnn (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/svhn_train_data.npy (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/US8K_train_label.npy (deflated 100%)\n",
            "  adding: NeuralWeightVirtualization/GTSRB_test_label.npy (deflated 99%)\n",
            "  adding: NeuralWeightVirtualization/weight_loader.so (deflated 68%)\n",
            "  adding: NeuralWeightVirtualization/obs.accuracy (deflated 26%)\n",
            "  adding: NeuralWeightVirtualization/gsc.vnn (deflated 51%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P3VbNpzn5wE",
        "outputId": "68e146b4-1b75-4818-fb9b-80bf59a2c1d9"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NeuralWeightVirtualization  NeuralWeightVirtualization.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8xmIUjYpvYd",
        "outputId": "e3bfffa2-9c2b-473a-fd8f-2c49a237bca7"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NeuralWeightVirtualization  NeuralWeightVirtualization.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy-SmNBguiF0",
        "outputId": "72a1f115-884f-459a-b739-695dde8da5fc"
      },
      "source": [
        "!ls -la NeuralWeightVirtualization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 9124384\n",
            "drwxr-xr-x 16 root root       4096 Jan  1 23:58 .\n",
            "drwxr-xr-x  1 root root       4096 Jan  2 01:11 ..\n",
            "-rw-r--r--  1 root root       3341 Jan  1 23:14 baseline_execute.py\n",
            "drwxr-xr-x  3 root root       4096 Jan  1 23:35 cifar10\n",
            "-rw-r--r--  1 root root         35 Jan  2 00:47 cifar10.accuracy\n",
            "-rw-r--r--  1 root root        145 Jan  2 00:47 cifar10_accuracy_ten_nets.txt\n",
            "-rw-r--r--  1 root root       2721 Jan  1 23:14 cifar10_data.py\n",
            "-rw-r--r--  1 root root       4045 Jan  1 23:35 cifar10_matching_ten_nets.txt\n",
            "-rw-r--r--  1 root root  245760128 Jan  1 23:14 cifar10_test_data.npy\n",
            "-rw-r--r--  1 root root     800128 Jan  1 23:14 cifar10_test_label.npy\n",
            "-rw-r--r--  1 root root 1228800128 Jan  1 23:14 cifar10_train_data.npy\n",
            "-rw-r--r--  1 root root    4000128 Jan  1 23:14 cifar10_train_label.npy\n",
            "-rw-r--r--  1 root root       2935 Jan  1 23:35 cifar10.vnn\n",
            "-rwxr-xr-x  1 root root      13568 Jan  1 23:14 download_dataset.sh\n",
            "-rw-r--r--  1 root root       5475 Jan  2 00:43 err.log\n",
            "drwxr-xr-x  3 root root       4096 Jan  1 23:43 esc10\n",
            "-rw-r--r--  1 root root         50 Jan  2 00:50 esc10.accuracy\n",
            "-rw-r--r--  1 root root        145 Jan  2 00:50 esc10_accuracy_ten_nets.txt\n",
            "-rw-r--r--  1 root root       1901 Jan  1 23:14 esc10_data.py\n",
            "-rw-r--r--  1 root root       4312 Jan  1 23:43 esc10_matching_ten_nets.txt\n",
            "-rw-r--r--  1 root root   27630848 Jan  1 23:17 esc10_test_data.npy\n",
            "-rw-r--r--  1 root root      28208 Jan  1 23:17 esc10_test_label.npy\n",
            "-rw-r--r--  1 root root  248715968 Jan  1 23:18 esc10_train_data.npy\n",
            "-rw-r--r--  1 root root     252888 Jan  1 23:18 esc10_train_label.npy\n",
            "-rw-r--r--  1 root root       3683 Jan  1 23:43 esc10.vnn\n",
            "drwxr-xr-x  3 root root       4096 Jan  1 23:38 fmnist\n",
            "-rw-r--r--  1 root root         34 Jan  2 00:49 fmnist.accuracy\n",
            "-rw-r--r--  1 root root        145 Jan  2 00:49 fmnist_accuracy_ten_nets.txt\n",
            "-rw-r--r--  1 root root       1880 Jan  1 23:14 fmnist_data.py\n",
            "-rw-r--r--  1 root root       4109 Jan  1 23:38 fmnist_matching_ten_nets.txt\n",
            "-rw-r--r--  1 root root   62720128 Jan  1 23:16 fmnist_test_data.npy\n",
            "-rw-r--r--  1 root root     400128 Jan  1 23:16 fmnist_test_label.npy\n",
            "-rw-r--r--  1 root root  376320128 Jan  1 23:16 fmnist_train_data.npy\n",
            "-rw-r--r--  1 root root    2400128 Jan  1 23:16 fmnist_train_label.npy\n",
            "-rw-r--r--  1 root root       3895 Jan  1 23:38 fmnist.vnn\n",
            "drwxr-xr-x  8 root root       4096 Jan  1 23:14 .git\n",
            "-rw-r--r--  1 root root         14 Jan  1 23:14 .gitignore\n",
            "drwxr-xr-x  3 root root       4096 Jan  1 23:32 gsc\n",
            "-rw-r--r--  1 root root         53 Jan  2 00:46 gsc.accuracy\n",
            "-rw-r--r--  1 root root        145 Jan  2 00:46 gsc_accuracy_ten_nets.txt\n",
            "-rw-r--r--  1 root root       3888 Jan  1 23:32 gsc_matching_ten_nets.txt\n",
            "-rw-r--r--  1 root root       2711 Jan  1 23:14 GSC_v2_data.py\n",
            "-rw-r--r--  1 root root   69815848 Jan  1 23:15 GSC_v2_test_data.npy\n",
            "-rw-r--r--  1 root root    3081528 Jan  1 23:15 GSC_v2_test_label.npy\n",
            "-rw-r--r--  1 root root  538244120 Jan  1 23:15 GSC_v2_train_data.npy\n",
            "-rw-r--r--  1 root root   23756168 Jan  1 23:15 GSC_v2_train_label.npy\n",
            "-rw-r--r--  1 root root   63319592 Jan  1 23:15 GSC_v2_validation_data.npy\n",
            "-rw-r--r--  1 root root    2794808 Jan  1 23:15 GSC_v2_validation_label.npy\n",
            "-rw-r--r--  1 root root       3659 Jan  1 23:32 gsc.vnn\n",
            "drwxr-xr-x  3 root root       4096 Jan  1 23:33 gtsrb\n",
            "-rw-r--r--  1 root root         51 Jan  2 00:46 gtsrb.accuracy\n",
            "-rw-r--r--  1 root root        145 Jan  2 00:46 gtsrb_accuracy_ten_nets.txt\n",
            "-rw-r--r--  1 root root       2913 Jan  1 23:14 GTSRB_data.py\n",
            "-rw-r--r--  1 root root       3968 Jan  1 23:33 gtsrb_matching_ten_nets.txt\n",
            "-rw-r--r--  1 root root  103465088 Jan  1 23:15 GTSRB_test_data.npy\n",
            "-rw-r--r--  1 root root    4344848 Jan  1 23:15 GTSRB_test_label.npy\n",
            "-rw-r--r--  1 root root  321200256 Jan  1 23:15 GTSRB_train_data.npy\n",
            "-rw-r--r--  1 root root   13488024 Jan  1 23:15 GTSRB_train_label.npy\n",
            "-rw-r--r--  1 root root       3735 Jan  1 23:33 gtsrb.vnn\n",
            "drwxr-xr-x  3 root root       4096 Jan  1 23:42 hhar\n",
            "-rw-r--r--  1 root root         53 Jan  2 00:50 hhar.accuracy\n",
            "-rw-r--r--  1 root root        145 Jan  2 00:50 hhar_accuracy_ten_nets.txt\n",
            "-rw-r--r--  1 root root       1836 Jan  1 23:14 hhar_data.py\n",
            "-rw-r--r--  1 root root       4247 Jan  1 23:42 hhar_matching_ten_nets.txt\n",
            "-rw-r--r--  1 root root   22905728 Jan  1 23:17 hhar_test_data.npy\n",
            "-rw-r--r--  1 root root      57392 Jan  1 23:17 hhar_test_label.npy\n",
            "-rw-r--r--  1 root root 2286336128 Jan  1 23:17 hhar_train_data.npy\n",
            "-rw-r--r--  1 root root    5715968 Jan  1 23:17 hhar_train_label.npy\n",
            "-rw-r--r--  1 root root       3663 Jan  1 23:42 hhar.vnn\n",
            "-rw-r--r--  1 root root       6038 Jan  1 23:14 in-memory_execute.py\n",
            "-rwxr-xr-x  1 root root       2266 Jan  1 23:38 joint_optimization.sh\n",
            "-rw-r--r--  1 root root     262295 Jan  1 23:14 L46_Project_Notebook.ipynb\n",
            "drwxr-xr-x  3 root root       4096 Jan  1 23:28 mnist\n",
            "-rw-r--r--  1 root root         33 Jan  2 00:46 mnist.accuracy\n",
            "-rw-r--r--  1 root root       1115 Jan  2 00:46 mnist_accuracy_ten_nets.txt\n",
            "drwxr-xr-x  2 root root       4096 Jan  1 23:27 MNIST_data\n",
            "-rw-r--r--  1 root root        542 Jan  1 23:14 mnist_data.py\n",
            "-rw-r--r--  1 root root       4068 Jan  1 23:28 mnist_matching_ten_nets.txt\n",
            "-rw-r--r--  1 root root       2907 Jan  1 23:28 mnist.vnn\n",
            "drwxr-xr-x  3 root root       4096 Jan  1 23:44 obs\n",
            "-rw-r--r--  1 root root         54 Jan  2 00:51 obs.accuracy\n",
            "-rw-r--r--  1 root root        145 Jan  2 00:51 obs_accuracy_ten_nets.txt\n",
            "-rw-r--r--  1 root root       4374 Jan  1 23:44 obs_matching_ten_nets.txt\n",
            "-rw-r--r--  1 root root       2839 Jan  1 23:14 obstacle_data.py\n",
            "-rw-r--r--  1 root root   82224128 Jan  1 23:18 obstacle_test_data.npy\n",
            "-rw-r--r--  1 root root      91488 Jan  1 23:18 obstacle_test_label.npy\n",
            "-rw-r--r--  1 root root  164620928 Jan  1 23:18 obstacle_train_data.npy\n",
            "-rw-r--r--  1 root root     183040 Jan  1 23:18 obstacle_train_label.npy\n",
            "-rw-r--r--  1 root root   82224128 Jan  1 23:18 obstacle_validation_data.npy\n",
            "-rw-r--r--  1 root root      91488 Jan  1 23:18 obstacle_validation_label.npy\n",
            "-rw-r--r--  1 root root       3919 Jan  1 23:44 obs.vnn\n",
            "-rw-r--r--  1 root root     152029 Jan  2 00:45 out_ten_nets.log\n",
            "drwxr-xr-x  2 root root       4096 Jan  1 23:43 __pycache__\n",
            "-rw-r--r--  1 root root      20691 Jan  1 23:14 README.md\n",
            "-rwxr-xr-x  1 root root       1751 Jan  1 23:14 sequential_optimization.sh\n",
            "drwxr-xr-x  3 root root       4096 Jan  1 23:36 svhn\n",
            "-rw-r--r--  1 root root         54 Jan  2 00:48 svhn.accuracy\n",
            "-rw-r--r--  1 root root        145 Jan  2 00:48 svhn_accuracy_ten_nets.txt\n",
            "-rw-r--r--  1 root root        844 Jan  1 23:14 svhn_data.py\n",
            "-rw-r--r--  1 root root       3985 Jan  1 23:37 svhn_matching_ten_nets.txt\n",
            "-rw-r--r--  1 root root  319881344 Jan  1 23:15 svhn_test_data.npy\n",
            "-rw-r--r--  1 root root    1041408 Jan  1 23:15 svhn_test_label.npy\n",
            "-rw-r--r--  1 root root  810160256 Jan  1 23:15 svhn_train_data.npy\n",
            "-rw-r--r--  1 root root    2637368 Jan  1 23:15 svhn_train_label.npy\n",
            "-rw-r--r--  1 root root   90022016 Jan  1 23:15 svhn_validation_data.npy\n",
            "-rw-r--r--  1 root root     293168 Jan  1 23:15 svhn_validation_label.npy\n",
            "-rw-r--r--  1 root root       2875 Jan  1 23:36 svhn.vnn\n",
            "drwxr-xr-x  2 root root       4096 Jan  1 23:14 tf_operation\n",
            "-rwxr-xr-x  1 root root     149584 Jan  1 23:14 tf_operation.so\n",
            "drwxr-xr-x  3 root root       4096 Jan  1 23:40 us8k\n",
            "-rw-r--r--  1 root root         55 Jan  2 00:49 us8k.accuracy\n",
            "-rw-r--r--  1 root root        145 Jan  2 00:49 us8k_accuracy_ten_nets.txt\n",
            "-rw-r--r--  1 root root       1887 Jan  1 23:14 us8k_data.py\n",
            "-rw-r--r--  1 root root       4167 Jan  1 23:40 us8k_matching_ten_nets.txt\n",
            "-rw-r--r--  1 root root  212740928 Jan  1 23:15 US8K_test_data.npy\n",
            "-rw-r--r--  1 root root     432528 Jan  1 23:15 US8K_test_label.npy\n",
            "-rw-r--r--  1 root root 1914982208 Jan  1 23:16 US8K_train_data.npy\n",
            "-rw-r--r--  1 root root    3892368 Jan  1 23:16 US8K_train_label.npy\n",
            "-rw-r--r--  1 root root       3731 Jan  1 23:40 us8k.vnn\n",
            "-rw-r--r--  1 root root     288528 Jan  2 00:45 virtual_weight_page.npy\n",
            "-rwxr-xr-x  1 root root      18728 Jan  1 23:14 weight_loader.so\n",
            "-rw-r--r--  1 root root      81901 Jan  1 23:44 weight_page_occupation.npy\n",
            "-rw-r--r--  1 root root      43046 Jan  1 23:14 weight_virtualization.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvZQgpUtvuCu",
        "outputId": "6dd70731-5174-48a0-ba3a-859ddf70489a"
      },
      "source": [
        "%cd NeuralWeightVirtualization/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/NeuralWeightVirtualization\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2jPVTD3ux_C"
      },
      "source": [
        "!rm hhar_train_data.npy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzhwDNRFvr7E"
      },
      "source": [
        "!rm hhar_test_data.npy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79qhCJ06v4X8"
      },
      "source": [
        "!rm *_test_data.npy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjgdbGdlwRus"
      },
      "source": [
        "!rm *_train_data.npy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0veLsJAwUQb"
      },
      "source": [
        "!rm *_train_label.npy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfnXRqEQwWl8"
      },
      "source": [
        "!rm *_test_label.npy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6NovyRNwX88"
      },
      "source": [
        "!rm *_validation_data.npy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QEUOMuDwa-L"
      },
      "source": [
        "!rm *_validation_label.npy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JxOkPcgwceR",
        "outputId": "e677281c-1c54-40ad-e1cb-fc0abd8c9815"
      },
      "source": [
        "!zip -r ./NeuralWeightVirtualization.zip ./NeuralWeightVirtualization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tzip warning: name not matched: ./NeuralWeightVirtualization\n",
            "\n",
            "zip error: Nothing to do! (try: zip -r ./NeuralWeightVirtualization.zip . -i ./NeuralWeightVirtualization)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdYCh0FpwffZ",
        "outputId": "c0fc022e-64c6-429b-f6b6-9eddb16ecfe7"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Juri6RaiwhGM",
        "outputId": "92c28b9e-90b6-4450-9f2b-fa211d6af300"
      },
      "source": [
        "!zip -r ./NeuralWeightVirtualization.zip ./NeuralWeightVirtualization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: NeuralWeightVirtualization/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/weight_page_occupation.npy (deflated 60%)\n",
            "updating: NeuralWeightVirtualization/hhar_matching_ten_nets.txt (deflated 78%)\n",
            "updating: NeuralWeightVirtualization/tf_operation.so (deflated 64%)\n",
            "updating: NeuralWeightVirtualization/cifar10_data.py (deflated 72%)\n",
            "updating: NeuralWeightVirtualization/cifar10_accuracy_ten_nets.txt (deflated 63%)\n",
            "updating: NeuralWeightVirtualization/svhn/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/svhn/svhn_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/svhn/__init__.py (stored 0%)\n",
            "updating: NeuralWeightVirtualization/svhn/svhn_network_fisher.npy (deflated 22%)\n",
            "updating: NeuralWeightVirtualization/svhn/svhn_network_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/svhn/svhn.meta (deflated 93%)\n",
            "updating: NeuralWeightVirtualization/svhn/__pycache__/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/svhn/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "updating: NeuralWeightVirtualization/svhn/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "updating: NeuralWeightVirtualization/svhn/svhn.data-00000-of-00001 (deflated 8%)\n",
            "updating: NeuralWeightVirtualization/svhn/svhn.index (deflated 47%)\n",
            "updating: NeuralWeightVirtualization/svhn/pintle.py (deflated 69%)\n",
            "updating: NeuralWeightVirtualization/cifar10.vnn (deflated 50%)\n",
            "updating: NeuralWeightVirtualization/L46_Project_Notebook.ipynb (deflated 86%)\n",
            "updating: NeuralWeightVirtualization/mnist.accuracy (deflated 9%)\n",
            "updating: NeuralWeightVirtualization/fmnist_matching_ten_nets.txt (deflated 78%)\n",
            "updating: NeuralWeightVirtualization/virtual_weight_page.npy (deflated 7%)\n",
            "updating: NeuralWeightVirtualization/svhn_accuracy_ten_nets.txt (deflated 58%)\n",
            "updating: NeuralWeightVirtualization/mnist_matching_ten_nets.txt (deflated 77%)\n",
            "updating: NeuralWeightVirtualization/joint_optimization.sh (deflated 84%)\n",
            "updating: NeuralWeightVirtualization/esc10/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/esc10/esc10.index (deflated 46%)\n",
            "updating: NeuralWeightVirtualization/esc10/__init__.py (stored 0%)\n",
            "updating: NeuralWeightVirtualization/esc10/esc10.meta (deflated 93%)\n",
            "updating: NeuralWeightVirtualization/esc10/esc10.data-00000-of-00001 (deflated 7%)\n",
            "updating: NeuralWeightVirtualization/esc10/__pycache__/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/esc10/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "updating: NeuralWeightVirtualization/esc10/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "updating: NeuralWeightVirtualization/esc10/esc10_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/esc10/esc10_network_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/esc10/esc10_network_fisher.npy (deflated 21%)\n",
            "updating: NeuralWeightVirtualization/esc10/pintle.py (deflated 69%)\n",
            "updating: NeuralWeightVirtualization/svhn.vnn (deflated 49%)\n",
            "updating: NeuralWeightVirtualization/hhar.accuracy (deflated 21%)\n",
            "updating: NeuralWeightVirtualization/gtsrb/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/gtsrb/__init__.py (stored 0%)\n",
            "updating: NeuralWeightVirtualization/gtsrb/gtsrb_network_fisher.npy (deflated 22%)\n",
            "updating: NeuralWeightVirtualization/gtsrb/__pycache__/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/gtsrb/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "updating: NeuralWeightVirtualization/gtsrb/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "updating: NeuralWeightVirtualization/gtsrb/gtsrb.meta (deflated 90%)\n",
            "updating: NeuralWeightVirtualization/gtsrb/gtsrb.data-00000-of-00001 (deflated 7%)\n",
            "updating: NeuralWeightVirtualization/gtsrb/gtsrb_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/gtsrb/pintle.py (deflated 69%)\n",
            "updating: NeuralWeightVirtualization/gtsrb/gtsrb_network_weight.npy (deflated 26%)\n",
            "updating: NeuralWeightVirtualization/gtsrb/gtsrb.index (deflated 47%)\n",
            "updating: NeuralWeightVirtualization/GTSRB_data.py (deflated 71%)\n",
            "updating: NeuralWeightVirtualization/weight_virtualization.py (deflated 82%)\n",
            "updating: NeuralWeightVirtualization/MNIST_data/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/MNIST_data/t10k-labels-idx1-ubyte.gz (stored 0%)\n",
            "updating: NeuralWeightVirtualization/MNIST_data/t10k-images-idx3-ubyte.gz (deflated 0%)\n",
            "updating: NeuralWeightVirtualization/MNIST_data/train-images-idx3-ubyte.gz (deflated 0%)\n",
            "updating: NeuralWeightVirtualization/MNIST_data/train-labels-idx1-ubyte.gz (stored 0%)\n",
            "updating: NeuralWeightVirtualization/gtsrb_matching_ten_nets.txt (deflated 77%)\n",
            "updating: NeuralWeightVirtualization/gsc.accuracy (deflated 19%)\n",
            "updating: NeuralWeightVirtualization/baseline_execute.py (deflated 62%)\n",
            "updating: NeuralWeightVirtualization/gsc_accuracy_ten_nets.txt (deflated 56%)\n",
            "updating: NeuralWeightVirtualization/README.md (deflated 73%)\n",
            "updating: NeuralWeightVirtualization/GSC_v2_data.py (deflated 70%)\n",
            "updating: NeuralWeightVirtualization/__pycache__/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/__pycache__/GSC_v2_data.cpython-36.pyc (deflated 49%)\n",
            "updating: NeuralWeightVirtualization/__pycache__/GTSRB_data.cpython-36.pyc (deflated 47%)\n",
            "updating: NeuralWeightVirtualization/__pycache__/obstacle_data.cpython-36.pyc (deflated 54%)\n",
            "updating: NeuralWeightVirtualization/__pycache__/esc10_data.cpython-36.pyc (deflated 50%)\n",
            "updating: NeuralWeightVirtualization/__pycache__/mnist_data.cpython-36.pyc (deflated 48%)\n",
            "updating: NeuralWeightVirtualization/__pycache__/svhn_data.cpython-36.pyc (deflated 54%)\n",
            "updating: NeuralWeightVirtualization/__pycache__/fmnist_data.cpython-36.pyc (deflated 50%)\n",
            "updating: NeuralWeightVirtualization/__pycache__/hhar_data.cpython-36.pyc (deflated 50%)\n",
            "updating: NeuralWeightVirtualization/__pycache__/cifar10_data.cpython-36.pyc (deflated 49%)\n",
            "updating: NeuralWeightVirtualization/__pycache__/us8k_data.cpython-36.pyc (deflated 49%)\n",
            "updating: NeuralWeightVirtualization/mnist_accuracy_ten_nets.txt (deflated 88%)\n",
            "updating: NeuralWeightVirtualization/err.log (deflated 89%)\n",
            "updating: NeuralWeightVirtualization/hhar_data.py (deflated 71%)\n",
            "updating: NeuralWeightVirtualization/mnist_data.py (deflated 53%)\n",
            "updating: NeuralWeightVirtualization/hhar_accuracy_ten_nets.txt (deflated 57%)\n",
            "updating: NeuralWeightVirtualization/us8k/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/us8k/us8k.index (deflated 45%)\n",
            "updating: NeuralWeightVirtualization/us8k/__init__.py (stored 0%)\n",
            "updating: NeuralWeightVirtualization/us8k/us8k_network_fisher.npy (deflated 22%)\n",
            "updating: NeuralWeightVirtualization/us8k/us8k_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/us8k/__pycache__/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/us8k/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "updating: NeuralWeightVirtualization/us8k/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "updating: NeuralWeightVirtualization/us8k/us8k_network_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/us8k/pintle.py (deflated 69%)\n",
            "updating: NeuralWeightVirtualization/us8k/us8k.data-00000-of-00001 (deflated 8%)\n",
            "updating: NeuralWeightVirtualization/us8k/us8k.meta (deflated 92%)\n",
            "updating: NeuralWeightVirtualization/fmnist_data.py (deflated 72%)\n",
            "updating: NeuralWeightVirtualization/gtsrb.accuracy (deflated 18%)\n",
            "updating: NeuralWeightVirtualization/obs_matching_ten_nets.txt (deflated 80%)\n",
            "updating: NeuralWeightVirtualization/esc10_matching_ten_nets.txt (deflated 80%)\n",
            "updating: NeuralWeightVirtualization/gtsrb.vnn (deflated 51%)\n",
            "updating: NeuralWeightVirtualization/gsc/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/gsc/gsc.meta (deflated 90%)\n",
            "updating: NeuralWeightVirtualization/gsc/__init__.py (stored 0%)\n",
            "updating: NeuralWeightVirtualization/gsc/gsc.data-00000-of-00001 (deflated 8%)\n",
            "updating: NeuralWeightVirtualization/gsc/gsc_network_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/gsc/gsc_network_fisher.npy (deflated 22%)\n",
            "updating: NeuralWeightVirtualization/gsc/gsc_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/gsc/__pycache__/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/gsc/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "updating: NeuralWeightVirtualization/gsc/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "updating: NeuralWeightVirtualization/gsc/pintle.py (deflated 69%)\n",
            "updating: NeuralWeightVirtualization/gsc/gsc.index (deflated 44%)\n",
            "updating: NeuralWeightVirtualization/esc10_accuracy_ten_nets.txt (deflated 58%)\n",
            "updating: NeuralWeightVirtualization/obstacle_data.py (deflated 76%)\n",
            "updating: NeuralWeightVirtualization/cifar10/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/cifar10/cifar10.data-00000-of-00001 (deflated 8%)\n",
            "updating: NeuralWeightVirtualization/cifar10/__init__.py (stored 0%)\n",
            "updating: NeuralWeightVirtualization/cifar10/cifar10_network_fisher.npy (deflated 22%)\n",
            "updating: NeuralWeightVirtualization/cifar10/cifar10_network_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/cifar10/cifar10_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/cifar10/__pycache__/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/cifar10/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "updating: NeuralWeightVirtualization/cifar10/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "updating: NeuralWeightVirtualization/cifar10/pintle.py (deflated 69%)\n",
            "updating: NeuralWeightVirtualization/cifar10/cifar10.index (deflated 47%)\n",
            "updating: NeuralWeightVirtualization/cifar10/cifar10.meta (deflated 91%)\n",
            "updating: NeuralWeightVirtualization/gtsrb_accuracy_ten_nets.txt (deflated 56%)\n",
            "updating: NeuralWeightVirtualization/esc10.vnn (deflated 50%)\n",
            "updating: NeuralWeightVirtualization/svhn.accuracy (deflated 20%)\n",
            "updating: NeuralWeightVirtualization/us8k.accuracy (deflated 22%)\n",
            "updating: NeuralWeightVirtualization/us8k_accuracy_ten_nets.txt (deflated 57%)\n",
            "updating: NeuralWeightVirtualization/us8k_matching_ten_nets.txt (deflated 78%)\n",
            "updating: NeuralWeightVirtualization/tf_operation/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/tf_operation/tf_operation.so (deflated 64%)\n",
            "updating: NeuralWeightVirtualization/tf_operation/weight_loader.cu.o (deflated 64%)\n",
            "updating: NeuralWeightVirtualization/tf_operation/build_tf_operation.sh (deflated 49%)\n",
            "updating: NeuralWeightVirtualization/tf_operation/tf_operation.cu (deflated 82%)\n",
            "updating: NeuralWeightVirtualization/tf_operation/weight_loader.c (deflated 59%)\n",
            "updating: NeuralWeightVirtualization/tf_operation/weight_loader.cu (deflated 54%)\n",
            "updating: NeuralWeightVirtualization/tf_operation/tf_operation.cu.o (deflated 64%)\n",
            "updating: NeuralWeightVirtualization/tf_operation/build_tf_operation_nano.sh (deflated 47%)\n",
            "updating: NeuralWeightVirtualization/tf_operation/build_weight_loader_nano.sh (deflated 43%)\n",
            "updating: NeuralWeightVirtualization/tf_operation/tf_operation.cc (deflated 85%)\n",
            "updating: NeuralWeightVirtualization/tf_operation/build_weight_loader.sh (deflated 43%)\n",
            "updating: NeuralWeightVirtualization/tf_operation/weight_loader.so (deflated 68%)\n",
            "updating: NeuralWeightVirtualization/fmnist/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/fmnist/__init__.py (stored 0%)\n",
            "updating: NeuralWeightVirtualization/fmnist/fmnist_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/fmnist/fmnist_network_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/fmnist/fmnist.meta (deflated 93%)\n",
            "updating: NeuralWeightVirtualization/fmnist/__pycache__/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/fmnist/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "updating: NeuralWeightVirtualization/fmnist/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "updating: NeuralWeightVirtualization/fmnist/fmnist_network_fisher.npy (deflated 21%)\n",
            "updating: NeuralWeightVirtualization/fmnist/fmnist.index (deflated 46%)\n",
            "updating: NeuralWeightVirtualization/fmnist/pintle.py (deflated 69%)\n",
            "updating: NeuralWeightVirtualization/fmnist/fmnist.data-00000-of-00001 (deflated 7%)\n",
            "updating: NeuralWeightVirtualization/esc10.accuracy (deflated 20%)\n",
            "updating: NeuralWeightVirtualization/cifar10_matching_ten_nets.txt (deflated 77%)\n",
            "updating: NeuralWeightVirtualization/us8k.vnn (deflated 50%)\n",
            "updating: NeuralWeightVirtualization/hhar/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/hhar/__init__.py (stored 0%)\n",
            "updating: NeuralWeightVirtualization/hhar/hhar.data-00000-of-00001 (deflated 6%)\n",
            "updating: NeuralWeightVirtualization/hhar/hhar_network_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/hhar/hhar_network_fisher.npy (deflated 20%)\n",
            "updating: NeuralWeightVirtualization/hhar/__pycache__/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/hhar/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "updating: NeuralWeightVirtualization/hhar/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "updating: NeuralWeightVirtualization/hhar/hhar.index (deflated 45%)\n",
            "updating: NeuralWeightVirtualization/hhar/hhar_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/hhar/pintle.py (deflated 69%)\n",
            "updating: NeuralWeightVirtualization/hhar/hhar.meta (deflated 92%)\n",
            "updating: NeuralWeightVirtualization/out_ten_nets.log (deflated 86%)\n",
            "updating: NeuralWeightVirtualization/obs.vnn (deflated 50%)\n",
            "updating: NeuralWeightVirtualization/svhn_matching_ten_nets.txt (deflated 78%)\n",
            "updating: NeuralWeightVirtualization/hhar.vnn (deflated 50%)\n",
            "updating: NeuralWeightVirtualization/.gitignore (stored 0%)\n",
            "updating: NeuralWeightVirtualization/obs/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/obs/__init__.py (stored 0%)\n",
            "updating: NeuralWeightVirtualization/obs/obs_network_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/obs/obs.meta (deflated 91%)\n",
            "updating: NeuralWeightVirtualization/obs/__pycache__/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/obs/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "updating: NeuralWeightVirtualization/obs/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "updating: NeuralWeightVirtualization/obs/obs.index (deflated 48%)\n",
            "updating: NeuralWeightVirtualization/obs/obs.data-00000-of-00001 (deflated 7%)\n",
            "updating: NeuralWeightVirtualization/obs/pintle.py (deflated 69%)\n",
            "updating: NeuralWeightVirtualization/obs/obs_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/obs/obs_network_fisher.npy (deflated 21%)\n",
            "updating: NeuralWeightVirtualization/obs_accuracy_ten_nets.txt (deflated 62%)\n",
            "updating: NeuralWeightVirtualization/fmnist_accuracy_ten_nets.txt (deflated 61%)\n",
            "updating: NeuralWeightVirtualization/download_dataset.sh (deflated 87%)\n",
            "updating: NeuralWeightVirtualization/mnist/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/mnist/__init__.py (stored 0%)\n",
            "updating: NeuralWeightVirtualization/mnist/mnist_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/mnist/__pycache__/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/mnist/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "updating: NeuralWeightVirtualization/mnist/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "updating: NeuralWeightVirtualization/mnist/mnist.meta (deflated 91%)\n",
            "updating: NeuralWeightVirtualization/mnist/mnist.data-00000-of-00001 (deflated 7%)\n",
            "updating: NeuralWeightVirtualization/mnist/mnist.index (deflated 46%)\n",
            "updating: NeuralWeightVirtualization/mnist/pintle.py (deflated 69%)\n",
            "updating: NeuralWeightVirtualization/mnist/mnist_network_fisher.npy (deflated 21%)\n",
            "updating: NeuralWeightVirtualization/mnist/mnist_network_weight.npy (deflated 25%)\n",
            "updating: NeuralWeightVirtualization/in-memory_execute.py (deflated 70%)\n",
            "updating: NeuralWeightVirtualization/.git/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/description (deflated 14%)\n",
            "updating: NeuralWeightVirtualization/.git/hooks/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/hooks/post-update.sample (deflated 27%)\n",
            "updating: NeuralWeightVirtualization/.git/hooks/pre-commit.sample (deflated 43%)\n",
            "updating: NeuralWeightVirtualization/.git/hooks/update.sample (deflated 68%)\n",
            "updating: NeuralWeightVirtualization/.git/hooks/pre-rebase.sample (deflated 59%)\n",
            "updating: NeuralWeightVirtualization/.git/hooks/fsmonitor-watchman.sample (deflated 53%)\n",
            "updating: NeuralWeightVirtualization/.git/hooks/pre-push.sample (deflated 50%)\n",
            "updating: NeuralWeightVirtualization/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
            "updating: NeuralWeightVirtualization/.git/hooks/commit-msg.sample (deflated 44%)\n",
            "updating: NeuralWeightVirtualization/.git/hooks/pre-receive.sample (deflated 40%)\n",
            "updating: NeuralWeightVirtualization/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "updating: NeuralWeightVirtualization/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
            "updating: NeuralWeightVirtualization/.git/info/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/info/exclude (deflated 28%)\n",
            "updating: NeuralWeightVirtualization/.git/logs/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/logs/refs/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/logs/refs/remotes/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/logs/refs/remotes/origin/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/logs/refs/remotes/origin/HEAD (deflated 27%)\n",
            "updating: NeuralWeightVirtualization/.git/logs/refs/heads/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/logs/refs/heads/master (deflated 27%)\n",
            "updating: NeuralWeightVirtualization/.git/logs/HEAD (deflated 27%)\n",
            "updating: NeuralWeightVirtualization/.git/objects/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/objects/info/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/objects/pack/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/objects/pack/pack-db02d4b6051da394f5f82a8f658ce6ab7f24806b.idx (deflated 11%)\n",
            "updating: NeuralWeightVirtualization/.git/objects/pack/pack-db02d4b6051da394f5f82a8f658ce6ab7f24806b.pack (deflated 0%)\n",
            "updating: NeuralWeightVirtualization/.git/index (deflated 56%)\n",
            "updating: NeuralWeightVirtualization/.git/branches/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/refs/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/refs/remotes/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/refs/remotes/origin/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/refs/remotes/origin/HEAD (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/refs/heads/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/refs/heads/master (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/refs/tags/ (stored 0%)\n",
            "updating: NeuralWeightVirtualization/.git/config (deflated 31%)\n",
            "updating: NeuralWeightVirtualization/.git/packed-refs (deflated 10%)\n",
            "updating: NeuralWeightVirtualization/.git/HEAD (stored 0%)\n",
            "updating: NeuralWeightVirtualization/mnist.vnn (deflated 57%)\n",
            "updating: NeuralWeightVirtualization/us8k_data.py (deflated 70%)\n",
            "updating: NeuralWeightVirtualization/esc10_data.py (deflated 71%)\n",
            "updating: NeuralWeightVirtualization/svhn_data.py (deflated 67%)\n",
            "updating: NeuralWeightVirtualization/cifar10.accuracy (deflated 17%)\n",
            "updating: NeuralWeightVirtualization/sequential_optimization.sh (deflated 92%)\n",
            "updating: NeuralWeightVirtualization/gsc_matching_ten_nets.txt (deflated 77%)\n",
            "updating: NeuralWeightVirtualization/fmnist.accuracy (deflated 12%)\n",
            "updating: NeuralWeightVirtualization/fmnist.vnn (deflated 50%)\n",
            "updating: NeuralWeightVirtualization/weight_loader.so (deflated 68%)\n",
            "updating: NeuralWeightVirtualization/obs.accuracy (deflated 26%)\n",
            "updating: NeuralWeightVirtualization/gsc.vnn (deflated 51%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHGQjAPpwhgh",
        "outputId": "d4f622de-291d-42ae-c808-fd4d50fae8c0"
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4161444\n",
            "drwxr-xr-x  1 root root       4096 Jan  2 01:43 .\n",
            "drwxr-xr-x  1 root root       4096 Jan  1 23:06 ..\n",
            "drwxr-xr-x  1 root root       4096 Dec 21 17:29 .config\n",
            "drwxr-xr-x 16 root root       4096 Jan  2 01:41 NeuralWeightVirtualization\n",
            "-rw-r--r--  1 root root 4261291540 Jan  2 01:43 NeuralWeightVirtualization.zip\n",
            "drwxr-xr-x  1 root root       4096 Dec 21 17:29 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXDlBi7axJxy"
      },
      "source": [
        "rm NeuralWeightVirtualization.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWoCVGd8xP3P",
        "outputId": "01da5fa8-5301-476d-9268-ba16ae9d7cd4"
      },
      "source": [
        "!zip -r ./NeuralWeightVirtualization.zip ./NeuralWeightVirtualization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: NeuralWeightVirtualization/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/weight_page_occupation.npy (deflated 60%)\n",
            "  adding: NeuralWeightVirtualization/hhar_matching_ten_nets.txt (deflated 78%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation.so (deflated 64%)\n",
            "  adding: NeuralWeightVirtualization/cifar10_data.py (deflated 72%)\n",
            "  adding: NeuralWeightVirtualization/cifar10_accuracy_ten_nets.txt (deflated 63%)\n",
            "  adding: NeuralWeightVirtualization/svhn/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/svhn/svhn_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/svhn/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/svhn/svhn_network_fisher.npy (deflated 22%)\n",
            "  adding: NeuralWeightVirtualization/svhn/svhn_network_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/svhn/svhn.meta (deflated 93%)\n",
            "  adding: NeuralWeightVirtualization/svhn/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/svhn/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/svhn/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/svhn/svhn.data-00000-of-00001 (deflated 8%)\n",
            "  adding: NeuralWeightVirtualization/svhn/svhn.index (deflated 47%)\n",
            "  adding: NeuralWeightVirtualization/svhn/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/cifar10.vnn (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/L46_Project_Notebook.ipynb (deflated 86%)\n",
            "  adding: NeuralWeightVirtualization/mnist.accuracy (deflated 9%)\n",
            "  adding: NeuralWeightVirtualization/fmnist_matching_ten_nets.txt (deflated 78%)\n",
            "  adding: NeuralWeightVirtualization/virtual_weight_page.npy (deflated 7%)\n",
            "  adding: NeuralWeightVirtualization/svhn_accuracy_ten_nets.txt (deflated 58%)\n",
            "  adding: NeuralWeightVirtualization/mnist_matching_ten_nets.txt (deflated 77%)\n",
            "  adding: NeuralWeightVirtualization/joint_optimization.sh (deflated 84%)\n",
            "  adding: NeuralWeightVirtualization/esc10/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/esc10/esc10.index (deflated 46%)\n",
            "  adding: NeuralWeightVirtualization/esc10/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/esc10/esc10.meta (deflated 93%)\n",
            "  adding: NeuralWeightVirtualization/esc10/esc10.data-00000-of-00001 (deflated 7%)\n",
            "  adding: NeuralWeightVirtualization/esc10/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/esc10/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/esc10/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/esc10/esc10_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/esc10/esc10_network_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/esc10/esc10_network_fisher.npy (deflated 21%)\n",
            "  adding: NeuralWeightVirtualization/esc10/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/svhn.vnn (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/hhar.accuracy (deflated 21%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/gtsrb_network_fisher.npy (deflated 22%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/gtsrb.meta (deflated 90%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/gtsrb.data-00000-of-00001 (deflated 7%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/gtsrb_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/gtsrb_network_weight.npy (deflated 26%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb/gtsrb.index (deflated 47%)\n",
            "  adding: NeuralWeightVirtualization/GTSRB_data.py (deflated 71%)\n",
            "  adding: NeuralWeightVirtualization/weight_virtualization.py (deflated 82%)\n",
            "  adding: NeuralWeightVirtualization/MNIST_data/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/MNIST_data/t10k-labels-idx1-ubyte.gz (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/MNIST_data/t10k-images-idx3-ubyte.gz (deflated 0%)\n",
            "  adding: NeuralWeightVirtualization/MNIST_data/train-images-idx3-ubyte.gz (deflated 0%)\n",
            "  adding: NeuralWeightVirtualization/MNIST_data/train-labels-idx1-ubyte.gz (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb_matching_ten_nets.txt (deflated 77%)\n",
            "  adding: NeuralWeightVirtualization/gsc.accuracy (deflated 19%)\n",
            "  adding: NeuralWeightVirtualization/baseline_execute.py (deflated 62%)\n",
            "  adding: NeuralWeightVirtualization/gsc_accuracy_ten_nets.txt (deflated 56%)\n",
            "  adding: NeuralWeightVirtualization/README.md (deflated 73%)\n",
            "  adding: NeuralWeightVirtualization/GSC_v2_data.py (deflated 70%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/GSC_v2_data.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/GTSRB_data.cpython-36.pyc (deflated 47%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/obstacle_data.cpython-36.pyc (deflated 54%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/esc10_data.cpython-36.pyc (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/mnist_data.cpython-36.pyc (deflated 48%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/svhn_data.cpython-36.pyc (deflated 54%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/fmnist_data.cpython-36.pyc (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/hhar_data.cpython-36.pyc (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/cifar10_data.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/__pycache__/us8k_data.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/mnist_accuracy_ten_nets.txt (deflated 88%)\n",
            "  adding: NeuralWeightVirtualization/err.log (deflated 89%)\n",
            "  adding: NeuralWeightVirtualization/hhar_data.py (deflated 71%)\n",
            "  adding: NeuralWeightVirtualization/mnist_data.py (deflated 53%)\n",
            "  adding: NeuralWeightVirtualization/hhar_accuracy_ten_nets.txt (deflated 57%)\n",
            "  adding: NeuralWeightVirtualization/us8k/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/us8k/us8k.index (deflated 45%)\n",
            "  adding: NeuralWeightVirtualization/us8k/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/us8k/us8k_network_fisher.npy (deflated 22%)\n",
            "  adding: NeuralWeightVirtualization/us8k/us8k_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/us8k/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/us8k/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/us8k/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/us8k/us8k_network_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/us8k/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/us8k/us8k.data-00000-of-00001 (deflated 8%)\n",
            "  adding: NeuralWeightVirtualization/us8k/us8k.meta (deflated 92%)\n",
            "  adding: NeuralWeightVirtualization/fmnist_data.py (deflated 72%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb.accuracy (deflated 18%)\n",
            "  adding: NeuralWeightVirtualization/obs_matching_ten_nets.txt (deflated 80%)\n",
            "  adding: NeuralWeightVirtualization/esc10_matching_ten_nets.txt (deflated 80%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb.vnn (deflated 51%)\n",
            "  adding: NeuralWeightVirtualization/gsc/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/gsc/gsc.meta (deflated 90%)\n",
            "  adding: NeuralWeightVirtualization/gsc/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/gsc/gsc.data-00000-of-00001 (deflated 8%)\n",
            "  adding: NeuralWeightVirtualization/gsc/gsc_network_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/gsc/gsc_network_fisher.npy (deflated 22%)\n",
            "  adding: NeuralWeightVirtualization/gsc/gsc_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/gsc/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/gsc/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/gsc/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/gsc/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/gsc/gsc.index (deflated 44%)\n",
            "  adding: NeuralWeightVirtualization/esc10_accuracy_ten_nets.txt (deflated 58%)\n",
            "  adding: NeuralWeightVirtualization/obstacle_data.py (deflated 76%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/cifar10.data-00000-of-00001 (deflated 8%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/cifar10_network_fisher.npy (deflated 22%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/cifar10_network_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/cifar10_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/cifar10.index (deflated 47%)\n",
            "  adding: NeuralWeightVirtualization/cifar10/cifar10.meta (deflated 91%)\n",
            "  adding: NeuralWeightVirtualization/gtsrb_accuracy_ten_nets.txt (deflated 56%)\n",
            "  adding: NeuralWeightVirtualization/esc10.vnn (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/svhn.accuracy (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/us8k.accuracy (deflated 22%)\n",
            "  adding: NeuralWeightVirtualization/us8k_accuracy_ten_nets.txt (deflated 57%)\n",
            "  adding: NeuralWeightVirtualization/us8k_matching_ten_nets.txt (deflated 78%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/tf_operation.so (deflated 64%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/weight_loader.cu.o (deflated 64%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/build_tf_operation.sh (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/tf_operation.cu (deflated 82%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/weight_loader.c (deflated 59%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/weight_loader.cu (deflated 54%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/tf_operation.cu.o (deflated 64%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/build_tf_operation_nano.sh (deflated 47%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/build_weight_loader_nano.sh (deflated 43%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/tf_operation.cc (deflated 85%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/build_weight_loader.sh (deflated 43%)\n",
            "  adding: NeuralWeightVirtualization/tf_operation/weight_loader.so (deflated 68%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/fmnist_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/fmnist_network_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/fmnist.meta (deflated 93%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/fmnist_network_fisher.npy (deflated 21%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/fmnist.index (deflated 46%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/fmnist/fmnist.data-00000-of-00001 (deflated 7%)\n",
            "  adding: NeuralWeightVirtualization/esc10.accuracy (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/cifar10_matching_ten_nets.txt (deflated 77%)\n",
            "  adding: NeuralWeightVirtualization/us8k.vnn (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/hhar/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/hhar/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/hhar/hhar.data-00000-of-00001 (deflated 6%)\n",
            "  adding: NeuralWeightVirtualization/hhar/hhar_network_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/hhar/hhar_network_fisher.npy (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/hhar/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/hhar/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/hhar/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/hhar/hhar.index (deflated 45%)\n",
            "  adding: NeuralWeightVirtualization/hhar/hhar_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/hhar/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/hhar/hhar.meta (deflated 92%)\n",
            "  adding: NeuralWeightVirtualization/out_ten_nets.log (deflated 86%)\n",
            "  adding: NeuralWeightVirtualization/obs.vnn (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/svhn_matching_ten_nets.txt (deflated 78%)\n",
            "  adding: NeuralWeightVirtualization/hhar.vnn (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/.gitignore (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/obs/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/obs/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/obs/obs_network_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/obs/obs.meta (deflated 91%)\n",
            "  adding: NeuralWeightVirtualization/obs/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/obs/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/obs/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/obs/obs.index (deflated 48%)\n",
            "  adding: NeuralWeightVirtualization/obs/obs.data-00000-of-00001 (deflated 7%)\n",
            "  adding: NeuralWeightVirtualization/obs/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/obs/obs_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/obs/obs_network_fisher.npy (deflated 21%)\n",
            "  adding: NeuralWeightVirtualization/obs_accuracy_ten_nets.txt (deflated 62%)\n",
            "  adding: NeuralWeightVirtualization/fmnist_accuracy_ten_nets.txt (deflated 61%)\n",
            "  adding: NeuralWeightVirtualization/download_dataset.sh (deflated 87%)\n",
            "  adding: NeuralWeightVirtualization/mnist/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/mnist/__init__.py (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/mnist/mnist_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/mnist/__pycache__/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/mnist/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n",
            "  adding: NeuralWeightVirtualization/mnist/__pycache__/pintle.cpython-36.pyc (deflated 49%)\n",
            "  adding: NeuralWeightVirtualization/mnist/mnist.meta (deflated 91%)\n",
            "  adding: NeuralWeightVirtualization/mnist/mnist.data-00000-of-00001 (deflated 7%)\n",
            "  adding: NeuralWeightVirtualization/mnist/mnist.index (deflated 46%)\n",
            "  adding: NeuralWeightVirtualization/mnist/pintle.py (deflated 69%)\n",
            "  adding: NeuralWeightVirtualization/mnist/mnist_network_fisher.npy (deflated 21%)\n",
            "  adding: NeuralWeightVirtualization/mnist/mnist_network_weight.npy (deflated 25%)\n",
            "  adding: NeuralWeightVirtualization/in-memory_execute.py (deflated 70%)\n",
            "  adding: NeuralWeightVirtualization/.git/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/description (deflated 14%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/post-update.sample (deflated 27%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/pre-commit.sample (deflated 43%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/update.sample (deflated 68%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/pre-rebase.sample (deflated 59%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/fsmonitor-watchman.sample (deflated 53%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/pre-push.sample (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/commit-msg.sample (deflated 44%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/pre-receive.sample (deflated 40%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
            "  adding: NeuralWeightVirtualization/.git/info/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/info/exclude (deflated 28%)\n",
            "  adding: NeuralWeightVirtualization/.git/logs/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/logs/refs/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/logs/refs/remotes/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/logs/refs/remotes/origin/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/logs/refs/remotes/origin/HEAD (deflated 27%)\n",
            "  adding: NeuralWeightVirtualization/.git/logs/refs/heads/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/logs/refs/heads/master (deflated 27%)\n",
            "  adding: NeuralWeightVirtualization/.git/logs/HEAD (deflated 27%)\n",
            "  adding: NeuralWeightVirtualization/.git/objects/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/objects/info/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/objects/pack/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/objects/pack/pack-db02d4b6051da394f5f82a8f658ce6ab7f24806b.idx (deflated 11%)\n",
            "  adding: NeuralWeightVirtualization/.git/objects/pack/pack-db02d4b6051da394f5f82a8f658ce6ab7f24806b.pack (deflated 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/index (deflated 56%)\n",
            "  adding: NeuralWeightVirtualization/.git/branches/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/refs/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/refs/remotes/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/refs/remotes/origin/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/refs/remotes/origin/HEAD (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/refs/heads/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/refs/heads/master (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/refs/tags/ (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/.git/config (deflated 31%)\n",
            "  adding: NeuralWeightVirtualization/.git/packed-refs (deflated 10%)\n",
            "  adding: NeuralWeightVirtualization/.git/HEAD (stored 0%)\n",
            "  adding: NeuralWeightVirtualization/mnist.vnn (deflated 57%)\n",
            "  adding: NeuralWeightVirtualization/us8k_data.py (deflated 70%)\n",
            "  adding: NeuralWeightVirtualization/esc10_data.py (deflated 71%)\n",
            "  adding: NeuralWeightVirtualization/svhn_data.py (deflated 67%)\n",
            "  adding: NeuralWeightVirtualization/cifar10.accuracy (deflated 17%)\n",
            "  adding: NeuralWeightVirtualization/sequential_optimization.sh (deflated 92%)\n",
            "  adding: NeuralWeightVirtualization/gsc_matching_ten_nets.txt (deflated 77%)\n",
            "  adding: NeuralWeightVirtualization/fmnist.accuracy (deflated 12%)\n",
            "  adding: NeuralWeightVirtualization/fmnist.vnn (deflated 50%)\n",
            "  adding: NeuralWeightVirtualization/weight_loader.so (deflated 68%)\n",
            "  adding: NeuralWeightVirtualization/obs.accuracy (deflated 26%)\n",
            "  adding: NeuralWeightVirtualization/gsc.vnn (deflated 51%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhgZo2PxqQJG",
        "outputId": "d961877f-5734-47b2-92b1-24b6ee708b38"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoMXBE50xSHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f1098a0-0b80-48d3-9871-1c877844f0b8"
      },
      "source": [
        "!unzip ./NeuralWeightVirtualization2.zip"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./NeuralWeightVirtualization2.zip\n",
            "   creating: NeuralWeightVirtualization/\n",
            "  inflating: __MACOSX/._NeuralWeightVirtualization  \n",
            "   creating: NeuralWeightVirtualization/mnist/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._mnist  \n",
            "  inflating: NeuralWeightVirtualization/weight_virtualization.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._weight_virtualization.py  \n",
            "  inflating: NeuralWeightVirtualization/err.log  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._err.log  \n",
            "  inflating: NeuralWeightVirtualization/gsc_matching_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._gsc_matching_ten_nets.txt  \n",
            "  inflating: NeuralWeightVirtualization/mnist.accuracy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._mnist.accuracy  \n",
            "   creating: NeuralWeightVirtualization/MNIST_data/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._MNIST_data  \n",
            "  inflating: NeuralWeightVirtualization/gtsrb.accuracy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._gtsrb.accuracy  \n",
            "  inflating: NeuralWeightVirtualization/us8k.accuracy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._us8k.accuracy  \n",
            "   creating: NeuralWeightVirtualization/esc10/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._esc10  \n",
            "  inflating: NeuralWeightVirtualization/sequential_optimization.sh  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._sequential_optimization.sh  \n",
            "  inflating: NeuralWeightVirtualization/in-memory_execute.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._in-memory_execute.py  \n",
            "   creating: NeuralWeightVirtualization/svhn/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._svhn  \n",
            "  inflating: NeuralWeightVirtualization/joint_optimization.sh  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._joint_optimization.sh  \n",
            "  inflating: NeuralWeightVirtualization/obs_matching_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._obs_matching_ten_nets.txt  \n",
            "  inflating: NeuralWeightVirtualization/us8k_accuracy_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._us8k_accuracy_ten_nets.txt  \n",
            "  inflating: NeuralWeightVirtualization/obs.vnn  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._obs.vnn  \n",
            "  inflating: NeuralWeightVirtualization/.DS_Store  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._.DS_Store  \n",
            "  inflating: NeuralWeightVirtualization/esc10_matching_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._esc10_matching_ten_nets.txt  \n",
            "  inflating: NeuralWeightVirtualization/virtual_weight_page.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._virtual_weight_page.npy  \n",
            "  inflating: NeuralWeightVirtualization/hhar_matching_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._hhar_matching_ten_nets.txt  \n",
            "  inflating: NeuralWeightVirtualization/svhn.vnn  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._svhn.vnn  \n",
            "  inflating: NeuralWeightVirtualization/weight_loader.so  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._weight_loader.so  \n",
            "  inflating: NeuralWeightVirtualization/fmnist.vnn  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._fmnist.vnn  \n",
            "  inflating: NeuralWeightVirtualization/cifar10.accuracy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._cifar10.accuracy  \n",
            "  inflating: NeuralWeightVirtualization/cifar10_matching_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._cifar10_matching_ten_nets.txt  \n",
            "  inflating: NeuralWeightVirtualization/tf_operation.so  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._tf_operation.so  \n",
            "  inflating: NeuralWeightVirtualization/gtsrb_matching_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._gtsrb_matching_ten_nets.txt  \n",
            "  inflating: NeuralWeightVirtualization/cifar10_data.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._cifar10_data.py  \n",
            "  inflating: NeuralWeightVirtualization/fmnist_accuracy_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._fmnist_accuracy_ten_nets.txt  \n",
            "  inflating: NeuralWeightVirtualization/svhn_matching_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._svhn_matching_ten_nets.txt  \n",
            "   creating: NeuralWeightVirtualization/us8k/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._us8k  \n",
            "  inflating: NeuralWeightVirtualization/fmnist.accuracy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._fmnist.accuracy  \n",
            "  inflating: NeuralWeightVirtualization/mnist_matching_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._mnist_matching_ten_nets.txt  \n",
            "  inflating: NeuralWeightVirtualization/us8k.vnn  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._us8k.vnn  \n",
            "   creating: NeuralWeightVirtualization/hhar/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._hhar  \n",
            "  inflating: NeuralWeightVirtualization/hhar.accuracy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._hhar.accuracy  \n",
            "  inflating: NeuralWeightVirtualization/GTSRB_data.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._GTSRB_data.py  \n",
            "  inflating: NeuralWeightVirtualization/gsc.vnn  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._gsc.vnn  \n",
            "  inflating: NeuralWeightVirtualization/mnist_data.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._mnist_data.py  \n",
            "  inflating: NeuralWeightVirtualization/hhar_data.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._hhar_data.py  \n",
            "   creating: NeuralWeightVirtualization/__pycache__/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.___pycache__  \n",
            "  inflating: NeuralWeightVirtualization/cifar10.vnn  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._cifar10.vnn  \n",
            "  inflating: NeuralWeightVirtualization/obstacle_data.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._obstacle_data.py  \n",
            "  inflating: NeuralWeightVirtualization/README.md  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._README.md  \n",
            "  inflating: NeuralWeightVirtualization/us8k_matching_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._us8k_matching_ten_nets.txt  \n",
            "  inflating: NeuralWeightVirtualization/obs_accuracy_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._obs_accuracy_ten_nets.txt  \n",
            "   creating: NeuralWeightVirtualization/obs/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._obs  \n",
            "  inflating: NeuralWeightVirtualization/GSC_v2_data.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._GSC_v2_data.py  \n",
            "   creating: NeuralWeightVirtualization/fmnist/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._fmnist  \n",
            "  inflating: NeuralWeightVirtualization/esc10_accuracy_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._esc10_accuracy_ten_nets.txt  \n",
            "  inflating: NeuralWeightVirtualization/hhar_accuracy_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._hhar_accuracy_ten_nets.txt  \n",
            "  inflating: NeuralWeightVirtualization/L46_Project_Notebook.ipynb  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._L46_Project_Notebook.ipynb  \n",
            "  inflating: NeuralWeightVirtualization/download_dataset.sh  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._download_dataset.sh  \n",
            "  inflating: NeuralWeightVirtualization/fmnist_data.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._fmnist_data.py  \n",
            "  inflating: NeuralWeightVirtualization/hhar.vnn  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._hhar.vnn  \n",
            "  inflating: NeuralWeightVirtualization/.gitignore  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._.gitignore  \n",
            "  inflating: NeuralWeightVirtualization/cifar10_accuracy_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._cifar10_accuracy_ten_nets.txt  \n",
            "  inflating: NeuralWeightVirtualization/gsc_accuracy_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._gsc_accuracy_ten_nets.txt  \n",
            "  inflating: NeuralWeightVirtualization/obs.accuracy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._obs.accuracy  \n",
            "   creating: NeuralWeightVirtualization/gsc/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._gsc  \n",
            "  inflating: NeuralWeightVirtualization/weight_page_occupation.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._weight_page_occupation.npy  \n",
            "  inflating: NeuralWeightVirtualization/gsc.accuracy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._gsc.accuracy  \n",
            "  inflating: NeuralWeightVirtualization/baseline_execute.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._baseline_execute.py  \n",
            "   creating: NeuralWeightVirtualization/tf_operation/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._tf_operation  \n",
            "  inflating: NeuralWeightVirtualization/gtsrb.vnn  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._gtsrb.vnn  \n",
            "  inflating: NeuralWeightVirtualization/svhn_data.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._svhn_data.py  \n",
            "  inflating: NeuralWeightVirtualization/us8k_data.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._us8k_data.py  \n",
            "  inflating: NeuralWeightVirtualization/mnist.vnn  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._mnist.vnn  \n",
            "   creating: NeuralWeightVirtualization/.git/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._.git  \n",
            "   creating: NeuralWeightVirtualization/gtsrb/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._gtsrb  \n",
            "  inflating: NeuralWeightVirtualization/gtsrb_accuracy_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._gtsrb_accuracy_ten_nets.txt  \n",
            "  inflating: NeuralWeightVirtualization/esc10.accuracy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._esc10.accuracy  \n",
            "  inflating: NeuralWeightVirtualization/fmnist_matching_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._fmnist_matching_ten_nets.txt  \n",
            "  inflating: NeuralWeightVirtualization/svhn.accuracy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._svhn.accuracy  \n",
            "  inflating: NeuralWeightVirtualization/svhn_accuracy_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._svhn_accuracy_ten_nets.txt  \n",
            "  inflating: NeuralWeightVirtualization/mnist_accuracy_ten_nets.txt  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._mnist_accuracy_ten_nets.txt  \n",
            "  inflating: NeuralWeightVirtualization/esc10_data.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._esc10_data.py  \n",
            "  inflating: NeuralWeightVirtualization/out_ten_nets.log  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._out_ten_nets.log  \n",
            "  inflating: NeuralWeightVirtualization/esc10.vnn  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._esc10.vnn  \n",
            "   creating: NeuralWeightVirtualization/cifar10/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/._cifar10  \n",
            "  inflating: NeuralWeightVirtualization/mnist/mnist_network_fisher.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/mnist/._mnist_network_fisher.npy  \n",
            "  inflating: NeuralWeightVirtualization/mnist/pintle.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/mnist/._pintle.py  \n",
            "  inflating: NeuralWeightVirtualization/mnist/__init__.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/mnist/.___init__.py  \n",
            "   creating: NeuralWeightVirtualization/mnist/__pycache__/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/mnist/.___pycache__  \n",
            "  inflating: NeuralWeightVirtualization/mnist/mnist.index  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/mnist/._mnist.index  \n",
            "  inflating: NeuralWeightVirtualization/mnist/mnist_network_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/mnist/._mnist_network_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/mnist/mnist_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/mnist/._mnist_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/mnist/mnist.data-00000-of-00001  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/mnist/._mnist.data-00000-of-00001  \n",
            "  inflating: NeuralWeightVirtualization/mnist/mnist.meta  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/mnist/._mnist.meta  \n",
            "  inflating: NeuralWeightVirtualization/MNIST_data/t10k-images-idx3-ubyte.gz  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/MNIST_data/._t10k-images-idx3-ubyte.gz  \n",
            "  inflating: NeuralWeightVirtualization/MNIST_data/train-images-idx3-ubyte.gz  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/MNIST_data/._train-images-idx3-ubyte.gz  \n",
            "  inflating: NeuralWeightVirtualization/MNIST_data/train-labels-idx1-ubyte.gz  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/MNIST_data/._train-labels-idx1-ubyte.gz  \n",
            "  inflating: NeuralWeightVirtualization/MNIST_data/t10k-labels-idx1-ubyte.gz  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/MNIST_data/._t10k-labels-idx1-ubyte.gz  \n",
            "  inflating: NeuralWeightVirtualization/esc10/esc10.data-00000-of-00001  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/esc10/._esc10.data-00000-of-00001  \n",
            "  inflating: NeuralWeightVirtualization/esc10/esc10_network_fisher.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/esc10/._esc10_network_fisher.npy  \n",
            "  inflating: NeuralWeightVirtualization/esc10/pintle.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/esc10/._pintle.py  \n",
            "  inflating: NeuralWeightVirtualization/esc10/__init__.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/esc10/.___init__.py  \n",
            "  inflating: NeuralWeightVirtualization/esc10/esc10.meta  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/esc10/._esc10.meta  \n",
            "   creating: NeuralWeightVirtualization/esc10/__pycache__/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/esc10/.___pycache__  \n",
            "  inflating: NeuralWeightVirtualization/esc10/esc10_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/esc10/._esc10_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/esc10/esc10_network_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/esc10/._esc10_network_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/esc10/esc10.index  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/esc10/._esc10.index  \n",
            "  inflating: NeuralWeightVirtualization/svhn/svhn.index  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/svhn/._svhn.index  \n",
            "  inflating: NeuralWeightVirtualization/svhn/svhn.meta  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/svhn/._svhn.meta  \n",
            "  inflating: NeuralWeightVirtualization/svhn/svhn_network_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/svhn/._svhn_network_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/svhn/svhn_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/svhn/._svhn_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/svhn/svhn.data-00000-of-00001  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/svhn/._svhn.data-00000-of-00001  \n",
            "  inflating: NeuralWeightVirtualization/svhn/pintle.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/svhn/._pintle.py  \n",
            "  inflating: NeuralWeightVirtualization/svhn/__init__.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/svhn/.___init__.py  \n",
            "   creating: NeuralWeightVirtualization/svhn/__pycache__/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/svhn/.___pycache__  \n",
            "  inflating: NeuralWeightVirtualization/svhn/svhn_network_fisher.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/svhn/._svhn_network_fisher.npy  \n",
            "  inflating: NeuralWeightVirtualization/us8k/us8k_network_fisher.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/us8k/._us8k_network_fisher.npy  \n",
            "  inflating: NeuralWeightVirtualization/us8k/pintle.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/us8k/._pintle.py  \n",
            "  inflating: NeuralWeightVirtualization/us8k/__init__.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/us8k/.___init__.py  \n",
            "  inflating: NeuralWeightVirtualization/us8k/us8k.meta  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/us8k/._us8k.meta  \n",
            "   creating: NeuralWeightVirtualization/us8k/__pycache__/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/us8k/.___pycache__  \n",
            "  inflating: NeuralWeightVirtualization/us8k/us8k_network_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/us8k/._us8k_network_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/us8k/us8k.data-00000-of-00001  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/us8k/._us8k.data-00000-of-00001  \n",
            "  inflating: NeuralWeightVirtualization/us8k/us8k.index  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/us8k/._us8k.index  \n",
            "  inflating: NeuralWeightVirtualization/us8k/us8k_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/us8k/._us8k_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/hhar/hhar.index  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/hhar/._hhar.index  \n",
            "  inflating: NeuralWeightVirtualization/hhar/hhar_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/hhar/._hhar_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/hhar/pintle.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/hhar/._pintle.py  \n",
            "  inflating: NeuralWeightVirtualization/hhar/__init__.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/hhar/.___init__.py  \n",
            "  inflating: NeuralWeightVirtualization/hhar/hhar_network_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/hhar/._hhar_network_weight.npy  \n",
            "   creating: NeuralWeightVirtualization/hhar/__pycache__/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/hhar/.___pycache__  \n",
            "  inflating: NeuralWeightVirtualization/hhar/hhar.meta  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/hhar/._hhar.meta  \n",
            "  inflating: NeuralWeightVirtualization/hhar/hhar.data-00000-of-00001  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/hhar/._hhar.data-00000-of-00001  \n",
            "  inflating: NeuralWeightVirtualization/hhar/hhar_network_fisher.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/hhar/._hhar_network_fisher.npy  \n",
            "  inflating: NeuralWeightVirtualization/__pycache__/cifar10_data.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/__pycache__/._cifar10_data.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/__pycache__/svhn_data.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/__pycache__/._svhn_data.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/__pycache__/GTSRB_data.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/__pycache__/._GTSRB_data.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/__pycache__/esc10_data.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/__pycache__/._esc10_data.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/__pycache__/obstacle_data.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/__pycache__/._obstacle_data.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/__pycache__/hhar_data.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/__pycache__/._hhar_data.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/__pycache__/mnist_data.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/__pycache__/._mnist_data.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/__pycache__/us8k_data.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/__pycache__/._us8k_data.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/__pycache__/fmnist_data.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/__pycache__/._fmnist_data.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/__pycache__/GSC_v2_data.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/__pycache__/._GSC_v2_data.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/obs/obs.data-00000-of-00001  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/obs/._obs.data-00000-of-00001  \n",
            "  inflating: NeuralWeightVirtualization/obs/obs.index  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/obs/._obs.index  \n",
            "  inflating: NeuralWeightVirtualization/obs/pintle.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/obs/._pintle.py  \n",
            "  inflating: NeuralWeightVirtualization/obs/__init__.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/obs/.___init__.py  \n",
            "   creating: NeuralWeightVirtualization/obs/__pycache__/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/obs/.___pycache__  \n",
            "  inflating: NeuralWeightVirtualization/obs/obs_network_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/obs/._obs_network_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/obs/obs.meta  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/obs/._obs.meta  \n",
            "  inflating: NeuralWeightVirtualization/obs/obs_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/obs/._obs_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/obs/obs_network_fisher.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/obs/._obs_network_fisher.npy  \n",
            "  inflating: NeuralWeightVirtualization/fmnist/fmnist_network_fisher.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/fmnist/._fmnist_network_fisher.npy  \n",
            "  inflating: NeuralWeightVirtualization/fmnist/fmnist.meta  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/fmnist/._fmnist.meta  \n",
            "  inflating: NeuralWeightVirtualization/fmnist/pintle.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/fmnist/._pintle.py  \n",
            "  inflating: NeuralWeightVirtualization/fmnist/__init__.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/fmnist/.___init__.py  \n",
            "   creating: NeuralWeightVirtualization/fmnist/__pycache__/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/fmnist/.___pycache__  \n",
            "  inflating: NeuralWeightVirtualization/fmnist/fmnist.index  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/fmnist/._fmnist.index  \n",
            "  inflating: NeuralWeightVirtualization/fmnist/fmnist_network_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/fmnist/._fmnist_network_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/fmnist/fmnist_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/fmnist/._fmnist_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/fmnist/fmnist.data-00000-of-00001  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/fmnist/._fmnist.data-00000-of-00001  \n",
            "  inflating: NeuralWeightVirtualization/gsc/gsc.index  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gsc/._gsc.index  \n",
            "  inflating: NeuralWeightVirtualization/gsc/gsc.data-00000-of-00001  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gsc/._gsc.data-00000-of-00001  \n",
            "  inflating: NeuralWeightVirtualization/gsc/gsc_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gsc/._gsc_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/gsc/gsc_network_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gsc/._gsc_network_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/gsc/pintle.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gsc/._pintle.py  \n",
            "  inflating: NeuralWeightVirtualization/gsc/__init__.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gsc/.___init__.py  \n",
            "   creating: NeuralWeightVirtualization/gsc/__pycache__/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gsc/.___pycache__  \n",
            "  inflating: NeuralWeightVirtualization/gsc/gsc.meta  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gsc/._gsc.meta  \n",
            "  inflating: NeuralWeightVirtualization/gsc/gsc_network_fisher.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gsc/._gsc_network_fisher.npy  \n",
            "  inflating: NeuralWeightVirtualization/tf_operation/tf_operation.cu.o  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/tf_operation/._tf_operation.cu.o  \n",
            "  inflating: NeuralWeightVirtualization/tf_operation/build_tf_operation_nano.sh  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/tf_operation/._build_tf_operation_nano.sh  \n",
            "  inflating: NeuralWeightVirtualization/tf_operation/weight_loader.so  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/tf_operation/._weight_loader.so  \n",
            "  inflating: NeuralWeightVirtualization/tf_operation/build_weight_loader.sh  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/tf_operation/._build_weight_loader.sh  \n",
            "  inflating: NeuralWeightVirtualization/tf_operation/tf_operation.so  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/tf_operation/._tf_operation.so  \n",
            "  inflating: NeuralWeightVirtualization/tf_operation/weight_loader.cu.o  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/tf_operation/._weight_loader.cu.o  \n",
            "  inflating: NeuralWeightVirtualization/tf_operation/build_weight_loader_nano.sh  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/tf_operation/._build_weight_loader_nano.sh  \n",
            "  inflating: NeuralWeightVirtualization/tf_operation/tf_operation.cc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/tf_operation/._tf_operation.cc  \n",
            "  inflating: NeuralWeightVirtualization/tf_operation/weight_loader.c  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/tf_operation/._weight_loader.c  \n",
            "  inflating: NeuralWeightVirtualization/tf_operation/build_tf_operation.sh  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/tf_operation/._build_tf_operation.sh  \n",
            "  inflating: NeuralWeightVirtualization/tf_operation/weight_loader.cu  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/tf_operation/._weight_loader.cu  \n",
            "  inflating: NeuralWeightVirtualization/tf_operation/tf_operation.cu  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/tf_operation/._tf_operation.cu  \n",
            "  inflating: NeuralWeightVirtualization/.git/config  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/._config  \n",
            "   creating: NeuralWeightVirtualization/.git/objects/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/._objects  \n",
            "  inflating: NeuralWeightVirtualization/.git/HEAD  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/._HEAD  \n",
            "   creating: NeuralWeightVirtualization/.git/info/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/._info  \n",
            "   creating: NeuralWeightVirtualization/.git/logs/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/._logs  \n",
            "  inflating: NeuralWeightVirtualization/.git/description  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/._description  \n",
            "   creating: NeuralWeightVirtualization/.git/hooks/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/._hooks  \n",
            "   creating: NeuralWeightVirtualization/.git/refs/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/._refs  \n",
            "  inflating: NeuralWeightVirtualization/.git/index  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/._index  \n",
            "   creating: NeuralWeightVirtualization/.git/branches/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/._branches  \n",
            "  inflating: NeuralWeightVirtualization/.git/packed-refs  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/._packed-refs  \n",
            "  inflating: NeuralWeightVirtualization/gtsrb/gtsrb_network_fisher.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gtsrb/._gtsrb_network_fisher.npy  \n",
            "  inflating: NeuralWeightVirtualization/gtsrb/gtsrb.data-00000-of-00001  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gtsrb/._gtsrb.data-00000-of-00001  \n",
            "  inflating: NeuralWeightVirtualization/gtsrb/gtsrb_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gtsrb/._gtsrb_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/gtsrb/pintle.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gtsrb/._pintle.py  \n",
            "  inflating: NeuralWeightVirtualization/gtsrb/__init__.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gtsrb/.___init__.py  \n",
            "   creating: NeuralWeightVirtualization/gtsrb/__pycache__/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gtsrb/.___pycache__  \n",
            "  inflating: NeuralWeightVirtualization/gtsrb/gtsrb_network_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gtsrb/._gtsrb_network_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/gtsrb/gtsrb.index  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gtsrb/._gtsrb.index  \n",
            "  inflating: NeuralWeightVirtualization/gtsrb/gtsrb.meta  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gtsrb/._gtsrb.meta  \n",
            "  inflating: NeuralWeightVirtualization/cifar10/cifar10_network_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/cifar10/._cifar10_network_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/cifar10/cifar10.index  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/cifar10/._cifar10.index  \n",
            "  inflating: NeuralWeightVirtualization/cifar10/pintle.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/cifar10/._pintle.py  \n",
            "  inflating: NeuralWeightVirtualization/cifar10/cifar10.data-00000-of-00001  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/cifar10/._cifar10.data-00000-of-00001  \n",
            "  inflating: NeuralWeightVirtualization/cifar10/__init__.py  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/cifar10/.___init__.py  \n",
            "   creating: NeuralWeightVirtualization/cifar10/__pycache__/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/cifar10/.___pycache__  \n",
            "  inflating: NeuralWeightVirtualization/cifar10/cifar10_weight.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/cifar10/._cifar10_weight.npy  \n",
            "  inflating: NeuralWeightVirtualization/cifar10/cifar10_network_fisher.npy  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/cifar10/._cifar10_network_fisher.npy  \n",
            "  inflating: NeuralWeightVirtualization/cifar10/cifar10.meta  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/cifar10/._cifar10.meta  \n",
            "  inflating: NeuralWeightVirtualization/mnist/__pycache__/pintle.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/mnist/__pycache__/._pintle.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/mnist/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/mnist/__pycache__/.___init__.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/esc10/__pycache__/pintle.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/esc10/__pycache__/._pintle.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/esc10/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/esc10/__pycache__/.___init__.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/svhn/__pycache__/pintle.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/svhn/__pycache__/._pintle.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/svhn/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/svhn/__pycache__/.___init__.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/us8k/__pycache__/pintle.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/us8k/__pycache__/._pintle.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/us8k/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/us8k/__pycache__/.___init__.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/hhar/__pycache__/pintle.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/hhar/__pycache__/._pintle.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/hhar/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/hhar/__pycache__/.___init__.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/obs/__pycache__/pintle.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/obs/__pycache__/._pintle.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/obs/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/obs/__pycache__/.___init__.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/fmnist/__pycache__/pintle.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/fmnist/__pycache__/._pintle.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/fmnist/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/fmnist/__pycache__/.___init__.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/gsc/__pycache__/pintle.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gsc/__pycache__/._pintle.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/gsc/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gsc/__pycache__/.___init__.cpython-36.pyc  \n",
            "   creating: NeuralWeightVirtualization/.git/objects/pack/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/objects/._pack  \n",
            "   creating: NeuralWeightVirtualization/.git/objects/info/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/objects/._info  \n",
            "  inflating: NeuralWeightVirtualization/.git/info/exclude  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/info/._exclude  \n",
            "  inflating: NeuralWeightVirtualization/.git/logs/HEAD  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/logs/._HEAD  \n",
            "   creating: NeuralWeightVirtualization/.git/logs/refs/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/logs/._refs  \n",
            "  inflating: NeuralWeightVirtualization/.git/hooks/commit-msg.sample  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/hooks/._commit-msg.sample  \n",
            "  inflating: NeuralWeightVirtualization/.git/hooks/pre-rebase.sample  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/hooks/._pre-rebase.sample  \n",
            "  inflating: NeuralWeightVirtualization/.git/hooks/pre-commit.sample  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/hooks/._pre-commit.sample  \n",
            "  inflating: NeuralWeightVirtualization/.git/hooks/applypatch-msg.sample  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/hooks/._applypatch-msg.sample  \n",
            "  inflating: NeuralWeightVirtualization/.git/hooks/fsmonitor-watchman.sample  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/hooks/._fsmonitor-watchman.sample  \n",
            "  inflating: NeuralWeightVirtualization/.git/hooks/pre-receive.sample  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/hooks/._pre-receive.sample  \n",
            "  inflating: NeuralWeightVirtualization/.git/hooks/prepare-commit-msg.sample  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/hooks/._prepare-commit-msg.sample  \n",
            "  inflating: NeuralWeightVirtualization/.git/hooks/post-update.sample  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/hooks/._post-update.sample  \n",
            "  inflating: NeuralWeightVirtualization/.git/hooks/pre-applypatch.sample  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/hooks/._pre-applypatch.sample  \n",
            "  inflating: NeuralWeightVirtualization/.git/hooks/pre-push.sample  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/hooks/._pre-push.sample  \n",
            "  inflating: NeuralWeightVirtualization/.git/hooks/update.sample  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/hooks/._update.sample  \n",
            "   creating: NeuralWeightVirtualization/.git/refs/heads/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/refs/._heads  \n",
            "   creating: NeuralWeightVirtualization/.git/refs/tags/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/refs/._tags  \n",
            "   creating: NeuralWeightVirtualization/.git/refs/remotes/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/refs/._remotes  \n",
            "  inflating: NeuralWeightVirtualization/gtsrb/__pycache__/pintle.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gtsrb/__pycache__/._pintle.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/gtsrb/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/gtsrb/__pycache__/.___init__.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/cifar10/__pycache__/pintle.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/cifar10/__pycache__/._pintle.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/cifar10/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/cifar10/__pycache__/.___init__.cpython-36.pyc  \n",
            "  inflating: NeuralWeightVirtualization/.git/objects/pack/pack-db02d4b6051da394f5f82a8f658ce6ab7f24806b.pack  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/objects/pack/._pack-db02d4b6051da394f5f82a8f658ce6ab7f24806b.pack  \n",
            "  inflating: NeuralWeightVirtualization/.git/objects/pack/pack-db02d4b6051da394f5f82a8f658ce6ab7f24806b.idx  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/objects/pack/._pack-db02d4b6051da394f5f82a8f658ce6ab7f24806b.idx  \n",
            "   creating: NeuralWeightVirtualization/.git/logs/refs/heads/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/logs/refs/._heads  \n",
            "   creating: NeuralWeightVirtualization/.git/logs/refs/remotes/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/logs/refs/._remotes  \n",
            "  inflating: NeuralWeightVirtualization/.git/refs/heads/master  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/refs/heads/._master  \n",
            "   creating: NeuralWeightVirtualization/.git/refs/remotes/origin/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/refs/remotes/._origin  \n",
            "  inflating: NeuralWeightVirtualization/.git/logs/refs/heads/master  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/logs/refs/heads/._master  \n",
            "   creating: NeuralWeightVirtualization/.git/logs/refs/remotes/origin/\n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/logs/refs/remotes/._origin  \n",
            "  inflating: NeuralWeightVirtualization/.git/refs/remotes/origin/HEAD  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/refs/remotes/origin/._HEAD  \n",
            "  inflating: NeuralWeightVirtualization/.git/logs/refs/remotes/origin/HEAD  \n",
            "  inflating: __MACOSX/NeuralWeightVirtualization/.git/logs/refs/remotes/origin/._HEAD  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HwBWAkkqSxj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}