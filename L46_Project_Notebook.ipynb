{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L46_Project_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM5mmAMtKknKW+ieWzi8FrW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/K0rnel/NeuralWeightVirtualization/blob/master/L46_Project_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M56qZ7aEFnyw"
      },
      "source": [
        "# L46 Project Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4u-mwxE5C27"
      },
      "source": [
        "##1. Setup\n",
        "To setup the Colab runtime for this project, first ensure that the **GPU runtime** is selected.\n",
        "\n",
        "Following that, run the cells below to ensure the version compatibility of TensorFlow and Numpy packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrqYQU7EfeIu",
        "outputId": "e7f7f303-f51c-46ce-e6fb-c6a35ed30021"
      },
      "source": [
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow-gpu==1.13.1\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.16.4\n",
        "import numpy as np\n",
        "print(np.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "1.16.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHfq_v77A6V"
      },
      "source": [
        "Next, clone the data from the GitHub repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss16WRzhEfoB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0a225a4-bcb3-4218-fac6-af356bd91bfa"
      },
      "source": [
        "!git clone https://github.com/K0rnel/NeuralWeightVirtualization"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NeuralWeightVirtualization'...\n",
            "remote: Enumerating objects: 122, done.\u001b[K\n",
            "remote: Counting objects: 100% (122/122), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 122 (delta 39), reused 93 (delta 20), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (122/122), 7.91 MiB | 3.49 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtY_vZ9IgLZE",
        "outputId": "093dcbda-f772-4be9-f715-754074092b4c"
      },
      "source": [
        "%cd NeuralWeightVirtualization"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/NeuralWeightVirtualization\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW0QJCo7gSGA",
        "outputId": "9121d336-0c48-4d7f-d976-3ddb05bead3e"
      },
      "source": [
        "ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "baseline_execute_6networks.py   \u001b[0m\u001b[01;34mmnist\u001b[0m/\n",
            "baseline_execute.py             mnist_data.py\n",
            "\u001b[01;34mcifar10\u001b[0m/                        README.md\n",
            "cifar10_data.py                 \u001b[01;32msequential_optimization.sh\u001b[0m*\n",
            "\u001b[01;32mdownload_dataset.sh\u001b[0m*            \u001b[01;34msvhn\u001b[0m/\n",
            "\u001b[01;34mgsc\u001b[0m/                            svhn_data.py\n",
            "GSC_v2_data.py                  \u001b[01;34mtf_operation\u001b[0m/\n",
            "\u001b[01;34mgtsrb\u001b[0m/                          \u001b[01;32mtf_operation.so\u001b[0m*\n",
            "GTSRB_data.py                   \u001b[01;34mus8k\u001b[0m/\n",
            "in-memory_execute_6networks.py  us8k_data.py\n",
            "in-memory_execute.py            \u001b[01;32mweight_loader.so\u001b[0m*\n",
            "\u001b[01;32mjoint_optimization.sh\u001b[0m*          weight_virtualization.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0qoxko47Ssw"
      },
      "source": [
        "##2. Download datasets\n",
        "Before getting into the weight virtualization, download the required datasets by executing the following script (download_dataset.sh). The script uses curl for downloading the datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soJe5nUlgS5o",
        "outputId": "cbb51c30-48c1-492c-de1e-26e721a5b667"
      },
      "source": [
        "!sh download_dataset.sh"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1/5] Downloading CIFAR10 dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1085      0 --:--:-- --:--:-- --:--:--  1082\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100  234M    0  234M    0     0  36.9M      0 --:--:--  0:00:06 --:--:-- 71.5M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    400      0 --:--:--  0:00:01 --:--:--   400\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100  781k  100  781k    0     0   270k      0  0:00:02  0:00:02 --:--:--  334M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1162      0 --:--:-- --:--:-- --:--:--  1162\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 1171M    0 1171M    0     0  62.3M      0 --:--:--  0:00:18 --:--:-- 67.4M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    443      0 --:--:-- --:--:-- --:--:--   442\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 3906k    0 3906k    0     0  2188k      0 --:--:--  0:00:01 --:--:-- 2188k\n",
            "\n",
            "[2/5] Downloading Google Speech Command V2 dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    225      0 --:--:--  0:00:01 --:--:--   225\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0\n",
            "100 66.5M    0 66.5M    0     0  16.6M      0 --:--:--  0:00:04 --:--:--  231M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    376      0 --:--:--  0:00:01 --:--:--   376\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100 3009k    0 3009k    0     0  1026k      0 --:--:--  0:00:02 --:--:--  165M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1267      0 --:--:-- --:--:-- --:--:--  1267\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100  513M    0  513M    0     0  45.6M      0 --:--:--  0:00:11 --:--:-- 68.3M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    309      0 --:--:--  0:00:01 --:--:--   309\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100 22.6M    0 22.6M    0     0  7164k      0 --:--:--  0:00:03 --:--:--  341M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    204      0 --:--:--  0:00:01 --:--:--   204\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100 60.3M    0 60.3M    0     0  17.4M      0 --:--:--  0:00:03 --:--:--  143M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    498      0 --:--:-- --:--:-- --:--:--   498\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100 2729k    0 2729k    0     0  1056k      0 --:--:--  0:00:02 --:--:-- 1056k\n",
            "\n",
            "[3/5] Downloading GTSRB dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    121      0 --:--:--  0:00:03 --:--:--   121\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0\n",
            "100 98.6M    0 98.6M    0     0  22.0M      0 --:--:--  0:00:04 --:--:--  548M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    342      0 --:--:--  0:00:01 --:--:--   342\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100 4243k    0 4243k    0     0  1402k      0 --:--:--  0:00:03 --:--:--  338M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1096      0 --:--:-- --:--:-- --:--:--  1096\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  306M    0  306M    0     0  48.4M      0 --:--:--  0:00:06 --:--:-- 66.3M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    328      0 --:--:--  0:00:01 --:--:--   328\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100 12.8M    0 12.8M    0     0  4192k      0 --:--:--  0:00:03 --:--:--  399M\n",
            "\n",
            "[4/5] Downloading SVHN dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1169      0 --:--:-- --:--:-- --:--:--  1172\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100  305M    0  305M    0     0  40.5M      0 --:--:--  0:00:07 --:--:-- 67.7M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    267      0 --:--:--  0:00:01 --:--:--   267\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 1017k  100 1017k    0     0   429k      0  0:00:02  0:00:02 --:--:--  429k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1159      0 --:--:-- --:--:-- --:--:--  1159\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  772M    0  772M    0     0  46.4M      0 --:--:--  0:00:16 --:--:-- 57.0M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    404      0 --:--:--  0:00:01 --:--:--   404\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100 2575k    0 2575k    0     0   898k      0 --:--:--  0:00:02 --:--:--  340M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    131      0 --:--:--  0:00:03 --:--:--   131\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:04 --:--:--     0\n",
            "100 85.8M    0 85.8M    0     0  16.6M      0 --:--:--  0:00:05 --:--:-- 16.6M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    587      0 --:--:-- --:--:-- --:--:--   587\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100  286k  100  286k    0     0   114k      0  0:00:02  0:00:02 --:--:--  114k\n",
            "\n",
            "[5/5] Downloading US8K dataset...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1046      0 --:--:-- --:--:-- --:--:--  1046\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  202M    0  202M    0     0  40.2M      0 --:--:--  0:00:05 --:--:-- 70.6M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    505      0 --:--:-- --:--:-- --:--:--   504\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100  422k  100  422k    0     0   161k      0  0:00:02  0:00:02 --:--:--  331M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1295      0 --:--:-- --:--:-- --:--:--  1291\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1826M    0 1826M    0     0  60.7M      0 --:--:--  0:00:30 --:--:-- 68.3M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    315      0 --:--:--  0:00:01 --:--:--   315\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100 3801k    0 3801k    0     0  1204k      0 --:--:--  0:00:03 --:--:--  358M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe7UFC197vQa"
      },
      "source": [
        "##3. Prepare DNN Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW34-uwegWDk",
        "outputId": "463bb23d-ae2c-4892-aff7-377092392c5c"
      },
      "source": [
        "ls -d mnist gsc gtsrb cifar10 svhn us8k"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mcifar10\u001b[0m/  \u001b[01;34mgsc\u001b[0m/  \u001b[01;34mgtsrb\u001b[0m/  \u001b[01;34mmnist\u001b[0m/  \u001b[01;34msvhn\u001b[0m/  \u001b[01;34mus8k\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBr4DQcp71t8"
      },
      "source": [
        "##4. Weight Virtualization "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCi88cI08Uvh"
      },
      "source": [
        "###Step 1: Weight-Page Matching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P14Sq1fcgbaS",
        "outputId": "ac203f6f-86c1-4808-a150-c6f58078478b"
      },
      "source": [
        "!python weight_virtualization.py -mode=a -network_path=mnist"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init new weight pages\n",
            "add_vnn\n",
            "mnist/mnist_network_weight.npy\n",
            "compute_fisher\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx:  9215\n",
            "sample num:    1, data_idx: 26206\n",
            "sample num:    2, data_idx:  6987\n",
            "sample num:    3, data_idx: 49772\n",
            "sample num:    4, data_idx: 53384\n",
            "sample num:    5, data_idx:  9140\n",
            "sample num:    6, data_idx: 30245\n",
            "sample num:    7, data_idx: 30453\n",
            "sample num:    8, data_idx: 52187\n",
            "sample num:    9, data_idx: 39608\n",
            "sample num:   10, data_idx: 32037\n",
            "sample num:   11, data_idx: 25679\n",
            "sample num:   12, data_idx: 48167\n",
            "sample num:   13, data_idx:    30\n",
            "sample num:   14, data_idx: 39728\n",
            "sample num:   15, data_idx: 14151\n",
            "sample num:   16, data_idx: 42162\n",
            "sample num:   17, data_idx: 13348\n",
            "sample num:   18, data_idx: 13450\n",
            "sample num:   19, data_idx: 25081\n",
            "sample num:   20, data_idx: 25305\n",
            "sample num:   21, data_idx: 22811\n",
            "sample num:   22, data_idx: 28322\n",
            "sample num:   23, data_idx: 20336\n",
            "sample num:   24, data_idx: 18562\n",
            "sample num:   25, data_idx: 27362\n",
            "sample num:   26, data_idx:  9443\n",
            "sample num:   27, data_idx: 51582\n",
            "sample num:   28, data_idx: 13049\n",
            "sample num:   29, data_idx: 53174\n",
            "sample num:   30, data_idx: 34313\n",
            "sample num:   31, data_idx: 53702\n",
            "sample num:   32, data_idx:  5536\n",
            "sample num:   33, data_idx: 50610\n",
            "sample num:   34, data_idx: 15013\n",
            "sample num:   35, data_idx: 17728\n",
            "sample num:   36, data_idx: 18317\n",
            "sample num:   37, data_idx: 45252\n",
            "sample num:   38, data_idx: 23953\n",
            "sample num:   39, data_idx: 52601\n",
            "sample num:   40, data_idx:  2517\n",
            "sample num:   41, data_idx: 52227\n",
            "sample num:   42, data_idx: 19213\n",
            "sample num:   43, data_idx:  1956\n",
            "sample num:   44, data_idx:  9072\n",
            "sample num:   45, data_idx: 10763\n",
            "sample num:   46, data_idx: 35850\n",
            "sample num:   47, data_idx: 30987\n",
            "sample num:   48, data_idx: 37960\n",
            "sample num:   49, data_idx:  8106\n",
            "sample num:   50, data_idx: 21832\n",
            "sample num:   51, data_idx: 25614\n",
            "sample num:   52, data_idx: 54255\n",
            "sample num:   53, data_idx:  4100\n",
            "sample num:   54, data_idx: 25926\n",
            "sample num:   55, data_idx:  3652\n",
            "sample num:   56, data_idx:  7469\n",
            "sample num:   57, data_idx: 32987\n",
            "sample num:   58, data_idx: 31892\n",
            "sample num:   59, data_idx: 35217\n",
            "sample num:   60, data_idx: 43849\n",
            "sample num:   61, data_idx: 36938\n",
            "sample num:   62, data_idx: 10409\n",
            "sample num:   63, data_idx: 43730\n",
            "sample num:   64, data_idx: 47455\n",
            "sample num:   65, data_idx: 37381\n",
            "sample num:   66, data_idx: 47981\n",
            "sample num:   67, data_idx: 25226\n",
            "sample num:   68, data_idx:  1427\n",
            "sample num:   69, data_idx: 51378\n",
            "sample num:   70, data_idx: 54414\n",
            "sample num:   71, data_idx: 48903\n",
            "sample num:   72, data_idx: 13693\n",
            "sample num:   73, data_idx: 22834\n",
            "sample num:   74, data_idx: 14510\n",
            "sample num:   75, data_idx: 41500\n",
            "sample num:   76, data_idx: 44421\n",
            "sample num:   77, data_idx: 29989\n",
            "sample num:   78, data_idx:  3106\n",
            "sample num:   79, data_idx: 27431\n",
            "sample num:   80, data_idx: 32682\n",
            "sample num:   81, data_idx: 11634\n",
            "sample num:   82, data_idx: 51018\n",
            "sample num:   83, data_idx: 31417\n",
            "sample num:   84, data_idx: 50305\n",
            "sample num:   85, data_idx: 25010\n",
            "sample num:   86, data_idx: 41377\n",
            "sample num:   87, data_idx:  6328\n",
            "sample num:   88, data_idx: 26685\n",
            "sample num:   89, data_idx: 45765\n",
            "sample num:   90, data_idx: 45079\n",
            "sample num:   91, data_idx: 41541\n",
            "sample num:   92, data_idx: 53068\n",
            "sample num:   93, data_idx: 42256\n",
            "sample num:   94, data_idx: 23791\n",
            "sample num:   95, data_idx:   236\n",
            "sample num:   96, data_idx:  7540\n",
            "sample num:   97, data_idx: 14128\n",
            "sample num:   98, data_idx: 31341\n",
            "sample num:   99, data_idx: 17803\n",
            "mnist/mnist_network_fisher.npy\n",
            "[calculate_cost]\n",
            "toal_cost: 0.0\n",
            "458 pages allocated for 45706 weights\n",
            "total_network_cost: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B05Alk_geNI",
        "outputId": "facc6a25-38f4-49db-cce4-b1a67019ea8e"
      },
      "source": [
        "!python weight_virtualization.py -mode=a -network_path=gsc"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "add_vnn\n",
            "gsc/gsc_network_weight.npy\n",
            "compute_fisher\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx: 56484\n",
            "sample num:    1, data_idx: 13719\n",
            "sample num:    2, data_idx: 13332\n",
            "sample num:    3, data_idx: 76022\n",
            "sample num:    4, data_idx: 35014\n",
            "sample num:    5, data_idx: 60726\n",
            "sample num:    6, data_idx: 31413\n",
            "sample num:    7, data_idx:   705\n",
            "sample num:    8, data_idx: 68088\n",
            "sample num:    9, data_idx: 16010\n",
            "sample num:   10, data_idx: 50250\n",
            "sample num:   11, data_idx: 17666\n",
            "sample num:   12, data_idx: 11124\n",
            "sample num:   13, data_idx:  2581\n",
            "sample num:   14, data_idx: 19591\n",
            "sample num:   15, data_idx: 60875\n",
            "sample num:   16, data_idx: 30367\n",
            "sample num:   17, data_idx: 33840\n",
            "sample num:   18, data_idx: 32924\n",
            "sample num:   19, data_idx:  1689\n",
            "sample num:   20, data_idx: 69036\n",
            "sample num:   21, data_idx: 18489\n",
            "sample num:   22, data_idx: 43503\n",
            "sample num:   23, data_idx: 36687\n",
            "sample num:   24, data_idx: 71760\n",
            "sample num:   25, data_idx: 82791\n",
            "sample num:   26, data_idx: 71521\n",
            "sample num:   27, data_idx: 23235\n",
            "sample num:   28, data_idx: 58176\n",
            "sample num:   29, data_idx: 28127\n",
            "sample num:   30, data_idx:   220\n",
            "sample num:   31, data_idx: 11366\n",
            "sample num:   32, data_idx: 60691\n",
            "sample num:   33, data_idx: 35845\n",
            "sample num:   34, data_idx: 57935\n",
            "sample num:   35, data_idx:   552\n",
            "sample num:   36, data_idx: 36562\n",
            "sample num:   37, data_idx: 84439\n",
            "sample num:   38, data_idx: 66928\n",
            "sample num:   39, data_idx: 58184\n",
            "sample num:   40, data_idx: 20946\n",
            "sample num:   41, data_idx: 34889\n",
            "sample num:   42, data_idx: 54751\n",
            "sample num:   43, data_idx:  6134\n",
            "sample num:   44, data_idx: 10585\n",
            "sample num:   45, data_idx: 11794\n",
            "sample num:   46, data_idx: 68804\n",
            "sample num:   47, data_idx: 29533\n",
            "sample num:   48, data_idx: 82243\n",
            "sample num:   49, data_idx: 54297\n",
            "sample num:   50, data_idx: 27309\n",
            "sample num:   51, data_idx: 20686\n",
            "sample num:   52, data_idx: 32160\n",
            "sample num:   53, data_idx: 24234\n",
            "sample num:   54, data_idx: 41831\n",
            "sample num:   55, data_idx: 70242\n",
            "sample num:   56, data_idx: 33413\n",
            "sample num:   57, data_idx: 12950\n",
            "sample num:   58, data_idx: 73567\n",
            "sample num:   59, data_idx:  9398\n",
            "sample num:   60, data_idx: 45436\n",
            "sample num:   61, data_idx: 68364\n",
            "sample num:   62, data_idx:  6722\n",
            "sample num:   63, data_idx: 13713\n",
            "sample num:   64, data_idx: 55156\n",
            "sample num:   65, data_idx: 52203\n",
            "sample num:   66, data_idx: 73240\n",
            "sample num:   67, data_idx: 81608\n",
            "sample num:   68, data_idx: 14938\n",
            "sample num:   69, data_idx: 30112\n",
            "sample num:   70, data_idx: 69466\n",
            "sample num:   71, data_idx: 30816\n",
            "sample num:   72, data_idx: 46685\n",
            "sample num:   73, data_idx: 39502\n",
            "sample num:   74, data_idx: 30772\n",
            "sample num:   75, data_idx: 26829\n",
            "sample num:   76, data_idx: 32269\n",
            "sample num:   77, data_idx: 41793\n",
            "sample num:   78, data_idx: 73193\n",
            "sample num:   79, data_idx: 10307\n",
            "sample num:   80, data_idx: 18461\n",
            "sample num:   81, data_idx: 68261\n",
            "sample num:   82, data_idx: 64435\n",
            "sample num:   83, data_idx: 64151\n",
            "sample num:   84, data_idx: 56862\n",
            "sample num:   85, data_idx: 36002\n",
            "sample num:   86, data_idx: 48249\n",
            "sample num:   87, data_idx: 79653\n",
            "sample num:   88, data_idx: 46751\n",
            "sample num:   89, data_idx: 26128\n",
            "sample num:   90, data_idx: 51536\n",
            "sample num:   91, data_idx: 25227\n",
            "sample num:   92, data_idx:   869\n",
            "sample num:   93, data_idx: 83527\n",
            "sample num:   94, data_idx: 78507\n",
            "sample num:   95, data_idx: 50897\n",
            "sample num:   96, data_idx: 72810\n",
            "sample num:   97, data_idx: 26383\n",
            "sample num:   98, data_idx:  4811\n",
            "sample num:   99, data_idx: 37174\n",
            "gsc/gsc_network_fisher.npy\n",
            "[match_page_by_cost]\n",
            "occupation: 0\n",
            "len(page_list): 211\n",
            "len(network_page_list): 656\n",
            "       0-th page\n",
            "     210-th page\n",
            "cost: 0.0\n",
            "\n",
            "occupation: 1\n",
            "len(page_list): 458\n",
            "len(network_page_list): 445\n",
            "       0-th page\n",
            "     444-th page\n",
            "cost: 0.01868509\n",
            "\n",
            "assing_page 281.647 ms\n",
            "[calculate_cost]\n",
            "toal_cost: 0.01868507304789091\n",
            "656 pages allocated for 65531 weights\n",
            "total_network_cost: 0.07000914216041565\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkOZ4W2RggPf",
        "outputId": "8e98d76a-e609-45e5-9a15-e4b7c5ffcec2"
      },
      "source": [
        "!python weight_virtualization.py -mode=a -network_path=gtsrb"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "add_vnn\n",
            "gtsrb/gtsrb_network_weight.npy\n",
            "compute_fisher\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx:  3829\n",
            "sample num:    1, data_idx:  5444\n",
            "sample num:    2, data_idx:  2024\n",
            "sample num:    3, data_idx: 30916\n",
            "sample num:    4, data_idx: 11750\n",
            "sample num:    5, data_idx: 13269\n",
            "sample num:    6, data_idx:  7821\n",
            "sample num:    7, data_idx:  5189\n",
            "sample num:    8, data_idx: 13756\n",
            "sample num:    9, data_idx: 28415\n",
            "sample num:   10, data_idx: 37268\n",
            "sample num:   11, data_idx:  3997\n",
            "sample num:   12, data_idx: 21178\n",
            "sample num:   13, data_idx: 33829\n",
            "sample num:   14, data_idx: 34764\n",
            "sample num:   15, data_idx: 38698\n",
            "sample num:   16, data_idx: 38032\n",
            "sample num:   17, data_idx:  8232\n",
            "sample num:   18, data_idx: 16797\n",
            "sample num:   19, data_idx:  8840\n",
            "sample num:   20, data_idx: 20079\n",
            "sample num:   21, data_idx: 10451\n",
            "sample num:   22, data_idx: 25295\n",
            "sample num:   23, data_idx:  8581\n",
            "sample num:   24, data_idx: 15053\n",
            "sample num:   25, data_idx: 26403\n",
            "sample num:   26, data_idx: 15270\n",
            "sample num:   27, data_idx: 34635\n",
            "sample num:   28, data_idx: 24755\n",
            "sample num:   29, data_idx:   760\n",
            "sample num:   30, data_idx:  2852\n",
            "sample num:   31, data_idx: 35243\n",
            "sample num:   32, data_idx: 38001\n",
            "sample num:   33, data_idx:  8052\n",
            "sample num:   34, data_idx: 20041\n",
            "sample num:   35, data_idx: 28647\n",
            "sample num:   36, data_idx: 10557\n",
            "sample num:   37, data_idx: 32541\n",
            "sample num:   38, data_idx: 28232\n",
            "sample num:   39, data_idx: 16286\n",
            "sample num:   40, data_idx:  9500\n",
            "sample num:   41, data_idx: 10167\n",
            "sample num:   42, data_idx: 36142\n",
            "sample num:   43, data_idx: 33377\n",
            "sample num:   44, data_idx: 27688\n",
            "sample num:   45, data_idx: 15181\n",
            "sample num:   46, data_idx: 19415\n",
            "sample num:   47, data_idx: 36779\n",
            "sample num:   48, data_idx:  5015\n",
            "sample num:   49, data_idx: 25388\n",
            "sample num:   50, data_idx: 14488\n",
            "sample num:   51, data_idx:  4837\n",
            "sample num:   52, data_idx: 37159\n",
            "sample num:   53, data_idx: 26981\n",
            "sample num:   54, data_idx: 35713\n",
            "sample num:   55, data_idx: 12747\n",
            "sample num:   56, data_idx: 37524\n",
            "sample num:   57, data_idx: 29534\n",
            "sample num:   58, data_idx: 23221\n",
            "sample num:   59, data_idx: 17647\n",
            "sample num:   60, data_idx: 15319\n",
            "sample num:   61, data_idx: 23451\n",
            "sample num:   62, data_idx: 10641\n",
            "sample num:   63, data_idx: 17220\n",
            "sample num:   64, data_idx: 22148\n",
            "sample num:   65, data_idx:  4004\n",
            "sample num:   66, data_idx: 29562\n",
            "sample num:   67, data_idx: 18414\n",
            "sample num:   68, data_idx: 23136\n",
            "sample num:   69, data_idx: 12294\n",
            "sample num:   70, data_idx: 18200\n",
            "sample num:   71, data_idx: 10723\n",
            "sample num:   72, data_idx:  2277\n",
            "sample num:   73, data_idx:    54\n",
            "sample num:   74, data_idx: 31733\n",
            "sample num:   75, data_idx: 11066\n",
            "sample num:   76, data_idx:  7501\n",
            "sample num:   77, data_idx:  2669\n",
            "sample num:   78, data_idx: 12988\n",
            "sample num:   79, data_idx: 19853\n",
            "sample num:   80, data_idx: 33644\n",
            "sample num:   81, data_idx: 25475\n",
            "sample num:   82, data_idx: 30714\n",
            "sample num:   83, data_idx: 26765\n",
            "sample num:   84, data_idx:   123\n",
            "sample num:   85, data_idx: 20809\n",
            "sample num:   86, data_idx: 19744\n",
            "sample num:   87, data_idx: 30104\n",
            "sample num:   88, data_idx: 25190\n",
            "sample num:   89, data_idx: 20040\n",
            "sample num:   90, data_idx: 36126\n",
            "sample num:   91, data_idx: 11391\n",
            "sample num:   92, data_idx: 18268\n",
            "sample num:   93, data_idx: 32424\n",
            "sample num:   94, data_idx:  7019\n",
            "sample num:   95, data_idx: 28423\n",
            "sample num:   96, data_idx: 23901\n",
            "sample num:   97, data_idx: 34596\n",
            "sample num:   98, data_idx: 18943\n",
            "sample num:   99, data_idx:  3865\n",
            "gtsrb/gtsrb_network_fisher.npy\n",
            "[match_page_by_cost]\n",
            "occupation: 0\n",
            "len(page_list): 0\n",
            "len(network_page_list): 665\n",
            "cost: 0\n",
            "\n",
            "occupation: 1\n",
            "len(page_list): 224\n",
            "len(network_page_list): 665\n",
            "       0-th page\n",
            "     223-th page\n",
            "cost: 1.5941404\n",
            "\n",
            "occupation: 2\n",
            "len(page_list): 445\n",
            "len(network_page_list): 441\n",
            "       0-th page\n",
            "     440-th page\n",
            "cost: 0.018514892\n",
            "\n",
            "assing_page 141.594 ms\n",
            "[calculate_cost]\n",
            "toal_cost: 1.6127095987467328\n",
            "665 pages allocated for 66475 weights\n",
            "total_network_cost: 5.966028243303299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwyeK3-Dg_nv",
        "outputId": "7db16372-c97c-461c-8320-0290ef5db823"
      },
      "source": [
        "!python weight_virtualization.py -mode=a -network_path=cifar10"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "add_vnn\n",
            "cifar10/cifar10_network_weight.npy\n",
            "compute_fisher\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x73d0000 @  0x7fa15d5271e7 0x7fa15ae70ca1 0x7fa15aeda9c5 0x7fa15aedb55e 0x7fa15af74a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx: 35572\n",
            "sample num:    1, data_idx: 23444\n",
            "sample num:    2, data_idx: 41443\n",
            "sample num:    3, data_idx: 45700\n",
            "sample num:    4, data_idx: 43279\n",
            "sample num:    5, data_idx: 30304\n",
            "sample num:    6, data_idx: 33670\n",
            "sample num:    7, data_idx:  5469\n",
            "sample num:    8, data_idx:  1942\n",
            "sample num:    9, data_idx: 38427\n",
            "sample num:   10, data_idx:  8488\n",
            "sample num:   11, data_idx: 39637\n",
            "sample num:   12, data_idx: 41729\n",
            "sample num:   13, data_idx: 22001\n",
            "sample num:   14, data_idx: 25481\n",
            "sample num:   15, data_idx: 38881\n",
            "sample num:   16, data_idx: 18978\n",
            "sample num:   17, data_idx:  5061\n",
            "sample num:   18, data_idx:  2219\n",
            "sample num:   19, data_idx: 30546\n",
            "sample num:   20, data_idx: 34150\n",
            "sample num:   21, data_idx: 43575\n",
            "sample num:   22, data_idx: 46356\n",
            "sample num:   23, data_idx:  2421\n",
            "sample num:   24, data_idx: 15448\n",
            "sample num:   25, data_idx:  6207\n",
            "sample num:   26, data_idx: 14293\n",
            "sample num:   27, data_idx: 16625\n",
            "sample num:   28, data_idx: 23671\n",
            "sample num:   29, data_idx: 21407\n",
            "sample num:   30, data_idx: 32120\n",
            "sample num:   31, data_idx: 49344\n",
            "sample num:   32, data_idx: 49216\n",
            "sample num:   33, data_idx: 27203\n",
            "sample num:   34, data_idx: 25429\n",
            "sample num:   35, data_idx:   245\n",
            "sample num:   36, data_idx: 23421\n",
            "sample num:   37, data_idx:  8870\n",
            "sample num:   38, data_idx: 30206\n",
            "sample num:   39, data_idx: 37533\n",
            "sample num:   40, data_idx: 39379\n",
            "sample num:   41, data_idx: 11645\n",
            "sample num:   42, data_idx: 20737\n",
            "sample num:   43, data_idx: 49041\n",
            "sample num:   44, data_idx: 27972\n",
            "sample num:   45, data_idx: 23327\n",
            "sample num:   46, data_idx:  4191\n",
            "sample num:   47, data_idx: 30272\n",
            "sample num:   48, data_idx: 42534\n",
            "sample num:   49, data_idx: 25721\n",
            "sample num:   50, data_idx: 12156\n",
            "sample num:   51, data_idx: 28628\n",
            "sample num:   52, data_idx: 19963\n",
            "sample num:   53, data_idx: 17490\n",
            "sample num:   54, data_idx: 19895\n",
            "sample num:   55, data_idx: 27373\n",
            "sample num:   56, data_idx:  9293\n",
            "sample num:   57, data_idx:  3939\n",
            "sample num:   58, data_idx: 36234\n",
            "sample num:   59, data_idx: 15063\n",
            "sample num:   60, data_idx: 42310\n",
            "sample num:   61, data_idx: 15307\n",
            "sample num:   62, data_idx: 38249\n",
            "sample num:   63, data_idx: 28149\n",
            "sample num:   64, data_idx: 39171\n",
            "sample num:   65, data_idx: 46355\n",
            "sample num:   66, data_idx: 20720\n",
            "sample num:   67, data_idx: 16341\n",
            "sample num:   68, data_idx: 14263\n",
            "sample num:   69, data_idx: 31082\n",
            "sample num:   70, data_idx: 48444\n",
            "sample num:   71, data_idx: 32958\n",
            "sample num:   72, data_idx: 41449\n",
            "sample num:   73, data_idx: 13664\n",
            "sample num:   74, data_idx: 16095\n",
            "sample num:   75, data_idx: 11381\n",
            "sample num:   76, data_idx: 15698\n",
            "sample num:   77, data_idx: 20669\n",
            "sample num:   78, data_idx:  5812\n",
            "sample num:   79, data_idx: 39053\n",
            "sample num:   80, data_idx: 45047\n",
            "sample num:   81, data_idx:  9285\n",
            "sample num:   82, data_idx: 42735\n",
            "sample num:   83, data_idx:  2182\n",
            "sample num:   84, data_idx: 32050\n",
            "sample num:   85, data_idx: 17693\n",
            "sample num:   86, data_idx: 46154\n",
            "sample num:   87, data_idx: 27502\n",
            "sample num:   88, data_idx: 17426\n",
            "sample num:   89, data_idx:  5921\n",
            "sample num:   90, data_idx:  1226\n",
            "sample num:   91, data_idx: 17254\n",
            "sample num:   92, data_idx: 48007\n",
            "sample num:   93, data_idx: 25154\n",
            "sample num:   94, data_idx: 40178\n",
            "sample num:   95, data_idx:  5280\n",
            "sample num:   96, data_idx:  3750\n",
            "sample num:   97, data_idx: 27374\n",
            "sample num:   98, data_idx: 18366\n",
            "sample num:   99, data_idx: 34385\n",
            "cifar10/cifar10_network_fisher.npy\n",
            "[match_page_by_cost]\n",
            "occupation: 0\n",
            "len(page_list): 0\n",
            "len(network_page_list): 455\n",
            "cost: 0\n",
            "\n",
            "occupation: 1\n",
            "len(page_list): 0\n",
            "len(network_page_list): 455\n",
            "cost: 0\n",
            "\n",
            "occupation: 2\n",
            "len(page_list): 228\n",
            "len(network_page_list): 455\n",
            "       0-th page\n",
            "     227-th page\n",
            "cost: 13.525499\n",
            "\n",
            "occupation: 3\n",
            "len(page_list): 441\n",
            "len(network_page_list): 227\n",
            "       0-th page\n",
            "     226-th page\n",
            "cost: 0.0027145967\n",
            "\n",
            "assing_page 114.409 ms\n",
            "[calculate_cost]\n",
            "toal_cost: 13.528221021399986\n",
            "455 pages allocated for 45490 weights\n",
            "total_network_cost: 65.89007499814034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etzJQqvlhoyo",
        "outputId": "fd70b496-b92f-4eed-80c9-0e1210be3ac8"
      },
      "source": [
        "!python weight_virtualization.py -mode=a -network_path=svhn"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "add_vnn\n",
            "svhn/svhn_network_weight.npy\n",
            "compute_fisher\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx: 31563\n",
            "sample num:    1, data_idx: 56694\n",
            "sample num:    2, data_idx: 49260\n",
            "sample num:    3, data_idx: 12850\n",
            "sample num:    4, data_idx: 31666\n",
            "sample num:    5, data_idx:  2827\n",
            "sample num:    6, data_idx: 43527\n",
            "sample num:    7, data_idx: 60945\n",
            "sample num:    8, data_idx: 55983\n",
            "sample num:    9, data_idx: 64193\n",
            "sample num:   10, data_idx: 37511\n",
            "sample num:   11, data_idx: 57383\n",
            "sample num:   12, data_idx: 25880\n",
            "sample num:   13, data_idx: 55632\n",
            "sample num:   14, data_idx: 41130\n",
            "sample num:   15, data_idx: 52702\n",
            "sample num:   16, data_idx:  6625\n",
            "sample num:   17, data_idx:  7620\n",
            "sample num:   18, data_idx: 12982\n",
            "sample num:   19, data_idx: 26934\n",
            "sample num:   20, data_idx: 54323\n",
            "sample num:   21, data_idx: 22871\n",
            "sample num:   22, data_idx: 18929\n",
            "sample num:   23, data_idx: 40591\n",
            "sample num:   24, data_idx: 15833\n",
            "sample num:   25, data_idx: 37656\n",
            "sample num:   26, data_idx: 15557\n",
            "sample num:   27, data_idx: 57227\n",
            "sample num:   28, data_idx: 27662\n",
            "sample num:   29, data_idx: 62950\n",
            "sample num:   30, data_idx: 46502\n",
            "sample num:   31, data_idx: 63533\n",
            "sample num:   32, data_idx: 48448\n",
            "sample num:   33, data_idx: 43382\n",
            "sample num:   34, data_idx: 35802\n",
            "sample num:   35, data_idx:   363\n",
            "sample num:   36, data_idx: 27922\n",
            "sample num:   37, data_idx: 43703\n",
            "sample num:   38, data_idx: 63182\n",
            "sample num:   39, data_idx: 31704\n",
            "sample num:   40, data_idx: 31069\n",
            "sample num:   41, data_idx: 33822\n",
            "sample num:   42, data_idx: 26476\n",
            "sample num:   43, data_idx: 61115\n",
            "sample num:   44, data_idx: 15122\n",
            "sample num:   45, data_idx: 16597\n",
            "sample num:   46, data_idx: 23900\n",
            "sample num:   47, data_idx: 30567\n",
            "sample num:   48, data_idx: 22096\n",
            "sample num:   49, data_idx: 44933\n",
            "sample num:   50, data_idx: 15893\n",
            "sample num:   51, data_idx: 39519\n",
            "sample num:   52, data_idx: 37510\n",
            "sample num:   53, data_idx: 57324\n",
            "sample num:   54, data_idx:  2421\n",
            "sample num:   55, data_idx: 62070\n",
            "sample num:   56, data_idx: 28963\n",
            "sample num:   57, data_idx:  8930\n",
            "sample num:   58, data_idx: 50049\n",
            "sample num:   59, data_idx: 41973\n",
            "sample num:   60, data_idx: 30534\n",
            "sample num:   61, data_idx: 47176\n",
            "sample num:   62, data_idx: 52625\n",
            "sample num:   63, data_idx: 47471\n",
            "sample num:   64, data_idx: 20454\n",
            "sample num:   65, data_idx: 19009\n",
            "sample num:   66, data_idx: 28416\n",
            "sample num:   67, data_idx: 20267\n",
            "sample num:   68, data_idx: 15629\n",
            "sample num:   69, data_idx: 22764\n",
            "sample num:   70, data_idx: 32258\n",
            "sample num:   71, data_idx: 47408\n",
            "sample num:   72, data_idx: 17143\n",
            "sample num:   73, data_idx:  4511\n",
            "sample num:   74, data_idx: 37256\n",
            "sample num:   75, data_idx: 28865\n",
            "sample num:   76, data_idx: 35945\n",
            "sample num:   77, data_idx: 45465\n",
            "sample num:   78, data_idx:  5250\n",
            "sample num:   79, data_idx: 46817\n",
            "sample num:   80, data_idx: 54724\n",
            "sample num:   81, data_idx: 41424\n",
            "sample num:   82, data_idx: 46166\n",
            "sample num:   83, data_idx: 58861\n",
            "sample num:   84, data_idx: 44471\n",
            "sample num:   85, data_idx: 35601\n",
            "sample num:   86, data_idx: 52243\n",
            "sample num:   87, data_idx: 35797\n",
            "sample num:   88, data_idx: 36490\n",
            "sample num:   89, data_idx: 56510\n",
            "sample num:   90, data_idx: 11643\n",
            "sample num:   91, data_idx: 46630\n",
            "sample num:   92, data_idx: 53431\n",
            "sample num:   93, data_idx: 36929\n",
            "sample num:   94, data_idx: 51290\n",
            "sample num:   95, data_idx: 12215\n",
            "sample num:   96, data_idx: 59097\n",
            "sample num:   97, data_idx: 36610\n",
            "sample num:   98, data_idx: 50309\n",
            "sample num:   99, data_idx: 54036\n",
            "svhn/svhn_network_fisher.npy\n",
            "[match_page_by_cost]\n",
            "occupation: 0\n",
            "len(page_list): 0\n",
            "len(network_page_list): 455\n",
            "cost: 0\n",
            "\n",
            "occupation: 1\n",
            "len(page_list): 0\n",
            "len(network_page_list): 455\n",
            "cost: 0\n",
            "\n",
            "occupation: 2\n",
            "len(page_list): 0\n",
            "len(network_page_list): 455\n",
            "cost: 0\n",
            "\n",
            "occupation: 3\n",
            "len(page_list): 442\n",
            "len(network_page_list): 455\n",
            "       0-th page\n",
            "     441-th page\n",
            "cost: 7.2867494\n",
            "\n",
            "occupation: 4\n",
            "len(page_list): 227\n",
            "len(network_page_list): 13\n",
            "       0-th page\n",
            "      12-th page\n",
            "cost: 0.00017150925\n",
            "\n",
            "assing_page 118.891 ms\n",
            "[calculate_cost]\n",
            "toal_cost: 7.2934045625333965\n",
            "455 pages allocated for 45490 weights\n",
            "total_network_cost: 112.11705520749092\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEXmlVfKhq9T",
        "outputId": "ea3aa589-d231-4f78-e306-6bf69bc238b2"
      },
      "source": [
        "!python weight_virtualization.py -mode=a -network_path=us8k"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "add_vnn\n",
            "us8k/us8k_network_weight.npy\n",
            "compute_fisher\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x8eb8000 @  0x7f0a268b61e7 0x7f0a241ffca1 0x7f0a242699c5 0x7f0a2426a55e 0x7f0a24303a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "do_compute_fisher\n",
            "sample num:    0, data_idx: 43052\n",
            "sample num:    1, data_idx: 37682\n",
            "sample num:    2, data_idx: 42190\n",
            "sample num:    3, data_idx: 36336\n",
            "sample num:    4, data_idx: 48027\n",
            "sample num:    5, data_idx:  8824\n",
            "sample num:    6, data_idx: 33410\n",
            "sample num:    7, data_idx: 26608\n",
            "sample num:    8, data_idx: 32661\n",
            "sample num:    9, data_idx: 36070\n",
            "sample num:   10, data_idx: 46793\n",
            "sample num:   11, data_idx: 28448\n",
            "sample num:   12, data_idx: 18425\n",
            "sample num:   13, data_idx:  2264\n",
            "sample num:   14, data_idx: 37648\n",
            "sample num:   15, data_idx:  1227\n",
            "sample num:   16, data_idx:  6958\n",
            "sample num:   17, data_idx:  1389\n",
            "sample num:   18, data_idx: 23507\n",
            "sample num:   19, data_idx:  8831\n",
            "sample num:   20, data_idx: 25420\n",
            "sample num:   21, data_idx:  8643\n",
            "sample num:   22, data_idx: 12104\n",
            "sample num:   23, data_idx:  3375\n",
            "sample num:   24, data_idx: 21427\n",
            "sample num:   25, data_idx: 31415\n",
            "sample num:   26, data_idx: 23119\n",
            "sample num:   27, data_idx: 21630\n",
            "sample num:   28, data_idx: 14997\n",
            "sample num:   29, data_idx:  2429\n",
            "sample num:   30, data_idx:  6581\n",
            "sample num:   31, data_idx: 22278\n",
            "sample num:   32, data_idx: 44062\n",
            "sample num:   33, data_idx: 11448\n",
            "sample num:   34, data_idx: 41609\n",
            "sample num:   35, data_idx:  4532\n",
            "sample num:   36, data_idx:  7978\n",
            "sample num:   37, data_idx: 14060\n",
            "sample num:   38, data_idx: 35518\n",
            "sample num:   39, data_idx: 29902\n",
            "sample num:   40, data_idx: 29787\n",
            "sample num:   41, data_idx: 15592\n",
            "sample num:   42, data_idx:  1463\n",
            "sample num:   43, data_idx: 30995\n",
            "sample num:   44, data_idx: 32372\n",
            "sample num:   45, data_idx: 32661\n",
            "sample num:   46, data_idx: 23612\n",
            "sample num:   47, data_idx: 46648\n",
            "sample num:   48, data_idx:   758\n",
            "sample num:   49, data_idx: 30183\n",
            "sample num:   50, data_idx: 38933\n",
            "sample num:   51, data_idx: 11330\n",
            "sample num:   52, data_idx: 19811\n",
            "sample num:   53, data_idx:  7241\n",
            "sample num:   54, data_idx:   950\n",
            "sample num:   55, data_idx: 32856\n",
            "sample num:   56, data_idx:  9439\n",
            "sample num:   57, data_idx:  6609\n",
            "sample num:   58, data_idx: 21140\n",
            "sample num:   59, data_idx: 30174\n",
            "sample num:   60, data_idx: 42997\n",
            "sample num:   61, data_idx: 46163\n",
            "sample num:   62, data_idx:  8692\n",
            "sample num:   63, data_idx: 38003\n",
            "sample num:   64, data_idx:  2127\n",
            "sample num:   65, data_idx: 25715\n",
            "sample num:   66, data_idx:  5321\n",
            "sample num:   67, data_idx: 33159\n",
            "sample num:   68, data_idx: 28322\n",
            "sample num:   69, data_idx: 15672\n",
            "sample num:   70, data_idx: 12063\n",
            "sample num:   71, data_idx: 42936\n",
            "sample num:   72, data_idx:  4083\n",
            "sample num:   73, data_idx:  1848\n",
            "sample num:   74, data_idx:  5005\n",
            "sample num:   75, data_idx: 18777\n",
            "sample num:   76, data_idx: 22669\n",
            "sample num:   77, data_idx: 34768\n",
            "sample num:   78, data_idx: 35790\n",
            "sample num:   79, data_idx:  7469\n",
            "sample num:   80, data_idx:  2047\n",
            "sample num:   81, data_idx: 48125\n",
            "sample num:   82, data_idx:  6849\n",
            "sample num:   83, data_idx: 13021\n",
            "sample num:   84, data_idx: 14829\n",
            "sample num:   85, data_idx: 29108\n",
            "sample num:   86, data_idx: 15268\n",
            "sample num:   87, data_idx: 19782\n",
            "sample num:   88, data_idx:  6095\n",
            "sample num:   89, data_idx: 27056\n",
            "sample num:   90, data_idx: 45681\n",
            "sample num:   91, data_idx: 13420\n",
            "sample num:   92, data_idx: 48501\n",
            "sample num:   93, data_idx: 22427\n",
            "sample num:   94, data_idx: 39670\n",
            "sample num:   95, data_idx: 16035\n",
            "sample num:   96, data_idx: 44374\n",
            "sample num:   97, data_idx: 25244\n",
            "sample num:   98, data_idx: 23752\n",
            "sample num:   99, data_idx:  3574\n",
            "us8k/us8k_network_fisher.npy\n",
            "[match_page_by_cost]\n",
            "occupation: 0\n",
            "len(page_list): 0\n",
            "len(network_page_list): 669\n",
            "cost: 0\n",
            "\n",
            "occupation: 1\n",
            "len(page_list): 0\n",
            "len(network_page_list): 669\n",
            "cost: 0\n",
            "\n",
            "occupation: 2\n",
            "len(page_list): 0\n",
            "len(network_page_list): 669\n",
            "cost: 0\n",
            "\n",
            "occupation: 3\n",
            "len(page_list): 0\n",
            "len(network_page_list): 669\n",
            "cost: 0\n",
            "\n",
            "occupation: 4\n",
            "len(page_list): 656\n",
            "len(network_page_list): 669\n",
            "       0-th page\n",
            "     655-th page\n",
            "cost: 7.2906985\n",
            "\n",
            "occupation: 5\n",
            "len(page_list): 13\n",
            "len(network_page_list): 13\n",
            "       0-th page\n",
            "      12-th page\n",
            "cost: 0.0007359219\n",
            "\n",
            "assing_page 152.527 ms\n",
            "[calculate_cost]\n",
            "toal_cost: 7.291435494633333\n",
            "669 pages allocated for 66854 weights\n",
            "total_network_cost: 179.3539688885212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYSq6kpqSBjs",
        "outputId": "c056d199-c4f7-4176-c227-c925d358da8a"
      },
      "source": [
        "!python weight_virtualization.py -mode=l"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[VNN list]\n",
            "Name: cifar10, id: 3, path: cifar10, num_of_weight: 45490\n",
            "Name: gsc, id: 1, path: gsc, num_of_weight: 65531\n",
            "Name: gtsrb, id: 2, path: gtsrb, num_of_weight: 66475\n",
            "Name: mnist, id: 0, path: mnist, num_of_weight: 45706\n",
            "Name: svhn, id: 4, path: svhn, num_of_weight: 45490\n",
            "Name: us8k, id: 5, path: us8k, num_of_weight: 66854\n",
            "\n",
            "[Weight page] total 669 weight pages\n",
            "[list([[0, 0], [2, 114], [3, 338], [4, 44], [5, 530]])\n",
            " list([[0, 1], [2, 16], [3, 336], [4, 118], [5, 450]])\n",
            " list([[0, 2], [2, 551], [3, 404], [4, 187], [5, 490]])\n",
            " list([[0, 3], [2, 544], [3, 416], [4, 406], [5, 191]])\n",
            " list([[0, 4], [1, 321], [3, 169], [4, 80], [5, 523]])\n",
            " list([[0, 5], [2, 608], [3, 187], [4, 194], [5, 435]])\n",
            " list([[0, 6], [2, 18], [3, 352], [4, 240], [5, 92]])\n",
            " list([[0, 7], [2, 92], [3, 271], [4, 378], [5, 267]])\n",
            " list([[0, 8], [2, 43], [3, 188], [4, 412], [5, 217]])\n",
            " list([[0, 9], [2, 25], [3, 178], [4, 292], [5, 508]])\n",
            " list([[0, 10], [2, 74], [3, 175], [4, 176], [5, 432]])\n",
            " list([[0, 11], [2, 61], [3, 125], [4, 142], [5, 219]])\n",
            " list([[0, 12], [2, 630], [3, 32], [4, 391], [5, 593]])\n",
            " list([[0, 13], [1, 367], [2, 293], [4, 416], [5, 168]])\n",
            " list([[0, 14], [1, 267], [2, 306], [4, 119], [5, 596]])\n",
            " list([[0, 15], [1, 291], [2, 396], [4, 157], [5, 209]])\n",
            " list([[0, 16], [1, 375], [2, 300], [4, 359], [5, 634]])\n",
            " list([[0, 17], [1, 281], [2, 282], [4, 185], [5, 326]])\n",
            " list([[0, 18], [1, 412], [2, 368], [4, 234], [5, 559]])\n",
            " list([[0, 19], [1, 307], [2, 383], [4, 297], [5, 330]])\n",
            " list([[0, 20], [1, 546], [2, 364], [4, 340], [5, 293]])\n",
            " list([[0, 21], [1, 471], [2, 292], [4, 287], [5, 313]])\n",
            " list([[0, 22], [1, 286], [2, 267], [4, 324], [5, 556]])\n",
            " list([[0, 23], [1, 416], [2, 99], [4, 99], [5, 151]])\n",
            " list([[0, 24], [1, 306], [2, 518], [4, 217], [5, 545]])\n",
            " list([[0, 25], [1, 246], [2, 371], [4, 321], [5, 153]])\n",
            " list([[0, 26], [1, 477], [2, 312], [4, 122], [5, 406]])\n",
            " list([[0, 27], [1, 308], [2, 520], [4, 424], [5, 468]])\n",
            " list([[0, 28], [1, 370], [2, 345], [4, 128], [5, 295]])\n",
            " list([[0, 29], [1, 470], [2, 260], [4, 263], [5, 601]])\n",
            " list([[0, 30], [1, 519], [2, 234], [4, 225], [5, 384]])\n",
            " list([[0, 31], [1, 303], [2, 138], [4, 247], [5, 433]])\n",
            " list([[0, 32], [1, 531], [2, 225], [4, 268], [5, 371]])\n",
            " list([[0, 33], [1, 426], [2, 455], [4, 160], [5, 540]])\n",
            " list([[0, 34], [1, 435], [2, 385], [4, 349], [5, 170]])\n",
            " list([[0, 35], [1, 439], [2, 370], [4, 177], [5, 169]])\n",
            " list([[0, 36], [1, 533], [2, 311], [4, 414], [5, 140]])\n",
            " list([[0, 37], [1, 437], [2, 307], [4, 331], [5, 221]])\n",
            " list([[0, 38], [1, 247], [2, 538], [4, 131], [5, 458]])\n",
            " list([[0, 39], [1, 304], [2, 250], [4, 313], [5, 75]])\n",
            " list([[0, 40], [1, 430], [3, 377], [4, 138], [5, 185]])\n",
            " list([[0, 41], [1, 505], [2, 392], [4, 425], [5, 509]])\n",
            " list([[0, 42], [1, 458], [2, 191], [4, 125], [5, 319]])\n",
            " list([[0, 43], [1, 387], [2, 477], [4, 403], [5, 456]])\n",
            " list([[0, 44], [1, 512], [2, 277], [4, 2], [5, 444]])\n",
            " list([[0, 45], [1, 266], [2, 94], [4, 308], [5, 511]])\n",
            " list([[0, 46], [1, 536], [2, 245], [4, 291], [5, 526]])\n",
            " list([[0, 47], [1, 293], [2, 532], [4, 358], [5, 381]])\n",
            " list([[0, 48], [1, 444], [2, 493], [4, 141], [5, 118]])\n",
            " list([[0, 49], [1, 428], [2, 496], [4, 288], [5, 79]])\n",
            " list([[0, 50], [1, 355], [2, 476], [4, 197], [5, 194]])\n",
            " list([[0, 51], [1, 414], [2, 168], [4, 212], [5, 261]])\n",
            " list([[0, 52], [1, 404], [2, 237], [4, 195], [5, 369]])\n",
            " list([[0, 53], [1, 347], [2, 341], [4, 206], [5, 216]])\n",
            " list([[0, 54], [1, 530], [2, 358], [4, 276], [5, 513]])\n",
            " list([[0, 55], [1, 521], [3, 184], [4, 348], [5, 143]])\n",
            " list([[0, 56], [1, 320], [2, 382], [4, 106], [5, 552]])\n",
            " list([[0, 57], [1, 268], [2, 393], [4, 363], [5, 489]])\n",
            " list([[0, 58], [2, 629], [3, 309], [4, 251], [5, 128]])\n",
            " list([[0, 59], [1, 323], [2, 230], [4, 431], [5, 436]])\n",
            " list([[0, 60], [1, 417], [2, 197], [3, 194], [5, 23]])\n",
            " list([[0, 61], [1, 372], [2, 437], [4, 366], [5, 624]])\n",
            " list([[0, 62], [1, 241], [2, 528], [4, 376], [5, 627]])\n",
            " list([[0, 63], [1, 443], [2, 530], [4, 237], [5, 475]])\n",
            " list([[0, 64], [1, 522], [2, 241], [4, 451], [5, 448]])\n",
            " list([[0, 65], [1, 314], [2, 534], [3, 301], [5, 482]])\n",
            " list([[0, 66], [1, 432], [2, 498], [4, 333], [5, 272]])\n",
            " list([[0, 67], [1, 345], [2, 529], [4, 161], [5, 570]])\n",
            " list([[0, 68], [1, 257], [2, 331], [4, 71], [5, 370]])\n",
            " list([[0, 69], [1, 413], [2, 472], [4, 32], [5, 447]])\n",
            " list([[0, 70], [1, 545], [2, 68], [4, 59], [5, 68]])\n",
            " list([[0, 71], [1, 373], [2, 303], [3, 198], [5, 472]])\n",
            " list([[0, 72], [1, 410], [2, 462], [3, 254], [5, 555]])\n",
            " list([[0, 73], [1, 462], [2, 315], [4, 76], [5, 446]])\n",
            " list([[0, 74], [1, 405], [2, 285], [4, 430], [5, 259]])\n",
            " list([[0, 75], [1, 494], [2, 298], [4, 426], [5, 360]])\n",
            " list([[0, 76], [1, 446], [2, 318], [4, 442], [5, 273]])\n",
            " list([[0, 77], [1, 497], [2, 178], [4, 35], [5, 646]])\n",
            " list([[0, 78], [1, 288], [2, 251], [4, 90], [5, 84]])\n",
            " list([[0, 79], [1, 529], [2, 519], [4, 132], [5, 539]])\n",
            " list([[0, 80], [1, 371], [2, 340], [4, 272], [5, 223]])\n",
            " list([[0, 81], [1, 352], [2, 402], [4, 1], [5, 212]])\n",
            " list([[0, 82], [1, 297], [2, 463], [4, 248], [5, 587]])\n",
            " list([[0, 83], [1, 292], [2, 288], [4, 310], [5, 244]])\n",
            " list([[0, 84], [1, 329], [2, 365], [4, 37], [5, 149]])\n",
            " list([[0, 85], [1, 440], [2, 446], [3, 257], [5, 502]])\n",
            " list([[0, 86], [1, 442], [2, 322], [3, 418], [5, 17]])\n",
            " list([[0, 87], [1, 496], [2, 435], [4, 70], [5, 292]])\n",
            " list([[0, 88], [1, 284], [2, 456], [3, 397], [5, 362]])\n",
            " list([[0, 89], [1, 526], [2, 453], [3, 318], [5, 39]])\n",
            " list([[0, 90], [1, 419], [2, 484], [3, 211], [5, 459]])\n",
            " list([[0, 91], [1, 449], [2, 515], [4, 69], [5, 572]])\n",
            " list([[0, 92], [1, 423], [2, 473], [4, 68], [5, 589]])\n",
            " list([[0, 93], [1, 357], [2, 438], [4, 265], [5, 130]])\n",
            " list([[0, 94], [1, 502], [2, 517], [4, 444], [5, 408]])\n",
            " list([[0, 95], [1, 433], [2, 328], [3, 365], [5, 639]])\n",
            " list([[0, 96], [1, 249], [2, 521], [4, 21], [5, 148]])\n",
            " list([[0, 97], [1, 332], [2, 323], [4, 441], [5, 438]])\n",
            " list([[0, 98], [1, 239], [2, 444], [4, 271], [5, 638]])\n",
            " list([[0, 99], [1, 236], [2, 413], [4, 357], [5, 162]])\n",
            " list([[0, 100], [1, 270], [3, 335], [4, 415], [5, 437]])\n",
            " list([[0, 101], [1, 415], [2, 533], [4, 304], [5, 590]])\n",
            " list([[0, 102], [1, 388], [2, 503], [3, 157], [5, 479]])\n",
            " list([[0, 103], [1, 453], [2, 394], [3, 359], [5, 581]])\n",
            " list([[0, 104], [1, 43], [2, 509], [4, 73], [5, 240]])\n",
            " list([[0, 105], [1, 57], [2, 349], [4, 56], [5, 73]])\n",
            " list([[0, 106], [1, 96], [2, 259], [4, 332], [5, 116]])\n",
            " list([[0, 107], [1, 192], [2, 416], [4, 91], [5, 422]])\n",
            " list([[0, 108], [1, 225], [2, 254], [3, 108], [5, 28]])\n",
            " list([[0, 109], [1, 344], [2, 152], [3, 123], [5, 503]])\n",
            " list([[0, 110], [1, 256], [2, 336], [3, 281], [5, 667]])\n",
            " list([[0, 111], [1, 237], [2, 69], [3, 340], [5, 78]])\n",
            " list([[0, 112], [1, 242], [2, 369], [3, 389], [5, 664]])\n",
            " list([[0, 113], [1, 541], [2, 151], [3, 393], [5, 56]])\n",
            " list([[0, 114], [1, 450], [2, 196], [3, 135], [5, 558]])\n",
            " list([[0, 115], [1, 231], [2, 228], [3, 245], [5, 61]])\n",
            " list([[0, 116], [1, 258], [2, 179], [3, 409], [5, 484]])\n",
            " list([[0, 117], [1, 558], [2, 409], [3, 233], [5, 16]])\n",
            " list([[0, 118], [1, 424], [2, 525], [3, 161], [5, 97]])\n",
            " list([[0, 119], [1, 312], [2, 62], [3, 101], [5, 22]])\n",
            " list([[0, 120], [1, 409], [2, 128], [3, 118], [5, 142]])\n",
            " list([[0, 121], [1, 248], [2, 65], [4, 428], [5, 83]])\n",
            " list([[0, 122], [1, 230], [2, 227], [3, 382], [5, 262]])\n",
            " list([[0, 123], [1, 61], [2, 482], [3, 112], [5, 563]])\n",
            " list([[0, 124], [1, 205], [2, 252], [4, 66], [5, 619]])\n",
            " list([[0, 125], [1, 105], [2, 280], [4, 169], [5, 531]])\n",
            " list([[0, 126], [1, 34], [2, 389], [4, 34], [5, 614]])\n",
            " list([[0, 127], [1, 185], [2, 343], [4, 85], [5, 560]])\n",
            " list([[0, 128], [1, 485], [2, 246], [3, 201], [5, 34]])\n",
            " list([[0, 129], [1, 147], [2, 367], [4, 62], [5, 163]])\n",
            " list([[0, 130], [1, 232], [2, 317], [4, 5], [5, 117]])\n",
            " list([[0, 131], [1, 65], [2, 388], [4, 81], [5, 528]])\n",
            " list([[0, 132], [1, 67], [2, 433], [3, 130], [5, 208]])\n",
            " list([[0, 133], [1, 99], [2, 359], [4, 11], [5, 247]])\n",
            " list([[0, 134], [1, 351], [2, 210], [3, 222], [5, 134]])\n",
            " list([[0, 135], [1, 325], [2, 115], [3, 374], [5, 119]])\n",
            " list([[0, 136], [1, 499], [2, 171], [4, 449], [5, 476]])\n",
            " list([[0, 137], [1, 243], [2, 460], [3, 298], [5, 146]])\n",
            " list([[0, 138], [1, 341], [2, 64], [3, 421], [5, 612]])\n",
            " list([[0, 139], [1, 343], [2, 203], [4, 429], [5, 421]])\n",
            " list([[0, 140], [1, 441], [2, 192], [3, 384], [5, 641]])\n",
            " list([[0, 141], [1, 254], [2, 159], [3, 334], [5, 640]])\n",
            " list([[0, 142], [1, 338], [2, 71], [3, 304], [5, 576]])\n",
            " list([[0, 143], [1, 420], [2, 213], [3, 314], [5, 2]])\n",
            " list([[0, 144], [1, 368], [2, 221], [3, 217], [5, 538]])\n",
            " list([[0, 145], [1, 399], [2, 130], [4, 14], [5, 127]])\n",
            " list([[0, 146], [1, 400], [2, 212], [3, 214], [5, 0]])\n",
            " list([[0, 147], [1, 271], [2, 96], [3, 423], [5, 93]])\n",
            " list([[0, 148], [1, 238], [2, 175], [3, 131], [5, 568]])\n",
            " list([[0, 149], [1, 465], [2, 209], [3, 253], [5, 29]])\n",
            " list([[0, 150], [1, 283], [2, 475], [3, 162], [5, 81]])\n",
            " list([[0, 151], [1, 42], [2, 427], [3, 323], [5, 584]])\n",
            " list([[0, 152], [1, 100], [2, 501], [4, 48], [5, 47]])\n",
            " list([[0, 153], [1, 182], [2, 305], [4, 18], [5, 302]])\n",
            " list([[0, 154], [1, 508], [2, 486], [3, 136], [5, 121]])\n",
            " list([[0, 155], [1, 369], [2, 547], [3, 288], [4, 404], [5, 226]])\n",
            " list([[0, 156], [1, 538], [2, 295], [3, 402], [5, 665]])\n",
            " list([[0, 157], [1, 259], [2, 350], [3, 411], [4, 382], [5, 485]])\n",
            " list([[0, 158], [1, 71], [2, 390], [4, 33], [5, 373]])\n",
            " list([[0, 159], [1, 394], [2, 101], [3, 385], [5, 54]])\n",
            " list([[0, 160], [1, 454], [2, 290], [3, 259], [5, 344]])\n",
            " list([[0, 161], [1, 165], [2, 378], [4, 6], [5, 653]])\n",
            " list([[0, 162], [1, 407], [2, 142], [4, 434], [5, 537]])\n",
            " list([[0, 163], [1, 299], [2, 81], [3, 240], [5, 57]])\n",
            " list([[0, 164], [1, 461], [2, 248], [3, 113], [4, 189], [5, 650]])\n",
            " list([[0, 165], [1, 452], [2, 391], [3, 122], [5, 48]])\n",
            " list([[0, 166], [1, 509], [2, 468], [3, 322], [5, 305]])\n",
            " list([[0, 167], [1, 44], [2, 265], [4, 83], [5, 76]])\n",
            " list([[0, 168], [1, 38], [2, 256], [3, 151], [5, 320]])\n",
            " list([[0, 169], [1, 548], [2, 461], [3, 146], [5, 597]])\n",
            " list([[0, 170], [1, 319], [2, 321], [3, 156], [5, 571]])\n",
            " list([[0, 171], [1, 64], [2, 488], [3, 210], [5, 40]])\n",
            " list([[0, 172], [1, 279], [2, 353], [3, 305], [5, 176]])\n",
            " list([[0, 173], [1, 366], [2, 271], [3, 177], [5, 631]])\n",
            " list([[0, 174], [1, 162], [2, 424], [4, 87], [5, 575]])\n",
            " list([[0, 175], [1, 534], [2, 384], [3, 330], [5, 124]])\n",
            " list([[0, 176], [1, 181], [2, 400], [4, 104], [5, 504]])\n",
            " list([[0, 177], [1, 151], [2, 326], [4, 60], [5, 248]])\n",
            " list([[0, 178], [1, 240], [2, 172], [3, 114], [5, 44]])\n",
            " list([[0, 179], [1, 463], [2, 145], [3, 115], [5, 343]])\n",
            " list([[0, 180], [1, 328], [2, 162], [3, 332], [5, 420]])\n",
            " list([[0, 181], [1, 354], [2, 169], [3, 341], [5, 454]])\n",
            " list([[0, 182], [1, 557], [2, 132], [4, 25], [5, 166]])\n",
            " list([[0, 183], [1, 364], [2, 485], [3, 104], [5, 253]])\n",
            " list([[0, 184], [1, 382], [2, 348], [3, 106], [5, 1]])\n",
            " list([[0, 185], [1, 348], [2, 215], [4, 445], [5, 334]])\n",
            " list([[0, 186], [1, 227], [2, 386], [4, 57], [5, 205]])\n",
            " list([[0, 187], [1, 204], [2, 240], [4, 43], [5, 300]])\n",
            " list([[0, 188], [1, 377], [2, 412], [3, 111], [5, 161]])\n",
            " list([[0, 189], [1, 517], [2, 487], [3, 147], [5, 578]])\n",
            " list([[0, 190], [1, 543], [2, 113], [3, 403], [5, 43]])\n",
            " list([[0, 191], [1, 228], [2, 366], [3, 289], [5, 637]])\n",
            " list([[0, 192], [1, 358], [2, 188], [3, 126], [5, 521]])\n",
            " list([[0, 193], [1, 262], [2, 139], [3, 158], [5, 64]])\n",
            " list([[0, 194], [1, 224], [2, 410], [3, 306], [5, 544]])\n",
            " list([[0, 195], [1, 81], [2, 548], [4, 52], [5, 497]])\n",
            " list([[0, 196], [1, 58], [2, 508], [4, 67], [5, 178]])\n",
            " list([[0, 197], [1, 507], [2, 76], [3, 369], [5, 478]])\n",
            " list([[0, 198], [1, 390], [2, 346], [3, 189], [5, 607]])\n",
            " list([[0, 199], [1, 537], [2, 127], [4, 450], [5, 158]])\n",
            " list([[0, 200], [1, 396], [2, 204], [3, 159], [5, 577]])\n",
            " list([[0, 201], [1, 45], [2, 375], [4, 452], [5, 474]])\n",
            " list([[0, 202], [1, 196], [2, 339], [4, 151], [5, 214]])\n",
            " list([[0, 203], [1, 161], [2, 543], [3, 356], [5, 340]])\n",
            " list([[0, 204], [1, 60], [2, 274], [4, 53], [5, 494]])\n",
            " list([[0, 205], [1, 216], [2, 474], [3, 163], [5, 635]])\n",
            " list([[0, 206], [1, 380], [2, 207], [3, 367], [5, 36]])\n",
            " list([[0, 207], [1, 556], [2, 195], [3, 401], [5, 135]])\n",
            " list([[0, 208], [1, 391], [2, 216], [3, 128], [5, 606]])\n",
            " list([[0, 209], [1, 179], [2, 373], [4, 26], [5, 283]])\n",
            " list([[0, 210], [1, 111], [2, 395], [4, 397], [5, 122]])\n",
            " list([[0, 211], [1, 510], [2, 289], [3, 230], [5, 658]])\n",
            " list([[0, 212], [1, 492], [2, 242], [3, 388], [4, 186], [5, 486]])\n",
            " list([[0, 213], [1, 263], [2, 239], [3, 321], [5, 662]])\n",
            " list([[0, 214], [1, 487], [2, 180], [4, 46], [5, 564]])\n",
            " list([[0, 215], [1, 559], [2, 84], [3, 258], [5, 527]])\n",
            " list([[0, 216], [1, 250], [2, 218], [3, 150], [5, 38]])\n",
            " list([[0, 217], [1, 82], [2, 489], [4, 10], [5, 179]])\n",
            " list([[0, 218], [1, 334], [2, 105], [3, 246], [5, 301]])\n",
            " list([[0, 219], [1, 365], [2, 173], [4, 96], [5, 547]])\n",
            " list([[0, 220], [1, 379], [2, 78], [4, 31], [5, 554]])\n",
            " list([[0, 221], [1, 540], [2, 109], [3, 364], [4, 190], [5, 129]])\n",
            " list([[0, 222], [1, 550], [2, 118], [4, 438], [5, 337]])\n",
            " list([[0, 223], [1, 514], [2, 454], [3, 290], [5, 91]])\n",
            " list([[0, 224], [1, 475], [2, 206], [3, 268], [5, 423]])\n",
            " list([[0, 225], [1, 393], [2, 208], [3, 424], [5, 46]])\n",
            " list([[0, 226], [1, 484], [2, 135], [3, 221], [5, 120]])\n",
            " list([[0, 227], [1, 333], [2, 232], [3, 280], [5, 280]])\n",
            " list([[0, 228], [1, 189], [2, 344], [3, 419], [5, 125]])\n",
            " list([[0, 229], [1, 63], [2, 439], [4, 82], [5, 617]])\n",
            " list([[0, 230], [1, 335], [2, 257], [3, 328], [5, 95]])\n",
            " list([[0, 231], [1, 431], [2, 423], [3, 370], [5, 25]])\n",
            " list([[0, 232], [1, 403], [2, 108], [3, 218], [5, 5]])\n",
            " list([[0, 233], [1, 363], [2, 87], [3, 109], [5, 418]])\n",
            " list([[0, 234], [1, 495], [2, 272], [3, 133], [5, 66]])\n",
            " list([[0, 235], [1, 425], [2, 506], [3, 149], [5, 611]])\n",
            " list([[0, 236], [1, 290], [2, 466], [3, 391], [5, 623]])\n",
            " list([[0, 237], [1, 142], [2, 294], [4, 260], [5, 323]])\n",
            " list([[0, 238], [1, 386], [2, 467], [3, 209], [5, 310]])\n",
            " list([[0, 239], [1, 170], [2, 286], [4, 306], [5, 519]])\n",
            " list([[0, 240], [1, 511], [2, 445], [3, 121], [5, 398]])\n",
            " list([[0, 241], [1, 79], [2, 417], [3, 422], [5, 386]])\n",
            " list([[0, 242], [1, 191], [2, 347], [4, 42], [5, 182]])\n",
            " list([[0, 243], [1, 554], [2, 481], [3, 120], [5, 27]])\n",
            " list([[0, 244], [1, 255], [2, 117], [4, 94], [5, 131]])\n",
            " list([[0, 245], [1, 349], [2, 270], [3, 223], [5, 107]])\n",
            " list([[0, 246], [1, 294], [2, 354], [3, 372], [5, 41]])\n",
            " list([[0, 247], [1, 331], [2, 483], [3, 232], [4, 405], [5, 470]])\n",
            " list([[0, 248], [1, 489], [2, 381], [3, 212], [5, 594]])\n",
            " list([[0, 249], [1, 313], [2, 177], [3, 324], [5, 303]])\n",
            " list([[0, 250], [1, 219], [2, 302], [4, 421], [5, 174]])\n",
            " list([[0, 251], [1, 265], [2, 440], [3, 417], [5, 281]])\n",
            " list([[0, 252], [1, 210], [2, 273], [3, 261], [5, 241]])\n",
            " list([[0, 253], [1, 47], [2, 226], [3, 251], [5, 404]])\n",
            " list([[0, 254], [1, 395], [2, 511], [3, 296], [5, 19]])\n",
            " list([[0, 255], [1, 467], [2, 200], [3, 116], [5, 94]])\n",
            " list([[0, 256], [1, 342], [2, 160], [3, 264], [5, 566]])\n",
            " list([[0, 257], [1, 561], [2, 134], [4, 454], [5, 364]])\n",
            " list([[0, 258], [1, 276], [2, 356], [3, 196], [5, 501]])\n",
            " list([[0, 259], [1, 381], [2, 470], [3, 286], [5, 655]])\n",
            " list([[0, 260], [1, 330], [2, 231], [3, 110], [5, 160]])\n",
            " list([[0, 261], [1, 539], [2, 447], [3, 197], [5, 314]])\n",
            " list([[0, 262], [1, 421], [2, 449], [3, 107], [5, 243]])\n",
            " list([[0, 263], [1, 418], [2, 163], [3, 325], [5, 557]])\n",
            " list([[0, 264], [1, 434], [2, 431], [3, 148], [5, 657]])\n",
            " list([[0, 265], [1, 500], [2, 187], [3, 366], [5, 112]])\n",
            " list([[0, 266], [1, 464], [2, 199], [4, 446], [5, 167]])\n",
            " list([[0, 267], [1, 422], [2, 72], [3, 395], [4, 360], [5, 464]])\n",
            " list([[0, 268], [1, 280], [2, 377], [3, 216], [5, 654]])\n",
            " list([[0, 269], [1, 39], [2, 338], [3, 362], [5, 399]])\n",
            " list([[0, 270], [1, 110], [2, 504], [4, 86], [5, 517]])\n",
            " list([[0, 271], [1, 46], [2, 320], [3, 160], [5, 60]])\n",
            " list([[0, 272], [1, 385], [2, 308], [3, 348], [5, 72]])\n",
            " list([[0, 273], [1, 397], [2, 67], [4, 447], [5, 251]])\n",
            " list([[0, 274], [1, 411], [2, 116], [3, 248], [5, 231]])\n",
            " list([[0, 275], [1, 483], [2, 255], [3, 213], [5, 636]])\n",
            " list([[0, 276], [1, 515], [2, 70], [3, 220], [5, 613]])\n",
            " list([[0, 277], [1, 69], [2, 140], [3, 291], [5, 380]])\n",
            " list([[0, 278], [1, 31], [2, 426], [4, 439], [5, 453]])\n",
            " list([[0, 279], [1, 122], [2, 516], [4, 437], [5, 592]])\n",
            " list([[0, 280], [1, 123], [2, 513], [4, 4], [5, 443]])\n",
            " list([[0, 281], [1, 261], [2, 63], [3, 331], [5, 666]])\n",
            " list([[0, 282], [1, 311], [2, 211], [3, 166], [5, 407]])\n",
            " list([[0, 283], [1, 125], [2, 546], [4, 289], [5, 200]])\n",
            " list([[0, 284], [1, 209], [2, 372], [3, 373], [5, 543]])\n",
            " list([[0, 285], [1, 275], [2, 287], [3, 235], [5, 246]])\n",
            " list([[0, 286], [1, 93], [2, 352], [4, 235], [5, 389]])\n",
            " list([[0, 287], [1, 208], [2, 527], [4, 3], [5, 488]])\n",
            " list([[0, 288], [1, 215], [2, 329], [4, 218], [5, 132]])\n",
            " list([[0, 289], [1, 226], [2, 224], [4, 49], [5, 341]])\n",
            " list([[0, 290], [1, 289], [2, 244], [3, 124], [5, 548]])\n",
            " list([[0, 291], [1, 49], [2, 236], [3, 260], [5, 24]])\n",
            " list([[0, 292], [1, 336], [2, 319], [3, 140], [5, 147]])\n",
            " list([[0, 293], [1, 547], [2, 502], [3, 190], [5, 588]])\n",
            " list([[0, 294], [1, 309], [2, 330], [3, 247], [5, 3]])\n",
            " list([[0, 295], [1, 274], [2, 500], [3, 333], [5, 227]])\n",
            " list([[0, 296], [1, 89], [2, 494], [4, 436], [5, 430]])\n",
            " list([[0, 297], [1, 168], [2, 269], [4, 55], [5, 388]])\n",
            " list([[0, 298], [1, 528], [2, 136], [3, 100], [5, 155]])\n",
            " list([[0, 299], [1, 322], [2, 176], [3, 307], [5, 510]])\n",
            " list([[0, 300], [1, 457], [2, 146], [3, 387], [5, 65]])\n",
            " list([[0, 301], [1, 282], [2, 432], [3, 129], [5, 7]])\n",
            " list([[0, 302], [1, 516], [2, 507], [3, 265], [5, 96]])\n",
            " list([[0, 303], [1, 474], [2, 161], [3, 250], [5, 254]])\n",
            " list([[0, 304], [1, 525], [2, 214], [3, 357], [5, 651]])\n",
            " list([[0, 305], [1, 340], [2, 100], [3, 315], [5, 35]])\n",
            " list([[0, 306], [1, 476], [2, 131], [3, 394], [5, 175]])\n",
            " list([[0, 307], [1, 523], [2, 155], [4, 41], [5, 532]])\n",
            " list([[0, 308], [1, 326], [2, 514], [3, 117], [5, 518]])\n",
            " list([[0, 309], [1, 223], [2, 263], [4, 77], [5, 213]])\n",
            " list([[0, 310], [1, 384], [2, 276], [3, 203], [5, 14]])\n",
            " list([[0, 311], [1, 506], [2, 450], [3, 316], [5, 656]])\n",
            " list([[0, 312], [1, 479], [2, 77], [3, 398], [5, 582]])\n",
            " list([[0, 313], [1, 33], [2, 479], [3, 132], [5, 87]])\n",
            " list([[0, 314], [1, 102], [2, 281], [4, 13], [5, 469]])\n",
            " list([[0, 315], [1, 70], [2, 268], [3, 293], [5, 603]])\n",
            " list([[0, 316], [1, 482], [2, 324], [3, 319], [5, 58]])\n",
            " list([[0, 317], [1, 493], [2, 327], [3, 420], [4, 210], [5, 257]])\n",
            " list([[0, 318], [1, 169], [2, 360], [4, 435], [5, 411]])\n",
            " list([[0, 319], [1, 140], [2, 361], [4, 167], [5, 397]])\n",
            " list([[0, 320], [1, 54], [2, 249], [4, 36], [5, 111]])\n",
            " list([[0, 321], [1, 220], [2, 420], [4, 433], [5, 103]])\n",
            " list([[0, 322], [1, 121], [2, 406], [4, 443], [5, 495]])\n",
            " list([[0, 323], [1, 158], [2, 457], [4, 334], [5, 452]])\n",
            " list([[0, 324], [1, 455], [2, 66], [4, 40], [5, 565]])\n",
            " list([[0, 325], [1, 298], [2, 148], [3, 381], [5, 31]])\n",
            " list([[0, 326], [1, 327], [2, 164], [3, 229], [5, 629]])\n",
            " list([[0, 327], [1, 488], [2, 186], [3, 234], [5, 45]])\n",
            " list([[0, 328], [1, 398], [2, 405], [3, 303], [5, 15]])\n",
            " list([[0, 329], [1, 104], [2, 428], [4, 72], [5, 496]])\n",
            " list([[0, 330], [1, 130], [2, 376], [4, 16], [5, 412]])\n",
            " list([[0, 331], [1, 362], [2, 262], [3, 202], [5, 55]])\n",
            " list([[0, 332], [1, 260], [2, 107], [4, 28], [5, 350]])\n",
            " list([[0, 333], [1, 300], [2, 106], [4, 453], [5, 569]])\n",
            " list([[0, 334], [1, 37], [2, 238], [4, 47], [5, 405]])\n",
            " list([[0, 335], [1, 87], [2, 436], [4, 84], [5, 533]])\n",
            " list([[0, 336], [1, 107], [2, 471], [4, 54], [5, 159]])\n",
            " list([[0, 337], [1, 52], [2, 342], [3, 297], [5, 491]])\n",
            " list([[0, 338], [1, 513], [2, 421], [3, 241], [5, 306]])\n",
            " list([[0, 339], [1, 229], [2, 235], [3, 176], [5, 573]])\n",
            " list([[0, 340], [1, 251], [2, 95], [3, 308], [5, 580]])\n",
            " list([[0, 341], [1, 459], [2, 80], [3, 400], [5, 201]])\n",
            " list([[0, 342], [1, 277], [2, 478], [3, 215], [5, 663]])\n",
            " list([[0, 343], [1, 269], [2, 523], [3, 119], [5, 123]])\n",
            " list([[0, 344], [1, 478], [2, 452], [3, 317], [5, 51]])\n",
            " list([[0, 345], [1, 178], [2, 550], [4, 130], [5, 255]])\n",
            " list([[0, 346], [1, 183], [2, 362], [4, 355], [5, 632]])\n",
            " list([[0, 347], [1, 211], [2, 526], [3, 358], [5, 335]])\n",
            " list([[0, 348], [1, 101], [2, 425], [4, 22], [5, 477]])\n",
            " list([[0, 349], [1, 491], [2, 147], [3, 262], [5, 30]])\n",
            " list([[0, 350], [1, 552], [2, 190], [3, 371], [5, 11]])\n",
            " list([[0, 351], [1, 296], [2, 75], [4, 24], [5, 133]])\n",
            " list([[0, 352], [1, 480], [2, 233], [3, 255], [5, 63]])\n",
            " list([[0, 353], [1, 542], [2, 194], [3, 224], [5, 156]])\n",
            " list([[0, 354], [1, 35], [2, 414], [4, 8], [5, 189]])\n",
            " list([[0, 355], [1, 68], [2, 505], [3, 256], [5, 660]])\n",
            " list([[0, 356], [1, 316], [2, 189], [3, 237], [5, 37]])\n",
            " list([[0, 357], [1, 83], [2, 442], [4, 427], [5, 211]])\n",
            " list([[0, 358], [1, 66], [2, 497], [4, 92], [5, 165]])\n",
            " list([[0, 359], [1, 273], [2, 374], [3, 236], [4, 188], [5, 602]])\n",
            " list([[0, 360], [1, 389], [2, 297], [3, 164], [4, 380], [5, 645]])\n",
            " list([[0, 361], [1, 305], [2, 283], [3, 292], [5, 82]])\n",
            " list([[0, 362], [1, 190], [2, 247], [3, 360], [5, 33]])\n",
            " list([[0, 363], [1, 378], [2, 91], [3, 145], [5, 609]])\n",
            " list([[0, 364], [1, 48], [2, 85], [3, 127], [5, 600]])\n",
            " list([[0, 365], [1, 202], [2, 407], [4, 88], [5, 648]])\n",
            " list([[0, 366], [1, 51], [2, 459], [4, 93], [5, 368]])\n",
            " list([[0, 367], [1, 427], [2, 275], [3, 165], [5, 8]])\n",
            " list([[0, 368], [1, 32], [2, 434], [3, 278], [5, 6]])\n",
            " list([[0, 369], [1, 40], [2, 542], [3, 410], [5, 21]])\n",
            " list([[0, 370], [1, 361], [2, 429], [3, 152], [5, 52]])\n",
            " list([[0, 371], [1, 466], [2, 185], [3, 219], [5, 541]])\n",
            " list([[0, 372], [1, 518], [2, 536], [3, 282], [5, 50]])\n",
            " list([[0, 373], [1, 188], [2, 490], [4, 27], [5, 322]])\n",
            " list([[0, 374], [1, 59], [2, 313], [4, 29], [5, 173]])\n",
            " list([[0, 375], [1, 90], [2, 309], [3, 375], [5, 312]])\n",
            " list([[0, 376], [1, 206], [2, 458], [4, 51], [5, 424]])\n",
            " list([[0, 377], [1, 272], [2, 531], [3, 225], [5, 661]])\n",
            " list([[0, 378], [1, 473], [2, 279], [3, 279], [5, 113]])\n",
            " list([[0, 379], [1, 498], [2, 510], [3, 249], [5, 325]])\n",
            " list([[0, 380], [1, 535], [2, 469], [3, 199], [5, 49]])\n",
            " list([[0, 381], [1, 30], [2, 443], [4, 95], [5, 492]])\n",
            " list([[0, 382], [1, 74], [2, 325], [4, 38], [5, 620]])\n",
            " list([[0, 383], [1, 217], [2, 491], [4, 12], [5, 77]])\n",
            " list([[0, 384], [1, 252], [2, 261], [3, 263], [5, 164]])\n",
            " list([[0, 385], [1, 486], [2, 193], [3, 355], [5, 618]])\n",
            " list([[0, 386], [1, 310], [2, 198], [4, 0], [5, 387]])\n",
            " list([[0, 387], [1, 392], [2, 545], [4, 9], [5, 428]])\n",
            " list([[0, 388], [1, 41], [2, 419], [3, 134], [4, 209], [5, 363]])\n",
            " list([[0, 389], [1, 91], [2, 355], [4, 50], [5, 279]])\n",
            " list([[0, 390], [1, 402], [2, 86], [3, 368], [5, 141]])\n",
            " list([[0, 391], [1, 447], [2, 465], [3, 349], [5, 265]])\n",
            " list([[0, 392], [1, 551], [2, 79], [3, 238], [5, 393]])\n",
            " list([[0, 393], [1, 264], [2, 217], [3, 327], [5, 13]])\n",
            " list([[0, 394], [1, 302], [2, 333], [3, 396], [5, 598]])\n",
            " list([[0, 395], [1, 301], [2, 451], [3, 392], [4, 325], [5, 102]])\n",
            " list([[0, 396], [1, 80], [2, 363], [4, 63], [5, 294]])\n",
            " list([[0, 397], [1, 50], [2, 418], [3, 277], [5, 473]])\n",
            " list([[0, 398], [1, 451], [2, 403], [4, 448], [5, 535]])\n",
            " list([[0, 399], [1, 555], [2, 181], [4, 432], [5, 431]])\n",
            " list([[0, 400], [1, 350], [2, 158], [3, 231], [5, 277]])\n",
            " list([[0, 401], [1, 560], [2, 278], [3, 141], [5, 186]])\n",
            " list([[0, 402], [1, 472], [2, 380], [3, 167], [5, 62]])\n",
            " list([[0, 403], [1, 88], [2, 296], [4, 124], [5, 90]])\n",
            " list([[0, 404], [1, 72], [2, 357], [4, 39], [5, 12]])\n",
            " list([[0, 405], [1, 36], [2, 351], [4, 89], [5, 197]])\n",
            " list([[0, 406], [1, 103], [2, 337], [4, 23], [5, 413]])\n",
            " list([[0, 407], [1, 53], [2, 398], [4, 17], [5, 439]])\n",
            " list([[0, 408], [1, 278], [2, 167], [3, 329], [5, 258]])\n",
            " list([[0, 409], [1, 353], [2, 404], [4, 440], [5, 425]])\n",
            " list([[0, 410], [1, 359], [2, 332], [3, 383], [5, 245]])\n",
            " list([[0, 411], [1, 527], [2, 464], [3, 200], [5, 561]])\n",
            " list([[0, 412], [1, 318], [2, 334], [3, 363], [5, 10]])\n",
            " list([[0, 413], [1, 448], [2, 430], [3, 390], [5, 53]])\n",
            " list([[0, 414], [1, 504], [2, 387], [3, 276], [5, 659]])\n",
            " list([[0, 415], [1, 532], [2, 335], [3, 386], [5, 42]])\n",
            " list([[0, 416], [1, 73], [2, 541], [4, 58], [5, 500]])\n",
            " list([[0, 417], [1, 175], [2, 299], [4, 243], [5, 26]])\n",
            " list([[0, 418], [1, 62], [2, 422], [4, 45], [5, 374]])\n",
            " list([[0, 419], [1, 119], [2, 415], [4, 64], [5, 403]])\n",
            " list([[0, 420], [1, 383], [2, 266], [3, 295], [5, 264]])\n",
            " list([[0, 421], [1, 346], [2, 512], [3, 326], [5, 385]])\n",
            " list([[0, 422], [1, 324], [2, 408], [3, 252], [5, 579]])\n",
            " list([[0, 423], [1, 285], [2, 448], [3, 195], [4, 361], [5, 515]])\n",
            " list([[0, 424], [1, 481], [2, 89], [3, 99], [5, 311]])\n",
            " list([[0, 425], [1, 456], [2, 120], [3, 239], [5, 115]])\n",
            " list([[0, 426], [1, 401], [2, 88], [3, 105], [5, 20]])\n",
            " list([[0, 427], [1, 253], [2, 166], [3, 287], [5, 359]])\n",
            " list([[0, 428], [1, 438], [2, 310], [3, 399], [5, 32]])\n",
            " list([[0, 429], [1, 315], [2, 537], [4, 407], [5, 346]])\n",
            " list([[0, 430], [1, 374], [2, 379], [4, 254], [5, 595]])\n",
            " list([[0, 431], [1, 520], [2, 480], [4, 258], [5, 263]])\n",
            " list([[0, 432], [1, 544], [2, 229], [4, 150], [5, 512]])\n",
            " list([[0, 433], [1, 287], [2, 535], [4, 356], [5, 481]])\n",
            " list([[0, 434], [1, 429], [2, 258], [4, 371], [5, 401]])\n",
            " list([[0, 435], [1, 490], [2, 539], [4, 199], [5, 522]])\n",
            " list([[0, 436], [1, 408], [2, 411], [4, 422], [5, 647]])\n",
            " list([[0, 437], [1, 356], [2, 291], [4, 164], [5, 59]])\n",
            " list([[0, 438], [1, 360], [2, 492], [4, 423], [5, 108]])\n",
            " list([[0, 439], [1, 460], [2, 314], [4, 285], [5, 333]])\n",
            " list([[0, 440], [1, 295], [2, 524], [4, 396], [5, 324]])\n",
            " list([[0, 441], [1, 468], [2, 253], [4, 102], [5, 195]])\n",
            " list([[0, 442], [1, 524], [2, 499], [4, 319], [5, 649]])\n",
            " list([[0, 443], [1, 503], [2, 397], [4, 107], [5, 85]])\n",
            " list([[0, 444], [1, 445], [2, 284], [4, 207], [5, 358]])\n",
            " list([[0, 445], [1, 549], [2, 90], [4, 399], [5, 615]])\n",
            " list([[0, 446], [1, 317], [2, 316], [4, 381], [5, 18]])\n",
            " list([[0, 447], [1, 339], [2, 549], [4, 249], [5, 400]])\n",
            " list([[0, 448], [1, 553], [2, 243], [4, 112], [5, 317]])\n",
            " list([[0, 449], [1, 244], [2, 401], [4, 182], [5, 402]])\n",
            " list([[0, 450], [1, 436], [2, 264], [4, 295], [5, 9]])\n",
            " list([[0, 451], [1, 469], [2, 301], [4, 152], [5, 610]])\n",
            " list([[0, 452], [1, 245], [2, 540], [4, 7], [5, 144]])\n",
            " list([[0, 453], [1, 376], [2, 495], [4, 121], [5, 157]])\n",
            " list([[0, 454], [1, 337], [2, 304], [4, 208], [5, 270]])\n",
            " list([[0, 455], [1, 501], [2, 399], [4, 338], [5, 298]])\n",
            " list([[0, 456], [1, 406], [2, 522], [4, 230], [5, 180]])\n",
            " list([[0, 457], [1, 56], [2, 441], [4, 162], [5, 361]])\n",
            " list([[1, 629], [2, 557], [3, 29], [4, 270], [5, 342]])\n",
            " list([[1, 650], [2, 597], [3, 64], [4, 127], [5, 379]])\n",
            " list([[1, 625], [2, 599], [3, 55], [4, 259], [5, 574]])\n",
            " list([[1, 593], [2, 560], [3, 37], [4, 417], [5, 110]])\n",
            " list([[1, 597], [2, 610], [3, 62], [4, 290], [5, 354]])\n",
            " list([[1, 608], [2, 566], [3, 426], [4, 339], [5, 152]])\n",
            " list([[1, 618], [2, 642], [3, 427], [4, 15], [5, 487]])\n",
            " list([[1, 601], [2, 590], [3, 80], [4, 159], [5, 4]])\n",
            " list([[1, 649], [2, 577], [3, 30], [4, 393], [5, 382]])\n",
            " list([[1, 613], [2, 602], [3, 17], [4, 120], [5, 493]])\n",
            " list([[1, 635], [2, 569], [3, 89], [4, 168], [5, 202]])\n",
            " list([[1, 653], [2, 611], [3, 448], [4, 351], [5, 516]])\n",
            " list([[1, 576], [2, 619], [3, 94], [4, 65], [5, 583]])\n",
            " list([[1, 622], [2, 594], [3, 447], [4, 146], [5, 626]])\n",
            " list([[1, 194], [2, 663], [3, 11], [4, 372], [5, 567]])\n",
            " list([[1, 135], [2, 650], [3, 429], [4, 105], [5, 375]])\n",
            " list([[1, 604], [2, 656], [3, 70], [4, 318], [5, 622]])\n",
            " list([[1, 591], [2, 662], [3, 27], [4, 312], [5, 549]])\n",
            " list([[1, 570], [2, 570], [3, 77], [4, 389], [5, 278]])\n",
            " list([[1, 600], [2, 637], [3, 320], [4, 410], [5, 441]])\n",
            " list([[1, 156], [2, 11], [3, 242], [4, 109], [5, 285]])\n",
            " list([[1, 174], [2, 7], [3, 351], [4, 274], [5, 139]])\n",
            " list([[1, 153], [2, 648], [3, 452], [4, 328], [5, 434]])\n",
            " list([[1, 197], [2, 607], [3, 7], [4, 196], [5, 345]])\n",
            " list([[1, 566], [2, 603], [3, 93], [4, 232], [5, 630]])\n",
            " list([[1, 585], [2, 641], [3, 87], [4, 341], [5, 138]])\n",
            " list([[1, 626], [2, 624], [3, 33], [4, 165], [5, 416]])\n",
            " list([[1, 575], [2, 604], [3, 49], [4, 253], [5, 198]])\n",
            " list([[1, 193], [2, 585], [3, 10], [4, 143], [5, 114]])\n",
            " list([[1, 128], [2, 559], [3, 438], [4, 236], [5, 339]])\n",
            " list([[1, 154], [2, 1], [3, 143], [4, 302], [5, 621]])\n",
            " list([[1, 129], [2, 26], [3, 415], [4, 347], [5, 461]])\n",
            " list([[1, 94], [2, 555], [3, 430], [4, 390], [5, 71]])\n",
            " list([[1, 98], [2, 652], [3, 443], [4, 153], [5, 150]])\n",
            " list([[1, 116], [2, 595], [3, 13], [4, 350], [5, 290]])\n",
            " list([[1, 145], [2, 24], [3, 380], [4, 226], [5, 652]])\n",
            " list([[1, 95], [2, 12], [3, 284], [4, 181], [5, 463]])\n",
            " list([[1, 75], [2, 30], [3, 31], [4, 335], [5, 429]])\n",
            " list([[1, 108], [2, 4], [3, 337], [4, 337], [5, 284]])\n",
            " list([[1, 200], [2, 32], [3, 412], [4, 149], [5, 287]])\n",
            " list([[1, 150], [2, 34], [3, 406], [4, 202], [5, 67]])\n",
            " list([[1, 201], [2, 635], [3, 441], [4, 175], [5, 471]])\n",
            " list([[1, 172], [2, 620], [3, 437], [4, 413], [5, 633]])\n",
            " list([[1, 149], [2, 22], [3, 344], [4, 135], [5, 207]])\n",
            " list([[1, 113], [2, 553], [3, 47], [4, 200], [5, 353]])\n",
            " list([[1, 207], [2, 33], [3, 45], [4, 353], [5, 126]])\n",
            " list([[1, 180], [2, 5], [3, 339], [4, 264], [5, 410]])\n",
            " list([[1, 131], [2, 45], [3, 376], [4, 279], [5, 276]])\n",
            " list([[1, 195], [2, 623], [3, 454], [4, 343], [5, 440]])\n",
            " list([[1, 77], [2, 593], [3, 6], [4, 145], [5, 154]])\n",
            " list([[1, 84], [2, 56], [3, 243], [4, 275], [5, 520]])\n",
            " list([[1, 109], [2, 561], [3, 444], [4, 379], [5, 391]])\n",
            " list([[1, 78], [2, 29], [3, 407], [4, 229], [5, 625]])\n",
            " list([[1, 164], [2, 36], [3, 425], [4, 215], [5, 184]])\n",
            " list([[1, 184], [2, 552], [3, 46], [4, 329], [5, 551]])\n",
            " list([[1, 143], [2, 8], [3, 342], [4, 317], [5, 616]])\n",
            " list([[1, 138], [2, 645], [3, 434], [4, 402], [5, 534]])\n",
            " list([[1, 187], [2, 19], [3, 272], [4, 280], [5, 233]])\n",
            " list([[1, 127], [2, 49], [3, 191], [4, 316], [5, 99]])\n",
            " list([[1, 137], [2, 554], [3, 21], [4, 183], [5, 86]])\n",
            " list([[1, 139], [2, 600], [3, 92], [4, 281], [5, 196]])\n",
            " list([[1, 167], [2, 17], [3, 173], [4, 336], [5, 308]])\n",
            " list([[1, 222], [2, 52], [3, 312], [4, 301], [5, 642]])\n",
            " list([[1, 134], [2, 2], [3, 267], [4, 383], [5, 329]])\n",
            " list([[1, 577], [2, 573], [3, 95], [4, 228], [5, 327]])\n",
            " list([[1, 612], [2, 563], [3, 75], [4, 398], [5, 498]])\n",
            " list([[1, 579], [2, 591], [3, 42], [4, 180], [5, 396]])\n",
            " list([[1, 633], [2, 657], [3, 54], [4, 201], [5, 181]])\n",
            " list([[1, 588], [2, 580], [3, 449], [4, 220], [5, 352]])\n",
            " list([[1, 598], [2, 631], [3, 439], [4, 211], [5, 220]])\n",
            " list([[1, 606], [2, 582], [3, 68], [4, 242], [5, 177]])\n",
            " list([[1, 646], [2, 583], [3, 0], [4, 74], [5, 304]])\n",
            " list([[1, 567], [2, 556], [3, 51], [4, 245], [5, 351]])\n",
            " list([[1, 603], [2, 574], [3, 20], [4, 282], [5, 550]])\n",
            " list([[1, 623], [2, 616], [3, 25], [4, 401], [5, 372]])\n",
            " list([[1, 615], [2, 150], [3, 59], [4, 305], [5, 80]])\n",
            " list([[1, 584], [2, 634], [3, 88], [4, 238], [5, 449]])\n",
            " list([[1, 599], [2, 592], [3, 442], [4, 223], [5, 260]])\n",
            " list([[1, 136], [2, 605], [3, 436], [4, 374], [5, 309]])\n",
            " list([[1, 176], [2, 618], [3, 8], [4, 418], [5, 250]])\n",
            " list([[1, 637], [2, 578], [3, 38], [4, 222], [5, 536]])\n",
            " list([[1, 619], [2, 579], [3, 84], [4, 250], [5, 204]])\n",
            " list([[1, 583], [2, 571], [3, 50], [4, 163], [5, 89]])\n",
            " list([[1, 571], [2, 575], [3, 44], [4, 154], [5, 104]])\n",
            " list([[1, 115], [2, 58], [3, 353], [4, 158], [5, 462]])\n",
            " list([[1, 213], [2, 568], [3, 5], [4, 204], [5, 238]])\n",
            " list([[1, 97], [2, 576], [3, 451], [4, 330], [5, 457]])\n",
            " list([[1, 155], [2, 51], [3, 205], [4, 269], [5, 356]])\n",
            " list([[1, 562], [2, 627], [3, 12], [4, 384], [5, 188]])\n",
            " list([[1, 578], [2, 659], [3, 39], [4, 303], [5, 562]])\n",
            " list([[1, 627], [2, 653], [3, 74], [4, 255], [5, 599]])\n",
            " list([[1, 617], [2, 615], [3, 2], [4, 61], [5, 206]])\n",
            " list([[1, 177], [2, 621], [3, 428], [4, 266], [5, 297]])\n",
            " list([[1, 133], [2, 647], [3, 1], [4, 136], [5, 542]])\n",
            " list([[1, 124], [2, 638], [3, 432], [4, 352], [5, 357]])\n",
            " list([[1, 166], [2, 20], [3, 142], [4, 147], [5, 229]])\n",
            " list([[1, 173], [2, 37], [3, 378], [4, 354], [5, 316]])\n",
            " list([[1, 106], [2, 562], [3, 431], [4, 327], [5, 288]])\n",
            " list([[1, 212], [2, 46], [3, 56], [4, 392], [5, 644]])\n",
            " list([[1, 214], [2, 6], [3, 346], [4, 241], [5, 417]])\n",
            " list([[1, 198], [2, 44], [3, 405], [4, 365], [5, 172]])\n",
            " list([[1, 76], [2, 35], [3, 35], [4, 299], [5, 234]])\n",
            " list([[1, 86], [2, 48], [3, 269], [4, 320], [5, 349]])\n",
            " list([[1, 186], [2, 581], [3, 34], [4, 388], [5, 315]])\n",
            " list([[1, 144], [2, 53], [3, 347], [4, 239], [5, 225]])\n",
            " list([[1, 160], [2, 661], [3, 440], [4, 113], [5, 546]])\n",
            " list([[1, 117], [2, 654], [3, 97], [4, 19], [5, 224]])\n",
            " list([[1, 132], [2, 9], [3, 153], [4, 140], [5, 392]])\n",
            " list([[1, 55], [2, 655], [3, 86], [4, 123], [5, 394]])\n",
            " list([[1, 114], [2, 54], [3, 275], [4, 385], [5, 271]])\n",
            " list([[1, 146], [2, 39], [3, 354], [4, 219], [5, 215]])\n",
            " list([[1, 85], [2, 612], [3, 48], [4, 178], [5, 585]])\n",
            " list([[1, 112], [2, 614], [3, 446], [4, 373], [5, 480]])\n",
            " list([[1, 221], [2, 660], [3, 90], [4, 367], [5, 235]])\n",
            " list([[1, 118], [2, 55], [3, 311], [4, 293], [5, 239]])\n",
            " list([[1, 157], [2, 584], [3, 453], [4, 137], [5, 395]])\n",
            " list([[1, 171], [2, 643], [3, 435], [4, 244], [5, 274]])\n",
            " list([[1, 199], [2, 3], [3, 207], [4, 103], [5, 289]])\n",
            " list([[1, 203], [2, 50], [3, 155], [4, 246], [5, 586]])\n",
            " list([[1, 148], [2, 564], [3, 450], [4, 323], [5, 242]])\n",
            " list([[1, 163], [2, 598], [3, 66], [4, 166], [5, 465]])\n",
            " list([[1, 152], [2, 27], [3, 154], [4, 344], [5, 499]])\n",
            " list([[1, 120], [2, 28], [3, 302], [4, 108], [5, 605]])\n",
            " list([[1, 218], [2, 57], [3, 204], [4, 314], [5, 296]])\n",
            " list([[1, 159], [2, 47], [3, 137], [4, 394], [5, 266]])\n",
            " list([[1, 92], [2, 10], [3, 270], [4, 100], [5, 106]])\n",
            " list([[1, 141], [2, 40], [3, 343], [4, 387], [5, 338]])\n",
            " list([[1, 126], [2, 14], [3, 180], [4, 298], [5, 643]])\n",
            " list([[1, 9], [2, 141], [3, 193], [4, 420], [5, 460]])\n",
            " list([[1, 7], [2, 60], [3, 174], [4, 227], [5, 193]])\n",
            " list([[1, 15], [2, 129], [3, 266], [4, 307], [5, 137]])\n",
            " list([[1, 11], [2, 123], [3, 274], [4, 395], [5, 321]])\n",
            " list([[1, 563], [2, 183], [3, 208], [4, 267], [5, 218]])\n",
            " list([[1, 614], [2, 649], [3, 283], [4, 144], [5, 88]])\n",
            " list([[1, 565], [2, 133], [3, 192], [4, 346], [5, 608]])\n",
            " list([[1, 574], [2, 586], [3, 57], [4, 221], [5, 145]])\n",
            " list([[1, 19], [2, 93], [3, 144], [4, 213], [5, 427]])\n",
            " list([[1, 23], [2, 21], [3, 206], [4, 115], [5, 525]])\n",
            " list([[1, 8], [2, 38], [3, 413], [4, 296], [5, 507]])\n",
            " list([[1, 12], [2, 31], [3, 168], [4, 172], [5, 604]])\n",
            " list([[1, 654], [2, 121], [3, 186], [4, 278], [5, 256]])\n",
            " list([[1, 640], [2, 73], [3, 9], [4, 173], [5, 455]])\n",
            " list([[1, 580], [2, 143], [3, 76], [4, 257], [5, 336]])\n",
            " list([[1, 616], [2, 149], [3, 228], [4, 184], [5, 483]])\n",
            " list([[1, 27], [2, 23], [3, 182], [4, 111], [5, 524]])\n",
            " list([[1, 24], [2, 13], [3, 138], [4, 300], [5, 505]])\n",
            " list([[1, 16], [2, 15], [3, 179], [4, 139], [5, 466]])\n",
            " list([[1, 20], [2, 42], [3, 244], [4, 345], [5, 414]])\n",
            " list([[1, 652], [2, 558], [3, 53], [4, 114], [5, 98]])\n",
            " list([[1, 609], [2, 601], [3, 103], [4, 342], [5, 109]])\n",
            " list([[1, 630], [2, 119], [3, 22], [4, 174], [5, 183]])\n",
            " list([[1, 573], [2, 165], [3, 72], [4, 170], [5, 228]])\n",
            " list([[1, 233], [2, 157], [3, 273], [4, 205], [5, 409]])\n",
            " list([[1, 235], [2, 640], [3, 181], [4, 216], [5, 378]])\n",
            " list([[1, 655], [2, 0], [3, 69], [4, 362], [5, 275]])\n",
            " list([[1, 564], [2, 103], [3, 139], [4, 191], [5, 366]])\n",
            " list([[1, 632], [2, 122], [3, 78], [4, 311], [5, 367]])\n",
            " list([[1, 582], [2, 184], [3, 24], [4, 409], [5, 553]])\n",
            " list([[1, 605], [2, 124], [3, 28], [4, 277], [5, 70]])\n",
            " list([[1, 620], [2, 625], [3, 15], [4, 117], [5, 192]])\n",
            " list([[1, 648], [2, 170], [3, 65], [4, 171], [5, 514]])\n",
            " list([[1, 589], [2, 639], [3, 226], [4, 203], [5, 307]])\n",
            " list([[1, 568], [2, 156], [3, 96], [4, 375], [5, 190]])\n",
            " list([[1, 644], [2, 102], [3, 43], [4, 286], [5, 101]])\n",
            " list([[1, 645], [2, 565], [3, 18], [4, 224], [5, 203]])\n",
            " list([[1, 587], [2, 587], [3, 91], [4, 283], [5, 451]])\n",
            " list([[1, 586], [2, 613], [3, 52], [4, 411], [5, 230]])\n",
            " list([[1, 594], [2, 205], [3, 3], [4, 261], [5, 383]])\n",
            " list([[1, 651], [2, 567], [3, 16], [4, 126], [5, 390]])\n",
            " list([[1, 621], [2, 59], [3, 71], [4, 370], [5, 628]])\n",
            " list([[1, 631], [2, 589], [3, 82], [4, 326], [5, 442]])\n",
            " list([[1, 636], [2, 633], [3, 408], [4, 133], [5, 419]])\n",
            " list([[1, 596], [2, 626], [3, 23], [4, 148], [5, 171]])\n",
            " list([[1, 572], [2, 202], [3, 14], [4, 30], [5, 105]])\n",
            " list([[1, 607], [2, 220], [3, 67], [4, 309], [5, 318]])\n",
            " list([[1, 634], [2, 636], [3, 83], [4, 364], [5, 467]])\n",
            " list([[1, 643], [2, 646], [3, 19], [4, 116], [5, 74]])\n",
            " list([[1, 638], [2, 628], [3, 85], [4, 156], [5, 291]])\n",
            " list([[1, 610], [2, 174], [3, 41], [4, 78], [5, 100]])\n",
            " list([[1, 624], [2, 219], [3, 63], [4, 155], [5, 69]])\n",
            " list([[1, 569], [2, 572], [3, 36], [4, 110], [5, 328]])\n",
            " list([[1, 581], [2, 144], [3, 40], [4, 129], [5, 332]])\n",
            " list([[1, 595], [2, 609], [3, 81], [4, 214], [5, 591]])\n",
            " list([[1, 602], [2, 632], [3, 61], [4, 400], [5, 331]])\n",
            " list([[1, 611], [2, 182], [3, 79], [4, 419], [5, 232]])\n",
            " list([[1, 647], [2, 644], [3, 361], [4, 322], [5, 187]])\n",
            " list([[1, 592], [2, 651], [3, 170], [4, 134], [5, 199]])\n",
            " list([[1, 642], [2, 622], [3, 26], [4, 262], [5, 376]])\n",
            " list([[1, 641], [2, 658], [3, 4], [4, 377], [5, 210]])\n",
            " list([[1, 639], [2, 606], [3, 60], [4, 284], [5, 236]])\n",
            " list([[1, 590], [2, 588], [3, 58], [4, 179], [5, 269]])\n",
            " list([[1, 628], [2, 617], [3, 73], [4, 252], [5, 299]])\n",
            " list([[1, 22], [2, 82], [3, 310], [4, 368], [5, 415]])\n",
            " list([[1, 26], [2, 41], [3, 300], [4, 233], [5, 268]])\n",
            " list([[1, 13], [2, 153], [3, 185], [4, 273], [5, 136]])\n",
            " list([[1, 2], [2, 223], [3, 379], [4, 256], [5, 355]])\n",
            " list([[1, 21], [2, 125], [3, 313], [4, 386], [5, 249]])\n",
            " list([[1, 234], [2, 104], [3, 183], [4, 192], [5, 237]])\n",
            " list([[1, 14], [2, 112], [3, 294], [4, 369], [5, 222]])\n",
            " list([[1, 17], [2, 222], [3, 98], [4, 231], [5, 529]])\n",
            " list([[1, 3], [2, 98], [3, 171], [4, 75], [5, 445]])\n",
            " list([[1, 1], [2, 83], [3, 227], [4, 193], [5, 348]])\n",
            " list([[1, 6], [2, 126], [3, 414], [4, 408], [5, 426]])\n",
            " list([[1, 0], [2, 111], [3, 285], [4, 198], [5, 365]])\n",
            " list([[1, 18], [2, 110], [3, 102], [4, 294], [5, 286]])\n",
            " list([[1, 25], [2, 137], [3, 172], [4, 315], [5, 377]])\n",
            " list([[1, 4], [2, 97], [3, 299], [4, 79], [5, 347]])\n",
            " list([[1, 10], [2, 154], [3, 345], [4, 20], [5, 506]])\n",
            " list([[1, 28], [2, 201], [3, 350], [4, 97], [5, 252]])\n",
            " list([[1, 29], [2, 596], [3, 433], [4, 101], [5, 282]])\n",
            " list([[1, 5], [2, 664], [3, 445], [4, 98], [5, 668]])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DmNbSY08FBC"
      },
      "source": [
        "###Step 2: Weight-Page Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6LCyycuhsQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef1a6259-d625-4092-8cec-ae8c2dc6af09"
      },
      "source": [
        "!bash ./joint_optimization.sh"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1-th joint optimization\n",
            "get_matching_loss\n",
            "v_train\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "step 0, training accuracy: 0.110000 original loss: 6.908881 matching loss: 52.037601\n",
            "step 0, Validation accuracy: 0.095800\n",
            "step 100, training accuracy: 0.240000 original loss: 6.486099 matching loss: 28.448986\n",
            "step 100, Validation accuracy: 0.308600\n",
            "get new weight for 0.3086\n",
            "step 200, training accuracy: 0.870000 original loss: 5.215354 matching loss: 16.161585\n",
            "step 200, Validation accuracy: 0.821700\n",
            "get new weight for 0.8217\n",
            "step 300, training accuracy: 0.870000 original loss: 5.083245 matching loss: 9.107092\n",
            "step 300, Validation accuracy: 0.897200\n",
            "get new weight for 0.8972\n",
            "step 400, training accuracy: 0.910000 original loss: 4.994786 matching loss: 5.069077\n",
            "step 400, Validation accuracy: 0.922000\n",
            "get new weight for 0.922\n",
            "step 500, training accuracy: 0.970000 original loss: 4.867200 matching loss: 2.823801\n",
            "step 500, Validation accuracy: 0.929600\n",
            "get new weight for 0.9296\n",
            "step 600, training accuracy: 0.960000 original loss: 4.860703 matching loss: 1.622666\n",
            "step 600, Validation accuracy: 0.937100\n",
            "get new weight for 0.9371\n",
            "step 700, training accuracy: 0.920000 original loss: 4.888347 matching loss: 1.001098\n",
            "step 700, Validation accuracy: 0.942800\n",
            "get new weight for 0.9428\n",
            "step 800, training accuracy: 0.960000 original loss: 4.764685 matching loss: 0.682518\n",
            "step 800, Validation accuracy: 0.949300\n",
            "get new weight for 0.9493\n",
            "step 900, training accuracy: 0.950000 original loss: 4.767778 matching loss: 0.514367\n",
            "step 900, Validation accuracy: 0.949000\n",
            "step 1000, training accuracy: 0.990000 original loss: 4.686175 matching loss: 0.419092\n",
            "step 1000, Validation accuracy: 0.952500\n",
            "get new weight for 0.9525\n",
            "step 1100, training accuracy: 0.970000 original loss: 4.722359 matching loss: 0.359655\n",
            "step 1100, Validation accuracy: 0.958400\n",
            "get new weight for 0.9584\n",
            "step 1200, training accuracy: 0.950000 original loss: 4.830149 matching loss: 0.319576\n",
            "step 1200, Validation accuracy: 0.956900\n",
            "step 1300, training accuracy: 1.000000 original loss: 4.670221 matching loss: 0.290768\n",
            "step 1300, Validation accuracy: 0.961100\n",
            "get new weight for 0.9611\n",
            "step 1400, training accuracy: 0.990000 original loss: 4.762803 matching loss: 0.269443\n",
            "step 1400, Validation accuracy: 0.962100\n",
            "get new weight for 0.9621\n",
            "step 1500, training accuracy: 0.960000 original loss: 4.776367 matching loss: 0.253374\n",
            "step 1500, Validation accuracy: 0.966200\n",
            "get new weight for 0.9662\n",
            "step 1600, training accuracy: 0.970000 original loss: 4.700257 matching loss: 0.240877\n",
            "step 1600, Validation accuracy: 0.966600\n",
            "get new weight for 0.9666\n",
            "step 1700, training accuracy: 0.940000 original loss: 4.727488 matching loss: 0.231033\n",
            "step 1700, Validation accuracy: 0.967300\n",
            "get new weight for 0.9673\n",
            "step 1800, training accuracy: 0.950000 original loss: 4.787805 matching loss: 0.223080\n",
            "step 1800, Validation accuracy: 0.962900\n",
            "step 1900, training accuracy: 0.980000 original loss: 4.740228 matching loss: 0.216858\n",
            "step 1900, Validation accuracy: 0.968500\n",
            "get new weight for 0.9685\n",
            "step 1999, training accuracy: 0.940000 original loss: 4.856927 matching loss: 0.211871\n",
            "step 1999, Validation accuracy: 0.969000\n",
            "get new weight for 0.969\n",
            "mnist/mnist_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "step 0, training accuracy: 0.010000 original loss: 8.161086 matching loss: 21.351767\n",
            "step 0, Validation accuracy: 0.017719\n",
            "step 100, training accuracy: 0.020000 original loss: 8.075349 matching loss: 9.106529\n",
            "step 100, Validation accuracy: 0.036075\n",
            "get new weight for 0.03607451\n",
            "step 200, training accuracy: 0.200000 original loss: 7.500449 matching loss: 4.528912\n",
            "step 200, Validation accuracy: 0.158746\n",
            "get new weight for 0.15874602\n",
            "step 300, training accuracy: 0.280000 original loss: 7.089551 matching loss: 2.563392\n",
            "step 300, Validation accuracy: 0.324035\n",
            "get new weight for 0.32403454\n",
            "step 400, training accuracy: 0.370000 original loss: 6.733882 matching loss: 1.624653\n",
            "step 400, Validation accuracy: 0.408542\n",
            "get new weight for 0.40854156\n",
            "step 500, training accuracy: 0.540000 original loss: 6.458574 matching loss: 1.138744\n",
            "step 500, Validation accuracy: 0.446888\n",
            "get new weight for 0.4468878\n",
            "step 600, training accuracy: 0.490000 original loss: 6.417609 matching loss: 0.871431\n",
            "step 600, Validation accuracy: 0.498046\n",
            "get new weight for 0.49804634\n",
            "step 700, training accuracy: 0.590000 original loss: 6.390429 matching loss: 0.721156\n",
            "step 700, Validation accuracy: 0.522672\n",
            "get new weight for 0.5226715\n",
            "step 800, training accuracy: 0.580000 original loss: 6.309604 matching loss: 0.635933\n",
            "step 800, Validation accuracy: 0.537392\n",
            "get new weight for 0.5373921\n",
            "step 900, training accuracy: 0.550000 original loss: 6.132917 matching loss: 0.585816\n",
            "step 900, Validation accuracy: 0.557020\n",
            "get new weight for 0.55701953\n",
            "step 1000, training accuracy: 0.540000 original loss: 6.486170 matching loss: 0.556202\n",
            "step 1000, Validation accuracy: 0.566470\n",
            "get new weight for 0.5664698\n",
            "step 1100, training accuracy: 0.550000 original loss: 6.222057 matching loss: 0.538053\n",
            "step 1100, Validation accuracy: 0.577374\n",
            "get new weight for 0.5773739\n",
            "step 1200, training accuracy: 0.570000 original loss: 6.206046 matching loss: 0.525206\n",
            "step 1200, Validation accuracy: 0.584189\n",
            "get new weight for 0.584189\n",
            "step 1300, training accuracy: 0.560000 original loss: 6.041529 matching loss: 0.517247\n",
            "step 1300, Validation accuracy: 0.582826\n",
            "step 1400, training accuracy: 0.640000 original loss: 6.009034 matching loss: 0.510449\n",
            "step 1400, Validation accuracy: 0.602181\n",
            "get new weight for 0.60218084\n",
            "step 1500, training accuracy: 0.740000 original loss: 5.828840 matching loss: 0.505906\n",
            "step 1500, Validation accuracy: 0.601363\n",
            "step 1600, training accuracy: 0.720000 original loss: 5.938283 matching loss: 0.501266\n",
            "step 1600, Validation accuracy: 0.608269\n",
            "get new weight for 0.608269\n",
            "step 1700, training accuracy: 0.580000 original loss: 5.954813 matching loss: 0.498766\n",
            "step 1700, Validation accuracy: 0.614993\n",
            "get new weight for 0.6149932\n",
            "step 1800, training accuracy: 0.620000 original loss: 6.019841 matching loss: 0.495738\n",
            "step 1800, Validation accuracy: 0.626624\n",
            "get new weight for 0.6266243\n",
            "step 1900, training accuracy: 0.650000 original loss: 5.881618 matching loss: 0.493360\n",
            "step 1900, Validation accuracy: 0.623626\n",
            "step 1999, training accuracy: 0.610000 original loss: 5.884827 matching loss: 0.491362\n",
            "step 1999, Validation accuracy: 0.630895\n",
            "get new weight for 0.630895\n",
            "gsc/gsc_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "step 0, training accuracy: 0.000000 original loss: 9.295041 matching loss: 0.354466\n",
            "step 0, Validation accuracy: 0.004751\n",
            "step 100, training accuracy: 0.190000 original loss: 8.003147 matching loss: 0.253210\n",
            "step 100, Validation accuracy: 0.136975\n",
            "get new weight for 0.13697545\n",
            "step 200, training accuracy: 0.600000 original loss: 6.178272 matching loss: 0.299518\n",
            "step 200, Validation accuracy: 0.623515\n",
            "get new weight for 0.6235154\n",
            "step 300, training accuracy: 0.830000 original loss: 5.632130 matching loss: 0.302152\n",
            "step 300, Validation accuracy: 0.755424\n",
            "get new weight for 0.7554236\n",
            "step 400, training accuracy: 0.880000 original loss: 5.523042 matching loss: 0.297535\n",
            "step 400, Validation accuracy: 0.791291\n",
            "get new weight for 0.7912906\n",
            "step 500, training accuracy: 0.910000 original loss: 5.270267 matching loss: 0.294528\n",
            "step 500, Validation accuracy: 0.825653\n",
            "get new weight for 0.8256532\n",
            "step 600, training accuracy: 0.850000 original loss: 5.291739 matching loss: 0.291999\n",
            "step 600, Validation accuracy: 0.841409\n",
            "get new weight for 0.8414093\n",
            "step 700, training accuracy: 0.900000 original loss: 5.251438 matching loss: 0.290082\n",
            "step 700, Validation accuracy: 0.860966\n",
            "get new weight for 0.86096597\n",
            "step 800, training accuracy: 0.930000 original loss: 5.146362 matching loss: 0.287174\n",
            "step 800, Validation accuracy: 0.863975\n",
            "get new weight for 0.8639747\n",
            "step 900, training accuracy: 0.890000 original loss: 5.238654 matching loss: 0.285179\n",
            "step 900, Validation accuracy: 0.871338\n",
            "get new weight for 0.87133807\n",
            "step 1000, training accuracy: 0.900000 original loss: 5.146529 matching loss: 0.283371\n",
            "step 1000, Validation accuracy: 0.881235\n",
            "get new weight for 0.8812352\n",
            "step 1100, training accuracy: 0.980000 original loss: 4.993299 matching loss: 0.281770\n",
            "step 1100, Validation accuracy: 0.878860\n",
            "step 1200, training accuracy: 0.950000 original loss: 4.965158 matching loss: 0.279716\n",
            "step 1200, Validation accuracy: 0.888124\n",
            "get new weight for 0.8881235\n",
            "step 1300, training accuracy: 0.890000 original loss: 5.060615 matching loss: 0.278044\n",
            "step 1300, Validation accuracy: 0.888599\n",
            "get new weight for 0.88859856\n",
            "step 1400, training accuracy: 0.950000 original loss: 5.007388 matching loss: 0.276843\n",
            "step 1400, Validation accuracy: 0.898021\n",
            "get new weight for 0.89802057\n",
            "step 1500, training accuracy: 0.940000 original loss: 4.985385 matching loss: 0.275266\n",
            "step 1500, Validation accuracy: 0.897229\n",
            "step 1600, training accuracy: 0.980000 original loss: 4.875664 matching loss: 0.273846\n",
            "step 1600, Validation accuracy: 0.900950\n",
            "get new weight for 0.90095013\n",
            "step 1700, training accuracy: 0.950000 original loss: 4.947030 matching loss: 0.272431\n",
            "step 1700, Validation accuracy: 0.896675\n",
            "step 1800, training accuracy: 0.950000 original loss: 4.962634 matching loss: 0.271759\n",
            "step 1800, Validation accuracy: 0.901821\n",
            "get new weight for 0.9018211\n",
            "step 1900, training accuracy: 0.980000 original loss: 4.874281 matching loss: 0.270401\n",
            "step 1900, Validation accuracy: 0.907918\n",
            "get new weight for 0.9079177\n",
            "step 1999, training accuracy: 0.950000 original loss: 4.944096 matching loss: 0.269616\n",
            "step 1999, Validation accuracy: 0.910610\n",
            "get new weight for 0.91060966\n",
            "gtsrb/gtsrb_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x1d5d4000 @  0x7f7304f851e7 0x7f73028ceca1 0x7f73029389c5 0x7f730293955e 0x7f73029d2a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "step 0, training accuracy: 0.120000 original loss: 7.047543 matching loss: 0.156512\n",
            "step 0, Validation accuracy: 0.125200\n",
            "step 100, training accuracy: 0.430000 original loss: 6.048884 matching loss: 0.118914\n",
            "step 100, Validation accuracy: 0.460600\n",
            "get new weight for 0.4606\n",
            "step 200, training accuracy: 0.570000 original loss: 5.942003 matching loss: 0.113939\n",
            "step 200, Validation accuracy: 0.497600\n",
            "get new weight for 0.4976\n",
            "step 300, training accuracy: 0.530000 original loss: 5.965563 matching loss: 0.112019\n",
            "step 300, Validation accuracy: 0.507500\n",
            "get new weight for 0.5075\n",
            "step 400, training accuracy: 0.550000 original loss: 5.913944 matching loss: 0.111389\n",
            "step 400, Validation accuracy: 0.505200\n",
            "step 500, training accuracy: 0.570000 original loss: 5.819502 matching loss: 0.110646\n",
            "step 500, Validation accuracy: 0.517100\n",
            "get new weight for 0.5171\n",
            "step 600, training accuracy: 0.550000 original loss: 5.870161 matching loss: 0.110339\n",
            "step 600, Validation accuracy: 0.526400\n",
            "get new weight for 0.5264\n",
            "step 700, training accuracy: 0.570000 original loss: 5.894701 matching loss: 0.110147\n",
            "step 700, Validation accuracy: 0.528200\n",
            "get new weight for 0.5282\n",
            "step 800, training accuracy: 0.560000 original loss: 5.783906 matching loss: 0.110450\n",
            "step 800, Validation accuracy: 0.536800\n",
            "get new weight for 0.5368\n",
            "step 900, training accuracy: 0.540000 original loss: 5.889539 matching loss: 0.109865\n",
            "step 900, Validation accuracy: 0.533100\n",
            "step 1000, training accuracy: 0.490000 original loss: 5.935688 matching loss: 0.109861\n",
            "step 1000, Validation accuracy: 0.527100\n",
            "step 1100, training accuracy: 0.500000 original loss: 5.993371 matching loss: 0.109959\n",
            "step 1100, Validation accuracy: 0.543300\n",
            "get new weight for 0.5433\n",
            "step 1200, training accuracy: 0.550000 original loss: 5.968216 matching loss: 0.109941\n",
            "step 1200, Validation accuracy: 0.543700\n",
            "get new weight for 0.5437\n",
            "step 1300, training accuracy: 0.500000 original loss: 6.060719 matching loss: 0.109916\n",
            "step 1300, Validation accuracy: 0.536900\n",
            "step 1400, training accuracy: 0.560000 original loss: 5.817975 matching loss: 0.110014\n",
            "step 1400, Validation accuracy: 0.543000\n",
            "step 1500, training accuracy: 0.540000 original loss: 5.877748 matching loss: 0.110009\n",
            "step 1500, Validation accuracy: 0.537600\n",
            "step 1600, training accuracy: 0.490000 original loss: 6.056957 matching loss: 0.109999\n",
            "step 1600, Validation accuracy: 0.541300\n",
            "step 1700, training accuracy: 0.630000 original loss: 5.758235 matching loss: 0.110041\n",
            "step 1700, Validation accuracy: 0.541900\n",
            "step 1800, training accuracy: 0.600000 original loss: 5.893409 matching loss: 0.109769\n",
            "step 1800, Validation accuracy: 0.552300\n",
            "get new weight for 0.5523\n",
            "step 1900, training accuracy: 0.600000 original loss: 5.770981 matching loss: 0.109866\n",
            "step 1900, Validation accuracy: 0.543100\n",
            "step 1999, training accuracy: 0.530000 original loss: 5.887803 matching loss: 0.110236\n",
            "step 1999, Validation accuracy: 0.554700\n",
            "get new weight for 0.5547\n",
            "cifar10/cifar10_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "step 0, training accuracy: 0.060000 original loss: 8.237750 matching loss: 0.115272\n",
            "step 0, Validation accuracy: 0.105178\n",
            "step 100, training accuracy: 0.700000 original loss: 5.632239 matching loss: 0.101705\n",
            "step 100, Validation accuracy: 0.738706\n",
            "get new weight for 0.73870623\n",
            "step 200, training accuracy: 0.780000 original loss: 5.486396 matching loss: 0.099470\n",
            "step 200, Validation accuracy: 0.775315\n",
            "get new weight for 0.775315\n",
            "step 300, training accuracy: 0.810000 original loss: 5.452343 matching loss: 0.098211\n",
            "step 300, Validation accuracy: 0.784803\n",
            "get new weight for 0.78480333\n",
            "step 400, training accuracy: 0.850000 original loss: 5.303800 matching loss: 0.096741\n",
            "step 400, Validation accuracy: 0.791756\n",
            "get new weight for 0.7917563\n",
            "step 500, training accuracy: 0.840000 original loss: 5.274236 matching loss: 0.095347\n",
            "step 500, Validation accuracy: 0.802397\n",
            "get new weight for 0.8023971\n",
            "step 600, training accuracy: 0.870000 original loss: 5.181678 matching loss: 0.093859\n",
            "step 600, Validation accuracy: 0.799708\n",
            "step 700, training accuracy: 0.780000 original loss: 5.281806 matching loss: 0.093054\n",
            "step 700, Validation accuracy: 0.808198\n",
            "get new weight for 0.8081976\n",
            "step 800, training accuracy: 0.840000 original loss: 5.236650 matching loss: 0.092212\n",
            "step 800, Validation accuracy: 0.805201\n",
            "step 900, training accuracy: 0.880000 original loss: 5.124200 matching loss: 0.091250\n",
            "step 900, Validation accuracy: 0.809465\n",
            "get new weight for 0.8094653\n",
            "step 1000, training accuracy: 0.790000 original loss: 5.261324 matching loss: 0.090714\n",
            "step 1000, Validation accuracy: 0.813384\n",
            "get new weight for 0.8133835\n",
            "step 1100, training accuracy: 0.830000 original loss: 5.152031 matching loss: 0.089823\n",
            "step 1100, Validation accuracy: 0.814498\n",
            "get new weight for 0.81449753\n",
            "step 1200, training accuracy: 0.850000 original loss: 5.114557 matching loss: 0.088969\n",
            "step 1200, Validation accuracy: 0.815727\n",
            "get new weight for 0.8157268\n",
            "step 1300, training accuracy: 0.850000 original loss: 5.149874 matching loss: 0.088832\n",
            "step 1300, Validation accuracy: 0.816610\n",
            "get new weight for 0.81661034\n",
            "step 1400, training accuracy: 0.840000 original loss: 5.144041 matching loss: 0.088288\n",
            "step 1400, Validation accuracy: 0.820029\n",
            "get new weight for 0.8200292\n",
            "step 1500, training accuracy: 0.820000 original loss: 5.215718 matching loss: 0.088190\n",
            "step 1500, Validation accuracy: 0.810157\n",
            "step 1600, training accuracy: 0.850000 original loss: 5.139570 matching loss: 0.087580\n",
            "step 1600, Validation accuracy: 0.820798\n",
            "get new weight for 0.8207975\n",
            "step 1700, training accuracy: 0.830000 original loss: 5.321332 matching loss: 0.087659\n",
            "step 1700, Validation accuracy: 0.819837\n",
            "step 1800, training accuracy: 0.850000 original loss: 5.185400 matching loss: 0.087202\n",
            "step 1800, Validation accuracy: 0.820260\n",
            "step 1900, training accuracy: 0.820000 original loss: 5.144447 matching loss: 0.086816\n",
            "step 1900, Validation accuracy: 0.823218\n",
            "get new weight for 0.8232176\n",
            "step 1999, training accuracy: 0.870000 original loss: 5.069448 matching loss: 0.086391\n",
            "step 1999, Validation accuracy: 0.824293\n",
            "get new weight for 0.8242932\n",
            "svhn/svhn_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x1ccd8000 @  0x7f5a9b5ed1e7 0x7f5a98f36ca1 0x7f5a98fa09c5 0x7f5a98fa155e 0x7f5a9903aa6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "step 0, training accuracy: 0.080000 original loss: 7.595868 matching loss: 0.065026\n",
            "step 0, Validation accuracy: 0.134320\n",
            "step 100, training accuracy: 0.520000 original loss: 6.022604 matching loss: 0.059203\n",
            "step 100, Validation accuracy: 0.332100\n",
            "get new weight for 0.3320999\n",
            "step 200, training accuracy: 0.600000 original loss: 5.865339 matching loss: 0.059402\n",
            "step 200, Validation accuracy: 0.385939\n",
            "get new weight for 0.38593894\n",
            "step 300, training accuracy: 0.690000 original loss: 5.692620 matching loss: 0.063029\n",
            "step 300, Validation accuracy: 0.370398\n",
            "step 400, training accuracy: 0.690000 original loss: 5.634009 matching loss: 0.059516\n",
            "step 400, Validation accuracy: 0.381314\n",
            "step 500, training accuracy: 0.660000 original loss: 5.645631 matching loss: 0.058681\n",
            "step 500, Validation accuracy: 0.403885\n",
            "get new weight for 0.4038853\n",
            "step 600, training accuracy: 0.690000 original loss: 5.579576 matching loss: 0.058320\n",
            "step 600, Validation accuracy: 0.400185\n",
            "step 700, training accuracy: 0.630000 original loss: 5.816958 matching loss: 0.058868\n",
            "step 700, Validation accuracy: 0.401665\n",
            "step 800, training accuracy: 0.730000 original loss: 5.581694 matching loss: 0.058557\n",
            "step 800, Validation accuracy: 0.405920\n",
            "get new weight for 0.40592045\n",
            "step 900, training accuracy: 0.690000 original loss: 5.646604 matching loss: 0.058747\n",
            "step 900, Validation accuracy: 0.404070\n",
            "step 1000, training accuracy: 0.720000 original loss: 5.629297 matching loss: 0.060663\n",
            "step 1000, Validation accuracy: 0.410361\n",
            "get new weight for 0.41036078\n",
            "step 1100, training accuracy: 0.720000 original loss: 5.661514 matching loss: 0.059506\n",
            "step 1100, Validation accuracy: 0.374468\n",
            "step 1200, training accuracy: 0.770000 original loss: 5.460920 matching loss: 0.059023\n",
            "step 1200, Validation accuracy: 0.399075\n",
            "step 1300, training accuracy: 0.750000 original loss: 5.525522 matching loss: 0.059037\n",
            "step 1300, Validation accuracy: 0.398335\n",
            "step 1400, training accuracy: 0.730000 original loss: 5.556889 matching loss: 0.059073\n",
            "step 1400, Validation accuracy: 0.393525\n",
            "step 1500, training accuracy: 0.790000 original loss: 5.426867 matching loss: 0.059508\n",
            "step 1500, Validation accuracy: 0.396300\n",
            "step 1600, training accuracy: 0.750000 original loss: 5.542682 matching loss: 0.059484\n",
            "step 1600, Validation accuracy: 0.400185\n",
            "step 1700, training accuracy: 0.770000 original loss: 5.507616 matching loss: 0.060094\n",
            "step 1700, Validation accuracy: 0.386679\n",
            "step 1800, training accuracy: 0.750000 original loss: 5.476911 matching loss: 0.060185\n",
            "step 1800, Validation accuracy: 0.397040\n",
            "step 1900, training accuracy: 0.760000 original loss: 5.396222 matching loss: 0.060518\n",
            "step 1900, Validation accuracy: 0.392784\n",
            "step 1999, training accuracy: 0.670000 original loss: 5.623537 matching loss: 0.060055\n",
            "step 1999, Validation accuracy: 0.413876\n",
            "get new weight for 0.41387603\n",
            "us8k/us8k_weight.npy\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Inference accuracy: 0.313100\n",
            "Inference accuracy: 0.380918\n",
            "Inference accuracy: 0.487332\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x4fd0000 @  0x7f9cb3ab91e7 0x7f9cb1402ca1 0x7f9cb146c9c5 0x7f9cb146d55e 0x7f9cb1506a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.448500\n",
            "Inference accuracy: 0.767863\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x61bc000 @  0x7f9c26b681e7 0x7f9c244b1ca1 0x7f9c2451b9c5 0x7f9c2451c55e 0x7f9c245b5a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.413876\n",
            "2-th joint optimization\n",
            "get_matching_loss\n",
            "v_train\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "step 0, training accuracy: 0.370000 original loss: 12.231005 matching loss: 0.026476\n",
            "step 0, Validation accuracy: 0.313100\n",
            "step 100, training accuracy: 0.960000 original loss: 4.903092 matching loss: 0.026508\n",
            "step 100, Validation accuracy: 0.919800\n",
            "get new weight for 0.9198\n",
            "step 200, training accuracy: 0.940000 original loss: 4.925230 matching loss: 0.025446\n",
            "step 200, Validation accuracy: 0.941900\n",
            "get new weight for 0.9419\n",
            "step 300, training accuracy: 0.950000 original loss: 4.921066 matching loss: 0.024803\n",
            "step 300, Validation accuracy: 0.954200\n",
            "get new weight for 0.9542\n",
            "step 400, training accuracy: 0.970000 original loss: 4.800030 matching loss: 0.024370\n",
            "step 400, Validation accuracy: 0.957400\n",
            "get new weight for 0.9574\n",
            "step 500, training accuracy: 0.970000 original loss: 4.776112 matching loss: 0.023813\n",
            "step 500, Validation accuracy: 0.959900\n",
            "get new weight for 0.9599\n",
            "step 600, training accuracy: 0.990000 original loss: 4.717301 matching loss: 0.023352\n",
            "step 600, Validation accuracy: 0.963300\n",
            "get new weight for 0.9633\n",
            "step 700, training accuracy: 0.950000 original loss: 4.782045 matching loss: 0.023052\n",
            "step 700, Validation accuracy: 0.963800\n",
            "get new weight for 0.9638\n",
            "step 800, training accuracy: 0.960000 original loss: 4.784597 matching loss: 0.022629\n",
            "step 800, Validation accuracy: 0.966200\n",
            "get new weight for 0.9662\n",
            "step 900, training accuracy: 0.950000 original loss: 4.793137 matching loss: 0.022345\n",
            "step 900, Validation accuracy: 0.967700\n",
            "get new weight for 0.9677\n",
            "step 1000, training accuracy: 0.970000 original loss: 4.777646 matching loss: 0.022087\n",
            "step 1000, Validation accuracy: 0.966600\n",
            "step 1100, training accuracy: 0.960000 original loss: 4.821267 matching loss: 0.021730\n",
            "step 1100, Validation accuracy: 0.967900\n",
            "get new weight for 0.9679\n",
            "step 1200, training accuracy: 0.940000 original loss: 4.786872 matching loss: 0.021579\n",
            "step 1200, Validation accuracy: 0.970800\n",
            "get new weight for 0.9708\n",
            "step 1300, training accuracy: 0.950000 original loss: 4.769111 matching loss: 0.021298\n",
            "step 1300, Validation accuracy: 0.972300\n",
            "get new weight for 0.9723\n",
            "step 1400, training accuracy: 0.990000 original loss: 4.688789 matching loss: 0.021058\n",
            "step 1400, Validation accuracy: 0.971600\n",
            "step 1500, training accuracy: 0.980000 original loss: 4.723082 matching loss: 0.020926\n",
            "step 1500, Validation accuracy: 0.973500\n",
            "get new weight for 0.9735\n",
            "step 1600, training accuracy: 0.950000 original loss: 4.734801 matching loss: 0.020716\n",
            "step 1600, Validation accuracy: 0.974500\n",
            "get new weight for 0.9745\n",
            "step 1700, training accuracy: 0.980000 original loss: 4.676991 matching loss: 0.020542\n",
            "step 1700, Validation accuracy: 0.973500\n",
            "step 1800, training accuracy: 0.980000 original loss: 4.696021 matching loss: 0.020381\n",
            "step 1800, Validation accuracy: 0.975300\n",
            "get new weight for 0.9753\n",
            "step 1900, training accuracy: 0.960000 original loss: 4.750139 matching loss: 0.020222\n",
            "step 1900, Validation accuracy: 0.975700\n",
            "get new weight for 0.9757\n",
            "step 1999, training accuracy: 0.980000 original loss: 4.693509 matching loss: 0.020087\n",
            "step 1999, Validation accuracy: 0.974700\n",
            "mnist/mnist_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "step 0, training accuracy: 0.410000 original loss: 6.972296 matching loss: 0.034328\n",
            "step 0, Validation accuracy: 0.369741\n",
            "step 100, training accuracy: 0.630000 original loss: 6.011023 matching loss: 0.034925\n",
            "step 100, Validation accuracy: 0.583462\n",
            "get new weight for 0.58346206\n",
            "step 200, training accuracy: 0.630000 original loss: 6.082369 matching loss: 0.036176\n",
            "step 200, Validation accuracy: 0.611449\n",
            "get new weight for 0.61144936\n",
            "step 300, training accuracy: 0.630000 original loss: 5.999905 matching loss: 0.036509\n",
            "step 300, Validation accuracy: 0.614539\n",
            "get new weight for 0.61453885\n",
            "step 400, training accuracy: 0.700000 original loss: 5.784633 matching loss: 0.037037\n",
            "step 400, Validation accuracy: 0.625170\n",
            "get new weight for 0.62517035\n",
            "step 500, training accuracy: 0.660000 original loss: 5.886678 matching loss: 0.037679\n",
            "step 500, Validation accuracy: 0.631713\n",
            "get new weight for 0.63171285\n",
            "step 600, training accuracy: 0.660000 original loss: 5.972894 matching loss: 0.037992\n",
            "step 600, Validation accuracy: 0.639709\n",
            "get new weight for 0.63970923\n",
            "step 700, training accuracy: 0.590000 original loss: 5.980331 matching loss: 0.038815\n",
            "step 700, Validation accuracy: 0.648342\n",
            "get new weight for 0.64834166\n",
            "step 800, training accuracy: 0.630000 original loss: 5.910079 matching loss: 0.039035\n",
            "step 800, Validation accuracy: 0.635529\n",
            "step 900, training accuracy: 0.650000 original loss: 5.900404 matching loss: 0.039622\n",
            "step 900, Validation accuracy: 0.651340\n",
            "get new weight for 0.6513403\n",
            "step 1000, training accuracy: 0.730000 original loss: 5.693547 matching loss: 0.039864\n",
            "step 1000, Validation accuracy: 0.660881\n",
            "get new weight for 0.6608814\n",
            "step 1100, training accuracy: 0.720000 original loss: 5.808044 matching loss: 0.039987\n",
            "step 1100, Validation accuracy: 0.658973\n",
            "step 1200, training accuracy: 0.700000 original loss: 5.691184 matching loss: 0.041186\n",
            "step 1200, Validation accuracy: 0.668514\n",
            "get new weight for 0.6685143\n",
            "step 1300, training accuracy: 0.700000 original loss: 5.807946 matching loss: 0.040795\n",
            "step 1300, Validation accuracy: 0.667787\n",
            "step 1400, training accuracy: 0.730000 original loss: 5.685157 matching loss: 0.042015\n",
            "step 1400, Validation accuracy: 0.664334\n",
            "step 1500, training accuracy: 0.740000 original loss: 5.624410 matching loss: 0.042272\n",
            "step 1500, Validation accuracy: 0.671786\n",
            "get new weight for 0.67178553\n",
            "step 1600, training accuracy: 0.730000 original loss: 5.724930 matching loss: 0.042740\n",
            "step 1600, Validation accuracy: 0.677965\n",
            "get new weight for 0.67796457\n",
            "step 1700, training accuracy: 0.700000 original loss: 5.772729 matching loss: 0.042995\n",
            "step 1700, Validation accuracy: 0.680872\n",
            "get new weight for 0.6808723\n",
            "step 1800, training accuracy: 0.730000 original loss: 5.644377 matching loss: 0.043464\n",
            "step 1800, Validation accuracy: 0.677238\n",
            "step 1900, training accuracy: 0.710000 original loss: 5.750255 matching loss: 0.044016\n",
            "step 1900, Validation accuracy: 0.686143\n",
            "get new weight for 0.6861427\n",
            "step 1999, training accuracy: 0.830000 original loss: 5.472746 matching loss: 0.044515\n",
            "step 1999, Validation accuracy: 0.682054\n",
            "gsc/gsc_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "step 0, training accuracy: 0.470000 original loss: 6.792951 matching loss: 0.034210\n",
            "step 0, Validation accuracy: 0.476247\n",
            "step 100, training accuracy: 0.950000 original loss: 5.103470 matching loss: 0.035257\n",
            "step 100, Validation accuracy: 0.879652\n",
            "get new weight for 0.8796516\n",
            "step 200, training accuracy: 0.920000 original loss: 5.098168 matching loss: 0.034764\n",
            "step 200, Validation accuracy: 0.893191\n",
            "get new weight for 0.8931908\n",
            "step 300, training accuracy: 0.950000 original loss: 5.028908 matching loss: 0.033990\n",
            "step 300, Validation accuracy: 0.899762\n",
            "get new weight for 0.89976245\n",
            "step 400, training accuracy: 0.970000 original loss: 4.924682 matching loss: 0.033847\n",
            "step 400, Validation accuracy: 0.901267\n",
            "get new weight for 0.9012668\n",
            "step 500, training accuracy: 0.950000 original loss: 4.974888 matching loss: 0.033763\n",
            "step 500, Validation accuracy: 0.908709\n",
            "get new weight for 0.9087094\n",
            "step 600, training accuracy: 0.960000 original loss: 4.993340 matching loss: 0.033520\n",
            "step 600, Validation accuracy: 0.909343\n",
            "get new weight for 0.9093428\n",
            "step 700, training accuracy: 0.940000 original loss: 5.081041 matching loss: 0.033616\n",
            "step 700, Validation accuracy: 0.910451\n",
            "get new weight for 0.9104513\n",
            "step 800, training accuracy: 0.960000 original loss: 4.898795 matching loss: 0.033871\n",
            "step 800, Validation accuracy: 0.912352\n",
            "get new weight for 0.91235155\n",
            "step 900, training accuracy: 0.990000 original loss: 4.868087 matching loss: 0.033527\n",
            "step 900, Validation accuracy: 0.915439\n",
            "get new weight for 0.9154394\n",
            "step 1000, training accuracy: 0.960000 original loss: 4.904251 matching loss: 0.033702\n",
            "step 1000, Validation accuracy: 0.913935\n",
            "step 1100, training accuracy: 0.980000 original loss: 4.958777 matching loss: 0.033718\n",
            "step 1100, Validation accuracy: 0.918765\n",
            "get new weight for 0.9187648\n",
            "step 1200, training accuracy: 0.980000 original loss: 4.899812 matching loss: 0.033869\n",
            "step 1200, Validation accuracy: 0.912114\n",
            "step 1300, training accuracy: 0.970000 original loss: 4.878495 matching loss: 0.034120\n",
            "step 1300, Validation accuracy: 0.921378\n",
            "get new weight for 0.92137766\n",
            "step 1400, training accuracy: 0.970000 original loss: 4.823214 matching loss: 0.034247\n",
            "step 1400, Validation accuracy: 0.915835\n",
            "step 1500, training accuracy: 0.980000 original loss: 4.848055 matching loss: 0.034113\n",
            "step 1500, Validation accuracy: 0.919319\n",
            "step 1600, training accuracy: 0.960000 original loss: 4.950043 matching loss: 0.034215\n",
            "step 1600, Validation accuracy: 0.921219\n",
            "step 1700, training accuracy: 0.980000 original loss: 4.812748 matching loss: 0.034446\n",
            "step 1700, Validation accuracy: 0.922407\n",
            "get new weight for 0.922407\n",
            "step 1800, training accuracy: 0.990000 original loss: 4.801136 matching loss: 0.034490\n",
            "step 1800, Validation accuracy: 0.923832\n",
            "get new weight for 0.9238321\n",
            "step 1900, training accuracy: 0.970000 original loss: 4.884699 matching loss: 0.034406\n",
            "step 1900, Validation accuracy: 0.925336\n",
            "get new weight for 0.9253365\n",
            "step 1999, training accuracy: 0.970000 original loss: 4.806536 matching loss: 0.034390\n",
            "step 1999, Validation accuracy: 0.928108\n",
            "get new weight for 0.9281077\n",
            "gtsrb/gtsrb_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x1c136000 @  0x7f5ce18fa1e7 0x7f5cdf243ca1 0x7f5cdf2ad9c5 0x7f5cdf2ae55e 0x7f5cdf347a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "step 0, training accuracy: 0.400000 original loss: 6.350189 matching loss: 0.021293\n",
            "step 0, Validation accuracy: 0.417800\n",
            "step 100, training accuracy: 0.550000 original loss: 5.884005 matching loss: 0.017263\n",
            "step 100, Validation accuracy: 0.517300\n",
            "get new weight for 0.5173\n",
            "step 200, training accuracy: 0.560000 original loss: 5.900239 matching loss: 0.017058\n",
            "step 200, Validation accuracy: 0.533200\n",
            "get new weight for 0.5332\n",
            "step 300, training accuracy: 0.490000 original loss: 6.006384 matching loss: 0.017006\n",
            "step 300, Validation accuracy: 0.540200\n",
            "get new weight for 0.5402\n",
            "step 400, training accuracy: 0.530000 original loss: 5.927666 matching loss: 0.017581\n",
            "step 400, Validation accuracy: 0.539400\n",
            "step 500, training accuracy: 0.540000 original loss: 5.988417 matching loss: 0.017698\n",
            "step 500, Validation accuracy: 0.538000\n",
            "step 600, training accuracy: 0.470000 original loss: 5.990393 matching loss: 0.017943\n",
            "step 600, Validation accuracy: 0.544200\n",
            "get new weight for 0.5442\n",
            "step 700, training accuracy: 0.530000 original loss: 5.971534 matching loss: 0.018344\n",
            "step 700, Validation accuracy: 0.542000\n",
            "step 800, training accuracy: 0.650000 original loss: 5.874598 matching loss: 0.018445\n",
            "step 800, Validation accuracy: 0.542000\n",
            "step 900, training accuracy: 0.560000 original loss: 5.941533 matching loss: 0.018926\n",
            "step 900, Validation accuracy: 0.547700\n",
            "get new weight for 0.5477\n",
            "step 1000, training accuracy: 0.600000 original loss: 5.749124 matching loss: 0.018996\n",
            "step 1000, Validation accuracy: 0.549200\n",
            "get new weight for 0.5492\n",
            "step 1100, training accuracy: 0.620000 original loss: 5.806387 matching loss: 0.019650\n",
            "step 1100, Validation accuracy: 0.535600\n",
            "step 1200, training accuracy: 0.600000 original loss: 5.761619 matching loss: 0.019840\n",
            "step 1200, Validation accuracy: 0.548500\n",
            "step 1300, training accuracy: 0.540000 original loss: 5.963407 matching loss: 0.020167\n",
            "step 1300, Validation accuracy: 0.553100\n",
            "get new weight for 0.5531\n",
            "step 1400, training accuracy: 0.660000 original loss: 5.651550 matching loss: 0.020296\n",
            "step 1400, Validation accuracy: 0.549600\n",
            "step 1500, training accuracy: 0.630000 original loss: 5.744611 matching loss: 0.020604\n",
            "step 1500, Validation accuracy: 0.560500\n",
            "get new weight for 0.5605\n",
            "step 1600, training accuracy: 0.600000 original loss: 5.808836 matching loss: 0.020753\n",
            "step 1600, Validation accuracy: 0.557700\n",
            "step 1700, training accuracy: 0.570000 original loss: 5.934257 matching loss: 0.021079\n",
            "step 1700, Validation accuracy: 0.558300\n",
            "step 1800, training accuracy: 0.540000 original loss: 5.912839 matching loss: 0.021342\n",
            "step 1800, Validation accuracy: 0.556800\n",
            "step 1900, training accuracy: 0.680000 original loss: 5.752319 matching loss: 0.021511\n",
            "step 1900, Validation accuracy: 0.553000\n",
            "step 1999, training accuracy: 0.550000 original loss: 5.881869 matching loss: 0.021886\n",
            "step 1999, Validation accuracy: 0.553800\n",
            "cifar10/cifar10_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "step 0, training accuracy: 0.760000 original loss: 5.733362 matching loss: 0.026730\n",
            "step 0, Validation accuracy: 0.692916\n",
            "step 100, training accuracy: 0.800000 original loss: 5.351636 matching loss: 0.023660\n",
            "step 100, Validation accuracy: 0.807967\n",
            "get new weight for 0.8079671\n",
            "step 200, training accuracy: 0.870000 original loss: 5.217687 matching loss: 0.022681\n",
            "step 200, Validation accuracy: 0.813345\n",
            "get new weight for 0.81334513\n",
            "step 300, training accuracy: 0.790000 original loss: 5.272611 matching loss: 0.022431\n",
            "step 300, Validation accuracy: 0.819760\n",
            "get new weight for 0.8197603\n",
            "step 400, training accuracy: 0.880000 original loss: 5.192059 matching loss: 0.021576\n",
            "step 400, Validation accuracy: 0.820144\n",
            "get new weight for 0.8201444\n",
            "step 500, training accuracy: 0.840000 original loss: 5.187137 matching loss: 0.021248\n",
            "step 500, Validation accuracy: 0.821066\n",
            "get new weight for 0.8210664\n",
            "step 600, training accuracy: 0.830000 original loss: 5.309359 matching loss: 0.020774\n",
            "step 600, Validation accuracy: 0.826022\n",
            "get new weight for 0.8260218\n",
            "step 700, training accuracy: 0.850000 original loss: 5.263209 matching loss: 0.020639\n",
            "step 700, Validation accuracy: 0.828288\n",
            "get new weight for 0.82828826\n",
            "step 800, training accuracy: 0.870000 original loss: 5.162390 matching loss: 0.020223\n",
            "step 800, Validation accuracy: 0.823371\n",
            "step 900, training accuracy: 0.890000 original loss: 5.026263 matching loss: 0.020272\n",
            "step 900, Validation accuracy: 0.823755\n",
            "step 1000, training accuracy: 0.830000 original loss: 5.180652 matching loss: 0.020065\n",
            "step 1000, Validation accuracy: 0.824793\n",
            "step 1100, training accuracy: 0.870000 original loss: 5.087900 matching loss: 0.020067\n",
            "step 1100, Validation accuracy: 0.822641\n",
            "step 1200, training accuracy: 0.810000 original loss: 5.196563 matching loss: 0.020232\n",
            "step 1200, Validation accuracy: 0.826944\n",
            "step 1300, training accuracy: 0.840000 original loss: 5.168793 matching loss: 0.020085\n",
            "step 1300, Validation accuracy: 0.827981\n",
            "step 1400, training accuracy: 0.890000 original loss: 5.062056 matching loss: 0.019843\n",
            "step 1400, Validation accuracy: 0.828634\n",
            "get new weight for 0.82863396\n",
            "step 1500, training accuracy: 0.860000 original loss: 5.101872 matching loss: 0.020032\n",
            "step 1500, Validation accuracy: 0.827097\n",
            "step 1600, training accuracy: 0.900000 original loss: 5.033295 matching loss: 0.020090\n",
            "step 1600, Validation accuracy: 0.832667\n",
            "get new weight for 0.83266747\n",
            "step 1700, training accuracy: 0.850000 original loss: 5.166723 matching loss: 0.020034\n",
            "step 1700, Validation accuracy: 0.828480\n",
            "step 1800, training accuracy: 0.820000 original loss: 5.123038 matching loss: 0.020170\n",
            "step 1800, Validation accuracy: 0.832475\n",
            "step 1900, training accuracy: 0.850000 original loss: 5.089088 matching loss: 0.020232\n",
            "step 1900, Validation accuracy: 0.828557\n",
            "step 1999, training accuracy: 0.790000 original loss: 5.300590 matching loss: 0.020266\n",
            "step 1999, Validation accuracy: 0.833705\n",
            "get new weight for 0.83370465\n",
            "svhn/svhn_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x1ce54000 @  0x7f8b955f81e7 0x7f8b92f41ca1 0x7f8b92fab9c5 0x7f8b92fac55e 0x7f8b93045a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "step 0, training accuracy: 0.620000 original loss: 5.918693 matching loss: 0.027052\n",
            "step 0, Validation accuracy: 0.354672\n",
            "step 100, training accuracy: 0.750000 original loss: 5.416939 matching loss: 0.021502\n",
            "step 100, Validation accuracy: 0.396300\n",
            "get new weight for 0.39629972\n",
            "step 200, training accuracy: 0.750000 original loss: 5.500850 matching loss: 0.021323\n",
            "step 200, Validation accuracy: 0.406105\n",
            "get new weight for 0.40610546\n",
            "step 300, training accuracy: 0.720000 original loss: 5.562608 matching loss: 0.020891\n",
            "step 300, Validation accuracy: 0.403515\n",
            "step 400, training accuracy: 0.800000 original loss: 5.373162 matching loss: 0.021230\n",
            "step 400, Validation accuracy: 0.397965\n",
            "step 500, training accuracy: 0.780000 original loss: 5.441210 matching loss: 0.021799\n",
            "step 500, Validation accuracy: 0.403330\n",
            "step 600, training accuracy: 0.670000 original loss: 5.711384 matching loss: 0.021912\n",
            "step 600, Validation accuracy: 0.389269\n",
            "step 700, training accuracy: 0.730000 original loss: 5.487163 matching loss: 0.023115\n",
            "step 700, Validation accuracy: 0.388344\n",
            "step 800, training accuracy: 0.820000 original loss: 5.294474 matching loss: 0.022402\n",
            "step 800, Validation accuracy: 0.402035\n",
            "step 900, training accuracy: 0.800000 original loss: 5.372737 matching loss: 0.022598\n",
            "step 900, Validation accuracy: 0.415541\n",
            "get new weight for 0.41554117\n",
            "step 1000, training accuracy: 0.810000 original loss: 5.386468 matching loss: 0.023259\n",
            "step 1000, Validation accuracy: 0.405735\n",
            "step 1100, training accuracy: 0.700000 original loss: 5.511552 matching loss: 0.023610\n",
            "step 1100, Validation accuracy: 0.405920\n",
            "step 1200, training accuracy: 0.730000 original loss: 5.521720 matching loss: 0.024124\n",
            "step 1200, Validation accuracy: 0.402405\n",
            "step 1300, training accuracy: 0.740000 original loss: 5.506181 matching loss: 0.024194\n",
            "step 1300, Validation accuracy: 0.395375\n",
            "step 1400, training accuracy: 0.780000 original loss: 5.448153 matching loss: 0.024039\n",
            "step 1400, Validation accuracy: 0.414246\n",
            "step 1500, training accuracy: 0.760000 original loss: 5.417643 matching loss: 0.024389\n",
            "step 1500, Validation accuracy: 0.407771\n",
            "step 1600, training accuracy: 0.750000 original loss: 5.348936 matching loss: 0.024901\n",
            "step 1600, Validation accuracy: 0.408696\n",
            "step 1700, training accuracy: 0.780000 original loss: 5.380990 matching loss: 0.025118\n",
            "step 1700, Validation accuracy: 0.412211\n",
            "step 1800, training accuracy: 0.780000 original loss: 5.537070 matching loss: 0.025623\n",
            "step 1800, Validation accuracy: 0.398890\n",
            "step 1900, training accuracy: 0.840000 original loss: 5.257846 matching loss: 0.026185\n",
            "step 1900, Validation accuracy: 0.399260\n",
            "step 1999, training accuracy: 0.720000 original loss: 5.524863 matching loss: 0.026470\n",
            "step 1999, Validation accuracy: 0.409251\n",
            "us8k/us8k_weight.npy\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Inference accuracy: 0.726700\n",
            "Inference accuracy: 0.556020\n",
            "Inference accuracy: 0.832937\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x4c08000 @  0x7fc9f36511e7 0x7fc9f0f9aca1 0x7fc9f10049c5 0x7fc9f100555e 0x7fc9f109ea6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.496800\n",
            "Inference accuracy: 0.817532\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x6130000 @  0x7f71ed0651e7 0x7f71ea9aeca1 0x7f71eaa189c5 0x7f71eaa1955e 0x7f71eaab2a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.415541\n",
            "3-th joint optimization\n",
            "get_matching_loss\n",
            "v_train\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "step 0, training accuracy: 0.740000 original loss: 6.701972 matching loss: 0.008789\n",
            "step 0, Validation accuracy: 0.726700\n",
            "step 100, training accuracy: 0.930000 original loss: 4.841402 matching loss: 0.008483\n",
            "step 100, Validation accuracy: 0.966200\n",
            "get new weight for 0.9662\n",
            "step 200, training accuracy: 0.980000 original loss: 4.746361 matching loss: 0.008364\n",
            "step 200, Validation accuracy: 0.968300\n",
            "get new weight for 0.9683\n",
            "step 300, training accuracy: 0.970000 original loss: 4.731871 matching loss: 0.008095\n",
            "step 300, Validation accuracy: 0.970100\n",
            "get new weight for 0.9701\n",
            "step 400, training accuracy: 0.950000 original loss: 4.823202 matching loss: 0.007989\n",
            "step 400, Validation accuracy: 0.971900\n",
            "get new weight for 0.9719\n",
            "step 500, training accuracy: 0.980000 original loss: 4.788742 matching loss: 0.007889\n",
            "step 500, Validation accuracy: 0.971500\n",
            "step 600, training accuracy: 0.970000 original loss: 4.775992 matching loss: 0.007753\n",
            "step 600, Validation accuracy: 0.971700\n",
            "step 700, training accuracy: 1.000000 original loss: 4.658452 matching loss: 0.007653\n",
            "step 700, Validation accuracy: 0.973500\n",
            "get new weight for 0.9735\n",
            "step 800, training accuracy: 0.990000 original loss: 4.675989 matching loss: 0.007661\n",
            "step 800, Validation accuracy: 0.973500\n",
            "step 900, training accuracy: 0.970000 original loss: 4.684661 matching loss: 0.007560\n",
            "step 900, Validation accuracy: 0.975100\n",
            "get new weight for 0.9751\n",
            "step 1000, training accuracy: 0.980000 original loss: 4.750547 matching loss: 0.007639\n",
            "step 1000, Validation accuracy: 0.976300\n",
            "get new weight for 0.9763\n",
            "step 1100, training accuracy: 0.980000 original loss: 4.703558 matching loss: 0.007588\n",
            "step 1100, Validation accuracy: 0.974100\n",
            "step 1200, training accuracy: 0.990000 original loss: 4.662742 matching loss: 0.007553\n",
            "step 1200, Validation accuracy: 0.975500\n",
            "step 1300, training accuracy: 0.950000 original loss: 4.722674 matching loss: 0.007530\n",
            "step 1300, Validation accuracy: 0.975700\n",
            "step 1400, training accuracy: 0.970000 original loss: 4.740812 matching loss: 0.007569\n",
            "step 1400, Validation accuracy: 0.975800\n",
            "step 1500, training accuracy: 0.970000 original loss: 4.704103 matching loss: 0.007572\n",
            "step 1500, Validation accuracy: 0.976300\n",
            "step 1600, training accuracy: 0.990000 original loss: 4.670848 matching loss: 0.007625\n",
            "step 1600, Validation accuracy: 0.976400\n",
            "get new weight for 0.9764\n",
            "step 1700, training accuracy: 0.980000 original loss: 4.699455 matching loss: 0.007612\n",
            "step 1700, Validation accuracy: 0.977500\n",
            "get new weight for 0.9775\n",
            "step 1800, training accuracy: 0.970000 original loss: 4.678667 matching loss: 0.007650\n",
            "step 1800, Validation accuracy: 0.978200\n",
            "get new weight for 0.9782\n",
            "step 1900, training accuracy: 0.970000 original loss: 4.697689 matching loss: 0.007655\n",
            "step 1900, Validation accuracy: 0.977700\n",
            "step 1999, training accuracy: 0.990000 original loss: 4.664157 matching loss: 0.007725\n",
            "step 1999, Validation accuracy: 0.976900\n",
            "mnist/mnist_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "step 0, training accuracy: 0.610000 original loss: 6.189145 matching loss: 0.015434\n",
            "step 0, Validation accuracy: 0.559291\n",
            "step 100, training accuracy: 0.620000 original loss: 5.942771 matching loss: 0.017641\n",
            "step 100, Validation accuracy: 0.659246\n",
            "get new weight for 0.6592458\n",
            "step 200, training accuracy: 0.710000 original loss: 5.821349 matching loss: 0.018786\n",
            "step 200, Validation accuracy: 0.659973\n",
            "get new weight for 0.6599727\n",
            "step 300, training accuracy: 0.640000 original loss: 5.858331 matching loss: 0.019632\n",
            "step 300, Validation accuracy: 0.673785\n",
            "get new weight for 0.6737846\n",
            "step 400, training accuracy: 0.790000 original loss: 5.687767 matching loss: 0.020486\n",
            "step 400, Validation accuracy: 0.681781\n",
            "get new weight for 0.681781\n",
            "step 500, training accuracy: 0.790000 original loss: 5.621464 matching loss: 0.021088\n",
            "step 500, Validation accuracy: 0.677147\n",
            "step 600, training accuracy: 0.690000 original loss: 5.842880 matching loss: 0.021605\n",
            "step 600, Validation accuracy: 0.674239\n",
            "step 700, training accuracy: 0.730000 original loss: 5.756496 matching loss: 0.021979\n",
            "step 700, Validation accuracy: 0.684053\n",
            "get new weight for 0.6840527\n",
            "step 800, training accuracy: 0.750000 original loss: 5.802913 matching loss: 0.022581\n",
            "step 800, Validation accuracy: 0.682962\n",
            "step 900, training accuracy: 0.720000 original loss: 5.614585 matching loss: 0.022830\n",
            "step 900, Validation accuracy: 0.686415\n",
            "get new weight for 0.68641526\n",
            "step 1000, training accuracy: 0.670000 original loss: 5.677313 matching loss: 0.023454\n",
            "step 1000, Validation accuracy: 0.686688\n",
            "get new weight for 0.6866879\n",
            "step 1100, training accuracy: 0.660000 original loss: 5.731731 matching loss: 0.023941\n",
            "step 1100, Validation accuracy: 0.691595\n",
            "get new weight for 0.6915947\n",
            "step 1200, training accuracy: 0.740000 original loss: 5.665429 matching loss: 0.024130\n",
            "step 1200, Validation accuracy: 0.695775\n",
            "get new weight for 0.6957747\n",
            "step 1300, training accuracy: 0.790000 original loss: 5.509051 matching loss: 0.024557\n",
            "step 1300, Validation accuracy: 0.695320\n",
            "step 1400, training accuracy: 0.730000 original loss: 5.588750 matching loss: 0.025315\n",
            "step 1400, Validation accuracy: 0.694412\n",
            "step 1500, training accuracy: 0.780000 original loss: 5.585684 matching loss: 0.025661\n",
            "step 1500, Validation accuracy: 0.694502\n",
            "step 1600, training accuracy: 0.740000 original loss: 5.681281 matching loss: 0.026496\n",
            "step 1600, Validation accuracy: 0.701318\n",
            "get new weight for 0.7013176\n",
            "step 1700, training accuracy: 0.790000 original loss: 5.623219 matching loss: 0.026988\n",
            "step 1700, Validation accuracy: 0.704589\n",
            "get new weight for 0.70458883\n",
            "step 1800, training accuracy: 0.770000 original loss: 5.536662 matching loss: 0.026832\n",
            "step 1800, Validation accuracy: 0.701499\n",
            "step 1900, training accuracy: 0.790000 original loss: 5.555948 matching loss: 0.027675\n",
            "step 1900, Validation accuracy: 0.700863\n",
            "step 1999, training accuracy: 0.720000 original loss: 5.684891 matching loss: 0.028277\n",
            "step 1999, Validation accuracy: 0.703408\n",
            "gsc/gsc_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "step 0, training accuracy: 0.770000 original loss: 5.897199 matching loss: 0.022426\n",
            "step 0, Validation accuracy: 0.782740\n",
            "step 100, training accuracy: 0.960000 original loss: 5.022757 matching loss: 0.020265\n",
            "step 100, Validation accuracy: 0.912114\n",
            "get new weight for 0.912114\n",
            "step 200, training accuracy: 0.950000 original loss: 4.981936 matching loss: 0.020135\n",
            "step 200, Validation accuracy: 0.917023\n",
            "get new weight for 0.91702294\n",
            "step 300, training accuracy: 0.990000 original loss: 4.849445 matching loss: 0.019537\n",
            "step 300, Validation accuracy: 0.917973\n",
            "get new weight for 0.9179731\n",
            "step 400, training accuracy: 0.980000 original loss: 4.840082 matching loss: 0.019708\n",
            "step 400, Validation accuracy: 0.920190\n",
            "get new weight for 0.92019004\n",
            "step 500, training accuracy: 0.980000 original loss: 4.848367 matching loss: 0.019542\n",
            "step 500, Validation accuracy: 0.927791\n",
            "get new weight for 0.927791\n",
            "step 600, training accuracy: 0.980000 original loss: 4.838974 matching loss: 0.019646\n",
            "step 600, Validation accuracy: 0.926524\n",
            "step 700, training accuracy: 0.970000 original loss: 5.014236 matching loss: 0.019740\n",
            "step 700, Validation accuracy: 0.927078\n",
            "step 800, training accuracy: 0.980000 original loss: 4.806211 matching loss: 0.019719\n",
            "step 800, Validation accuracy: 0.925416\n",
            "step 900, training accuracy: 0.990000 original loss: 4.756180 matching loss: 0.019624\n",
            "step 900, Validation accuracy: 0.926682\n",
            "step 1000, training accuracy: 0.990000 original loss: 4.784581 matching loss: 0.019807\n",
            "step 1000, Validation accuracy: 0.926524\n",
            "step 1100, training accuracy: 0.950000 original loss: 4.900768 matching loss: 0.019494\n",
            "step 1100, Validation accuracy: 0.925416\n",
            "step 1200, training accuracy: 1.000000 original loss: 4.749502 matching loss: 0.019642\n",
            "step 1200, Validation accuracy: 0.931433\n",
            "get new weight for 0.9314331\n",
            "step 1300, training accuracy: 0.990000 original loss: 4.781426 matching loss: 0.019813\n",
            "step 1300, Validation accuracy: 0.931433\n",
            "step 1400, training accuracy: 1.000000 original loss: 4.743563 matching loss: 0.019925\n",
            "step 1400, Validation accuracy: 0.935313\n",
            "get new weight for 0.93531275\n",
            "step 1500, training accuracy: 0.990000 original loss: 4.756928 matching loss: 0.020061\n",
            "step 1500, Validation accuracy: 0.927633\n",
            "step 1600, training accuracy: 0.990000 original loss: 4.783533 matching loss: 0.020194\n",
            "step 1600, Validation accuracy: 0.930879\n",
            "step 1700, training accuracy: 0.970000 original loss: 4.808971 matching loss: 0.020372\n",
            "step 1700, Validation accuracy: 0.933096\n",
            "step 1800, training accuracy: 0.990000 original loss: 4.728330 matching loss: 0.020444\n",
            "step 1800, Validation accuracy: 0.932067\n",
            "step 1900, training accuracy: 0.990000 original loss: 4.772380 matching loss: 0.020833\n",
            "step 1900, Validation accuracy: 0.930325\n",
            "step 1999, training accuracy: 0.960000 original loss: 4.851553 matching loss: 0.020757\n",
            "step 1999, Validation accuracy: 0.932542\n",
            "gtsrb/gtsrb_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x1c900000 @  0x7f3146f1e1e7 0x7f3144867ca1 0x7f31448d19c5 0x7f31448d255e 0x7f314496ba6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "step 0, training accuracy: 0.470000 original loss: 6.188278 matching loss: 0.013139\n",
            "step 0, Validation accuracy: 0.466100\n",
            "step 100, training accuracy: 0.510000 original loss: 5.909834 matching loss: 0.011246\n",
            "step 100, Validation accuracy: 0.539900\n",
            "get new weight for 0.5399\n",
            "step 200, training accuracy: 0.550000 original loss: 5.870311 matching loss: 0.011427\n",
            "step 200, Validation accuracy: 0.541600\n",
            "get new weight for 0.5416\n",
            "step 300, training accuracy: 0.530000 original loss: 5.911628 matching loss: 0.011725\n",
            "step 300, Validation accuracy: 0.543100\n",
            "get new weight for 0.5431\n",
            "step 400, training accuracy: 0.500000 original loss: 5.886581 matching loss: 0.012064\n",
            "step 400, Validation accuracy: 0.549900\n",
            "get new weight for 0.5499\n",
            "step 500, training accuracy: 0.570000 original loss: 5.807268 matching loss: 0.012420\n",
            "step 500, Validation accuracy: 0.548600\n",
            "step 600, training accuracy: 0.620000 original loss: 5.718005 matching loss: 0.012789\n",
            "step 600, Validation accuracy: 0.549000\n",
            "step 700, training accuracy: 0.560000 original loss: 5.876700 matching loss: 0.013128\n",
            "step 700, Validation accuracy: 0.551100\n",
            "get new weight for 0.5511\n",
            "step 800, training accuracy: 0.570000 original loss: 5.783691 matching loss: 0.013304\n",
            "step 800, Validation accuracy: 0.549100\n",
            "step 900, training accuracy: 0.570000 original loss: 5.754907 matching loss: 0.013472\n",
            "step 900, Validation accuracy: 0.549500\n",
            "step 1000, training accuracy: 0.580000 original loss: 5.753616 matching loss: 0.013842\n",
            "step 1000, Validation accuracy: 0.551500\n",
            "get new weight for 0.5515\n",
            "step 1100, training accuracy: 0.610000 original loss: 5.806170 matching loss: 0.014133\n",
            "step 1100, Validation accuracy: 0.559100\n",
            "get new weight for 0.5591\n",
            "step 1200, training accuracy: 0.540000 original loss: 5.865282 matching loss: 0.014589\n",
            "step 1200, Validation accuracy: 0.542700\n",
            "step 1300, training accuracy: 0.580000 original loss: 5.812075 matching loss: 0.015103\n",
            "step 1300, Validation accuracy: 0.545200\n",
            "step 1400, training accuracy: 0.570000 original loss: 5.832185 matching loss: 0.015346\n",
            "step 1400, Validation accuracy: 0.561500\n",
            "get new weight for 0.5615\n",
            "step 1500, training accuracy: 0.640000 original loss: 5.787163 matching loss: 0.015597\n",
            "step 1500, Validation accuracy: 0.556400\n",
            "step 1600, training accuracy: 0.590000 original loss: 5.806189 matching loss: 0.015874\n",
            "step 1600, Validation accuracy: 0.557200\n",
            "step 1700, training accuracy: 0.490000 original loss: 5.977022 matching loss: 0.016009\n",
            "step 1700, Validation accuracy: 0.559800\n",
            "step 1800, training accuracy: 0.550000 original loss: 6.023254 matching loss: 0.016492\n",
            "step 1800, Validation accuracy: 0.562600\n",
            "get new weight for 0.5626\n",
            "step 1900, training accuracy: 0.650000 original loss: 5.555014 matching loss: 0.016604\n",
            "step 1900, Validation accuracy: 0.566100\n",
            "get new weight for 0.5661\n",
            "step 1999, training accuracy: 0.560000 original loss: 5.799849 matching loss: 0.016892\n",
            "step 1999, Validation accuracy: 0.559700\n",
            "cifar10/cifar10_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "step 0, training accuracy: 0.860000 original loss: 5.494299 matching loss: 0.020815\n",
            "step 0, Validation accuracy: 0.794100\n",
            "step 100, training accuracy: 0.810000 original loss: 5.169604 matching loss: 0.016477\n",
            "step 100, Validation accuracy: 0.822565\n",
            "get new weight for 0.82256454\n",
            "step 200, training accuracy: 0.770000 original loss: 5.208176 matching loss: 0.015599\n",
            "step 200, Validation accuracy: 0.826444\n",
            "get new weight for 0.8264444\n",
            "step 300, training accuracy: 0.880000 original loss: 5.142461 matching loss: 0.015002\n",
            "step 300, Validation accuracy: 0.821066\n",
            "step 400, training accuracy: 0.850000 original loss: 5.090808 matching loss: 0.014477\n",
            "step 400, Validation accuracy: 0.828711\n",
            "get new weight for 0.8287108\n",
            "step 500, training accuracy: 0.830000 original loss: 5.084723 matching loss: 0.014355\n",
            "step 500, Validation accuracy: 0.825868\n",
            "step 600, training accuracy: 0.800000 original loss: 5.306828 matching loss: 0.013777\n",
            "step 600, Validation accuracy: 0.826329\n",
            "step 700, training accuracy: 0.860000 original loss: 5.031750 matching loss: 0.013742\n",
            "step 700, Validation accuracy: 0.829057\n",
            "get new weight for 0.82905656\n",
            "step 800, training accuracy: 0.860000 original loss: 5.157645 matching loss: 0.013603\n",
            "step 800, Validation accuracy: 0.830401\n",
            "get new weight for 0.83040106\n",
            "step 900, training accuracy: 0.840000 original loss: 5.070785 matching loss: 0.013615\n",
            "step 900, Validation accuracy: 0.834473\n",
            "get new weight for 0.83447295\n",
            "step 1000, training accuracy: 0.870000 original loss: 5.000432 matching loss: 0.013557\n",
            "step 1000, Validation accuracy: 0.827405\n",
            "step 1100, training accuracy: 0.910000 original loss: 4.985643 matching loss: 0.013629\n",
            "step 1100, Validation accuracy: 0.834780\n",
            "get new weight for 0.8347803\n",
            "step 1200, training accuracy: 0.880000 original loss: 5.042699 matching loss: 0.013684\n",
            "step 1200, Validation accuracy: 0.829710\n",
            "step 1300, training accuracy: 0.840000 original loss: 5.175302 matching loss: 0.013540\n",
            "step 1300, Validation accuracy: 0.822296\n",
            "step 1400, training accuracy: 0.870000 original loss: 5.165300 matching loss: 0.013797\n",
            "step 1400, Validation accuracy: 0.834435\n",
            "step 1500, training accuracy: 0.900000 original loss: 5.048781 matching loss: 0.013694\n",
            "step 1500, Validation accuracy: 0.835817\n",
            "get new weight for 0.83581746\n",
            "step 1600, training accuracy: 0.850000 original loss: 5.125286 matching loss: 0.013799\n",
            "step 1600, Validation accuracy: 0.833205\n",
            "step 1700, training accuracy: 0.880000 original loss: 5.035652 matching loss: 0.013695\n",
            "step 1700, Validation accuracy: 0.837008\n",
            "get new weight for 0.8370083\n",
            "step 1800, training accuracy: 0.870000 original loss: 5.034093 matching loss: 0.014094\n",
            "step 1800, Validation accuracy: 0.836125\n",
            "step 1900, training accuracy: 0.850000 original loss: 5.114631 matching loss: 0.014208\n",
            "step 1900, Validation accuracy: 0.838353\n",
            "get new weight for 0.8383528\n",
            "step 1999, training accuracy: 0.850000 original loss: 5.152795 matching loss: 0.014016\n",
            "step 1999, Validation accuracy: 0.835741\n",
            "svhn/svhn_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x1d58e000 @  0x7f00d363f1e7 0x7f00d0f88ca1 0x7f00d0ff29c5 0x7f00d0ff355e 0x7f00d108ca6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "step 0, training accuracy: 0.710000 original loss: 5.770989 matching loss: 0.019416\n",
            "step 0, Validation accuracy: 0.404995\n",
            "step 100, training accuracy: 0.760000 original loss: 5.426664 matching loss: 0.015577\n",
            "step 100, Validation accuracy: 0.404810\n",
            "step 200, training accuracy: 0.800000 original loss: 5.357290 matching loss: 0.015022\n",
            "step 200, Validation accuracy: 0.402960\n",
            "step 300, training accuracy: 0.720000 original loss: 5.528364 matching loss: 0.015255\n",
            "step 300, Validation accuracy: 0.380944\n",
            "step 400, training accuracy: 0.790000 original loss: 5.328598 matching loss: 0.015475\n",
            "step 400, Validation accuracy: 0.414061\n",
            "get new weight for 0.41406104\n",
            "step 500, training accuracy: 0.790000 original loss: 5.389478 matching loss: 0.015607\n",
            "step 500, Validation accuracy: 0.414431\n",
            "get new weight for 0.4144311\n",
            "step 600, training accuracy: 0.770000 original loss: 5.346191 matching loss: 0.015909\n",
            "step 600, Validation accuracy: 0.394265\n",
            "step 700, training accuracy: 0.750000 original loss: 5.385147 matching loss: 0.016412\n",
            "step 700, Validation accuracy: 0.407401\n",
            "step 800, training accuracy: 0.830000 original loss: 5.408310 matching loss: 0.016587\n",
            "step 800, Validation accuracy: 0.410361\n",
            "step 900, training accuracy: 0.800000 original loss: 5.404384 matching loss: 0.016708\n",
            "step 900, Validation accuracy: 0.410361\n",
            "step 1000, training accuracy: 0.730000 original loss: 5.496167 matching loss: 0.017270\n",
            "step 1000, Validation accuracy: 0.402590\n",
            "step 1100, training accuracy: 0.840000 original loss: 5.291184 matching loss: 0.017349\n",
            "step 1100, Validation accuracy: 0.397595\n",
            "step 1200, training accuracy: 0.780000 original loss: 5.361636 matching loss: 0.018461\n",
            "step 1200, Validation accuracy: 0.396485\n",
            "step 1300, training accuracy: 0.760000 original loss: 5.521297 matching loss: 0.018306\n",
            "step 1300, Validation accuracy: 0.405180\n",
            "step 1400, training accuracy: 0.890000 original loss: 5.169931 matching loss: 0.018643\n",
            "step 1400, Validation accuracy: 0.410176\n",
            "step 1500, training accuracy: 0.810000 original loss: 5.332911 matching loss: 0.018963\n",
            "step 1500, Validation accuracy: 0.404255\n",
            "step 1600, training accuracy: 0.780000 original loss: 5.300186 matching loss: 0.019455\n",
            "step 1600, Validation accuracy: 0.419241\n",
            "get new weight for 0.41924143\n",
            "step 1700, training accuracy: 0.720000 original loss: 5.437432 matching loss: 0.019616\n",
            "step 1700, Validation accuracy: 0.409806\n",
            "step 1800, training accuracy: 0.820000 original loss: 5.313411 matching loss: 0.020022\n",
            "step 1800, Validation accuracy: 0.405550\n",
            "step 1900, training accuracy: 0.780000 original loss: 5.351148 matching loss: 0.020545\n",
            "step 1900, Validation accuracy: 0.404995\n",
            "step 1999, training accuracy: 0.860000 original loss: 5.246331 matching loss: 0.020703\n",
            "step 1999, Validation accuracy: 0.392969\n",
            "us8k/us8k_weight.npy\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Inference accuracy: 0.928400\n",
            "Inference accuracy: 0.615448\n",
            "Inference accuracy: 0.847110\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x67f0000 @  0x7f43ff69a1e7 0x7f43fcfe3ca1 0x7f43fd04d9c5 0x7f43fd04e55e 0x7f43fd0e7a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.520800\n",
            "Inference accuracy: 0.824063\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x574a000 @  0x7f3c0e7091e7 0x7f3c0c052ca1 0x7f3c0c0bc9c5 0x7f3c0c0bd55e 0x7f3c0c156a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.419241\n",
            "4-th joint optimization\n",
            "get_matching_loss\n",
            "v_train\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "step 0, training accuracy: 0.910000 original loss: 5.967732 matching loss: 0.008408\n",
            "step 0, Validation accuracy: 0.928400\n",
            "step 100, training accuracy: 0.960000 original loss: 4.778229 matching loss: 0.007276\n",
            "step 100, Validation accuracy: 0.970100\n",
            "get new weight for 0.9701\n",
            "step 200, training accuracy: 0.960000 original loss: 4.739643 matching loss: 0.007099\n",
            "step 200, Validation accuracy: 0.974200\n",
            "get new weight for 0.9742\n",
            "step 300, training accuracy: 0.970000 original loss: 4.741541 matching loss: 0.006952\n",
            "step 300, Validation accuracy: 0.974800\n",
            "get new weight for 0.9748\n",
            "step 400, training accuracy: 0.990000 original loss: 4.686463 matching loss: 0.006778\n",
            "step 400, Validation accuracy: 0.973800\n",
            "step 500, training accuracy: 0.990000 original loss: 4.658705 matching loss: 0.006662\n",
            "step 500, Validation accuracy: 0.973500\n",
            "step 600, training accuracy: 0.980000 original loss: 4.735581 matching loss: 0.006598\n",
            "step 600, Validation accuracy: 0.975400\n",
            "get new weight for 0.9754\n",
            "step 700, training accuracy: 0.990000 original loss: 4.683203 matching loss: 0.006547\n",
            "step 700, Validation accuracy: 0.976700\n",
            "get new weight for 0.9767\n",
            "step 800, training accuracy: 1.000000 original loss: 4.676586 matching loss: 0.006496\n",
            "step 800, Validation accuracy: 0.974200\n",
            "step 900, training accuracy: 0.970000 original loss: 4.711868 matching loss: 0.006419\n",
            "step 900, Validation accuracy: 0.976500\n",
            "step 1000, training accuracy: 0.990000 original loss: 4.698195 matching loss: 0.006388\n",
            "step 1000, Validation accuracy: 0.977600\n",
            "get new weight for 0.9776\n",
            "step 1100, training accuracy: 0.960000 original loss: 4.701766 matching loss: 0.006377\n",
            "step 1100, Validation accuracy: 0.979000\n",
            "get new weight for 0.979\n",
            "step 1200, training accuracy: 1.000000 original loss: 4.653775 matching loss: 0.006370\n",
            "step 1200, Validation accuracy: 0.978700\n",
            "step 1300, training accuracy: 0.980000 original loss: 4.691492 matching loss: 0.006328\n",
            "step 1300, Validation accuracy: 0.978100\n",
            "step 1400, training accuracy: 0.990000 original loss: 4.654706 matching loss: 0.006307\n",
            "step 1400, Validation accuracy: 0.979700\n",
            "get new weight for 0.9797\n",
            "step 1500, training accuracy: 0.990000 original loss: 4.659369 matching loss: 0.006356\n",
            "step 1500, Validation accuracy: 0.976600\n",
            "step 1600, training accuracy: 0.980000 original loss: 4.759050 matching loss: 0.006286\n",
            "step 1600, Validation accuracy: 0.978400\n",
            "step 1700, training accuracy: 0.980000 original loss: 4.686659 matching loss: 0.006298\n",
            "step 1700, Validation accuracy: 0.980000\n",
            "get new weight for 0.98\n",
            "step 1800, training accuracy: 0.990000 original loss: 4.673828 matching loss: 0.006316\n",
            "step 1800, Validation accuracy: 0.979600\n",
            "step 1900, training accuracy: 0.970000 original loss: 4.694146 matching loss: 0.006409\n",
            "step 1900, Validation accuracy: 0.976000\n",
            "step 1999, training accuracy: 0.990000 original loss: 4.670134 matching loss: 0.006443\n",
            "step 1999, Validation accuracy: 0.978700\n",
            "mnist/mnist_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "step 0, training accuracy: 0.650000 original loss: 6.080108 matching loss: 0.013635\n",
            "step 0, Validation accuracy: 0.607088\n",
            "step 100, training accuracy: 0.790000 original loss: 5.674611 matching loss: 0.015893\n",
            "step 100, Validation accuracy: 0.678782\n",
            "get new weight for 0.67878234\n",
            "step 200, training accuracy: 0.730000 original loss: 5.663683 matching loss: 0.016975\n",
            "step 200, Validation accuracy: 0.687233\n",
            "get new weight for 0.6872331\n",
            "step 300, training accuracy: 0.740000 original loss: 5.894457 matching loss: 0.017288\n",
            "step 300, Validation accuracy: 0.696138\n",
            "get new weight for 0.69613814\n",
            "step 400, training accuracy: 0.700000 original loss: 5.753322 matching loss: 0.018157\n",
            "step 400, Validation accuracy: 0.688596\n",
            "step 500, training accuracy: 0.810000 original loss: 5.483623 matching loss: 0.018508\n",
            "step 500, Validation accuracy: 0.698046\n",
            "get new weight for 0.6980463\n",
            "step 600, training accuracy: 0.740000 original loss: 5.552201 matching loss: 0.019079\n",
            "step 600, Validation accuracy: 0.697955\n",
            "step 700, training accuracy: 0.700000 original loss: 5.672579 matching loss: 0.019570\n",
            "step 700, Validation accuracy: 0.693412\n",
            "step 800, training accuracy: 0.780000 original loss: 5.503564 matching loss: 0.019768\n",
            "step 800, Validation accuracy: 0.705407\n",
            "get new weight for 0.7054066\n",
            "step 900, training accuracy: 0.770000 original loss: 5.531254 matching loss: 0.020194\n",
            "step 900, Validation accuracy: 0.699500\n",
            "step 1000, training accuracy: 0.660000 original loss: 5.813065 matching loss: 0.020609\n",
            "step 1000, Validation accuracy: 0.700772\n",
            "step 1100, training accuracy: 0.760000 original loss: 5.646468 matching loss: 0.020590\n",
            "step 1100, Validation accuracy: 0.707042\n",
            "get new weight for 0.7070423\n",
            "step 1200, training accuracy: 0.720000 original loss: 5.572693 matching loss: 0.021235\n",
            "step 1200, Validation accuracy: 0.700591\n",
            "step 1300, training accuracy: 0.730000 original loss: 5.698911 matching loss: 0.021778\n",
            "step 1300, Validation accuracy: 0.706497\n",
            "step 1400, training accuracy: 0.790000 original loss: 5.470828 matching loss: 0.021811\n",
            "step 1400, Validation accuracy: 0.705407\n",
            "step 1500, training accuracy: 0.830000 original loss: 5.333740 matching loss: 0.021941\n",
            "step 1500, Validation accuracy: 0.711949\n",
            "get new weight for 0.7119491\n",
            "step 1600, training accuracy: 0.810000 original loss: 5.492216 matching loss: 0.022712\n",
            "step 1600, Validation accuracy: 0.716674\n",
            "get new weight for 0.71667427\n",
            "step 1700, training accuracy: 0.700000 original loss: 5.598118 matching loss: 0.023246\n",
            "step 1700, Validation accuracy: 0.715039\n",
            "step 1800, training accuracy: 0.740000 original loss: 5.718609 matching loss: 0.023471\n",
            "step 1800, Validation accuracy: 0.711949\n",
            "step 1900, training accuracy: 0.760000 original loss: 5.556482 matching loss: 0.023740\n",
            "step 1900, Validation accuracy: 0.711586\n",
            "step 1999, training accuracy: 0.750000 original loss: 5.539371 matching loss: 0.024284\n",
            "step 1999, Validation accuracy: 0.712040\n",
            "gsc/gsc_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "step 0, training accuracy: 0.820000 original loss: 5.787336 matching loss: 0.019687\n",
            "step 0, Validation accuracy: 0.802454\n",
            "step 100, training accuracy: 0.940000 original loss: 4.961088 matching loss: 0.017425\n",
            "step 100, Validation accuracy: 0.919082\n",
            "get new weight for 0.91908157\n",
            "step 200, training accuracy: 0.990000 original loss: 4.869291 matching loss: 0.016894\n",
            "step 200, Validation accuracy: 0.924861\n",
            "get new weight for 0.92486143\n",
            "step 300, training accuracy: 1.000000 original loss: 4.831580 matching loss: 0.016765\n",
            "step 300, Validation accuracy: 0.923357\n",
            "step 400, training accuracy: 0.990000 original loss: 4.886400 matching loss: 0.016960\n",
            "step 400, Validation accuracy: 0.925574\n",
            "get new weight for 0.925574\n",
            "step 500, training accuracy: 0.980000 original loss: 4.825073 matching loss: 0.016792\n",
            "step 500, Validation accuracy: 0.926603\n",
            "get new weight for 0.9266033\n",
            "step 600, training accuracy: 0.950000 original loss: 4.863902 matching loss: 0.016459\n",
            "step 600, Validation accuracy: 0.930245\n",
            "get new weight for 0.93024546\n",
            "step 700, training accuracy: 1.000000 original loss: 4.800124 matching loss: 0.016643\n",
            "step 700, Validation accuracy: 0.926049\n",
            "step 800, training accuracy: 0.980000 original loss: 4.781174 matching loss: 0.016823\n",
            "step 800, Validation accuracy: 0.928108\n",
            "step 900, training accuracy: 0.990000 original loss: 4.797485 matching loss: 0.016815\n",
            "step 900, Validation accuracy: 0.932700\n",
            "get new weight for 0.9326999\n",
            "step 1000, training accuracy: 0.990000 original loss: 4.777312 matching loss: 0.016739\n",
            "step 1000, Validation accuracy: 0.931116\n",
            "step 1100, training accuracy: 0.980000 original loss: 4.809995 matching loss: 0.017055\n",
            "step 1100, Validation accuracy: 0.936025\n",
            "get new weight for 0.9360253\n",
            "step 1200, training accuracy: 0.960000 original loss: 4.827609 matching loss: 0.016912\n",
            "step 1200, Validation accuracy: 0.931433\n",
            "step 1300, training accuracy: 0.980000 original loss: 4.803219 matching loss: 0.017293\n",
            "step 1300, Validation accuracy: 0.932700\n",
            "step 1400, training accuracy: 1.000000 original loss: 4.733373 matching loss: 0.017055\n",
            "step 1400, Validation accuracy: 0.933254\n",
            "step 1500, training accuracy: 1.000000 original loss: 4.756354 matching loss: 0.017213\n",
            "step 1500, Validation accuracy: 0.935392\n",
            "step 1600, training accuracy: 1.000000 original loss: 4.720539 matching loss: 0.017364\n",
            "step 1600, Validation accuracy: 0.935629\n",
            "step 1700, training accuracy: 0.960000 original loss: 4.822073 matching loss: 0.017378\n",
            "step 1700, Validation accuracy: 0.934917\n",
            "step 1800, training accuracy: 1.000000 original loss: 4.716939 matching loss: 0.017694\n",
            "step 1800, Validation accuracy: 0.934917\n",
            "step 1900, training accuracy: 0.980000 original loss: 4.831953 matching loss: 0.017861\n",
            "step 1900, Validation accuracy: 0.933729\n",
            "step 1999, training accuracy: 0.990000 original loss: 4.738689 matching loss: 0.017856\n",
            "step 1999, Validation accuracy: 0.937767\n",
            "get new weight for 0.9377672\n",
            "gtsrb/gtsrb_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x1bf2c000 @  0x7efe3d76f1e7 0x7efe3b0b8ca1 0x7efe3b1229c5 0x7efe3b12355e 0x7efe3b1bca6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "step 0, training accuracy: 0.540000 original loss: 6.090792 matching loss: 0.011823\n",
            "step 0, Validation accuracy: 0.489000\n",
            "step 100, training accuracy: 0.590000 original loss: 5.826864 matching loss: 0.010749\n",
            "step 100, Validation accuracy: 0.550500\n",
            "get new weight for 0.5505\n",
            "step 200, training accuracy: 0.610000 original loss: 5.702819 matching loss: 0.010796\n",
            "step 200, Validation accuracy: 0.549500\n",
            "step 300, training accuracy: 0.540000 original loss: 5.879883 matching loss: 0.011252\n",
            "step 300, Validation accuracy: 0.547500\n",
            "step 400, training accuracy: 0.520000 original loss: 5.882771 matching loss: 0.011325\n",
            "step 400, Validation accuracy: 0.540000\n",
            "step 500, training accuracy: 0.590000 original loss: 5.815689 matching loss: 0.011687\n",
            "step 500, Validation accuracy: 0.552500\n",
            "get new weight for 0.5525\n",
            "step 600, training accuracy: 0.610000 original loss: 5.688539 matching loss: 0.012321\n",
            "step 600, Validation accuracy: 0.554500\n",
            "get new weight for 0.5545\n",
            "step 700, training accuracy: 0.630000 original loss: 5.787212 matching loss: 0.012323\n",
            "step 700, Validation accuracy: 0.555800\n",
            "get new weight for 0.5558\n",
            "step 800, training accuracy: 0.630000 original loss: 5.798723 matching loss: 0.012544\n",
            "step 800, Validation accuracy: 0.560700\n",
            "get new weight for 0.5607\n",
            "step 900, training accuracy: 0.520000 original loss: 5.863162 matching loss: 0.012961\n",
            "step 900, Validation accuracy: 0.551100\n",
            "step 1000, training accuracy: 0.580000 original loss: 5.783522 matching loss: 0.013276\n",
            "step 1000, Validation accuracy: 0.554200\n",
            "step 1100, training accuracy: 0.590000 original loss: 5.783537 matching loss: 0.013370\n",
            "step 1100, Validation accuracy: 0.558800\n",
            "step 1200, training accuracy: 0.580000 original loss: 5.746558 matching loss: 0.013763\n",
            "step 1200, Validation accuracy: 0.565700\n",
            "get new weight for 0.5657\n",
            "step 1300, training accuracy: 0.670000 original loss: 5.695302 matching loss: 0.014150\n",
            "step 1300, Validation accuracy: 0.562000\n",
            "step 1400, training accuracy: 0.630000 original loss: 5.759326 matching loss: 0.014297\n",
            "step 1400, Validation accuracy: 0.559400\n",
            "step 1500, training accuracy: 0.680000 original loss: 5.668378 matching loss: 0.014446\n",
            "step 1500, Validation accuracy: 0.563000\n",
            "step 1600, training accuracy: 0.570000 original loss: 5.775738 matching loss: 0.014897\n",
            "step 1600, Validation accuracy: 0.562600\n",
            "step 1700, training accuracy: 0.610000 original loss: 5.890574 matching loss: 0.015173\n",
            "step 1700, Validation accuracy: 0.563800\n",
            "step 1800, training accuracy: 0.580000 original loss: 5.696123 matching loss: 0.015486\n",
            "step 1800, Validation accuracy: 0.561700\n",
            "step 1900, training accuracy: 0.590000 original loss: 5.696419 matching loss: 0.015683\n",
            "step 1900, Validation accuracy: 0.564100\n",
            "step 1999, training accuracy: 0.620000 original loss: 5.759604 matching loss: 0.015931\n",
            "step 1999, Validation accuracy: 0.565800\n",
            "get new weight for 0.5658\n",
            "cifar10/cifar10_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "step 0, training accuracy: 0.900000 original loss: 5.399992 matching loss: 0.019820\n",
            "step 0, Validation accuracy: 0.809312\n",
            "step 100, training accuracy: 0.780000 original loss: 5.224139 matching loss: 0.015906\n",
            "step 100, Validation accuracy: 0.829825\n",
            "get new weight for 0.8298248\n",
            "step 200, training accuracy: 0.880000 original loss: 5.051695 matching loss: 0.014779\n",
            "step 200, Validation accuracy: 0.830478\n",
            "get new weight for 0.8304779\n",
            "step 300, training accuracy: 0.830000 original loss: 5.262465 matching loss: 0.014119\n",
            "step 300, Validation accuracy: 0.833244\n",
            "get new weight for 0.8332437\n",
            "step 400, training accuracy: 0.870000 original loss: 5.076392 matching loss: 0.014745\n",
            "step 400, Validation accuracy: 0.834703\n",
            "get new weight for 0.83470345\n",
            "step 500, training accuracy: 0.840000 original loss: 5.328459 matching loss: 0.013648\n",
            "step 500, Validation accuracy: 0.836931\n",
            "get new weight for 0.83693147\n",
            "step 600, training accuracy: 0.850000 original loss: 5.161661 matching loss: 0.013654\n",
            "step 600, Validation accuracy: 0.833013\n",
            "step 700, training accuracy: 0.870000 original loss: 5.034687 matching loss: 0.013332\n",
            "step 700, Validation accuracy: 0.834050\n",
            "step 800, training accuracy: 0.920000 original loss: 4.973117 matching loss: 0.013323\n",
            "step 800, Validation accuracy: 0.839928\n",
            "get new weight for 0.8399278\n",
            "step 900, training accuracy: 0.820000 original loss: 5.436519 matching loss: 0.013314\n",
            "step 900, Validation accuracy: 0.838967\n",
            "step 1000, training accuracy: 0.890000 original loss: 5.084410 matching loss: 0.013217\n",
            "step 1000, Validation accuracy: 0.831361\n",
            "step 1100, training accuracy: 0.830000 original loss: 5.165054 matching loss: 0.013413\n",
            "step 1100, Validation accuracy: 0.839851\n",
            "step 1200, training accuracy: 0.810000 original loss: 5.286672 matching loss: 0.013223\n",
            "step 1200, Validation accuracy: 0.837200\n",
            "step 1300, training accuracy: 0.870000 original loss: 5.069303 matching loss: 0.013191\n",
            "step 1300, Validation accuracy: 0.837546\n",
            "step 1400, training accuracy: 0.880000 original loss: 5.134337 matching loss: 0.013071\n",
            "step 1400, Validation accuracy: 0.834703\n",
            "step 1500, training accuracy: 0.820000 original loss: 5.109309 matching loss: 0.013045\n",
            "step 1500, Validation accuracy: 0.837354\n",
            "step 1600, training accuracy: 0.840000 original loss: 5.166105 matching loss: 0.013052\n",
            "step 1600, Validation accuracy: 0.835894\n",
            "step 1700, training accuracy: 0.850000 original loss: 5.141408 matching loss: 0.013279\n",
            "step 1700, Validation accuracy: 0.840005\n",
            "get new weight for 0.8400046\n",
            "step 1800, training accuracy: 0.880000 original loss: 5.023897 matching loss: 0.013304\n",
            "step 1800, Validation accuracy: 0.838814\n",
            "step 1900, training accuracy: 0.860000 original loss: 5.073900 matching loss: 0.013510\n",
            "step 1900, Validation accuracy: 0.835894\n",
            "step 1999, training accuracy: 0.920000 original loss: 5.035351 matching loss: 0.013607\n",
            "step 1999, Validation accuracy: 0.836816\n",
            "svhn/svhn_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x1c8cc000 @  0x7fa9c73fd1e7 0x7fa9c4d46ca1 0x7fa9c4db09c5 0x7fa9c4db155e 0x7fa9c4e4aa6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "step 0, training accuracy: 0.810000 original loss: 5.533914 matching loss: 0.018328\n",
            "step 0, Validation accuracy: 0.405920\n",
            "step 100, training accuracy: 0.840000 original loss: 5.313572 matching loss: 0.014293\n",
            "step 100, Validation accuracy: 0.396670\n",
            "step 200, training accuracy: 0.820000 original loss: 5.396090 matching loss: 0.013982\n",
            "step 200, Validation accuracy: 0.401295\n",
            "step 300, training accuracy: 0.890000 original loss: 5.210249 matching loss: 0.014057\n",
            "step 300, Validation accuracy: 0.391304\n",
            "step 400, training accuracy: 0.710000 original loss: 5.462767 matching loss: 0.014684\n",
            "step 400, Validation accuracy: 0.388344\n",
            "step 500, training accuracy: 0.820000 original loss: 5.274303 matching loss: 0.014271\n",
            "step 500, Validation accuracy: 0.403700\n",
            "step 600, training accuracy: 0.830000 original loss: 5.292021 matching loss: 0.014377\n",
            "step 600, Validation accuracy: 0.401480\n",
            "step 700, training accuracy: 0.660000 original loss: 5.624700 matching loss: 0.015200\n",
            "step 700, Validation accuracy: 0.399445\n",
            "step 800, training accuracy: 0.830000 original loss: 5.267322 matching loss: 0.015042\n",
            "step 800, Validation accuracy: 0.392229\n",
            "step 900, training accuracy: 0.830000 original loss: 5.298524 matching loss: 0.015266\n",
            "step 900, Validation accuracy: 0.392229\n",
            "step 1000, training accuracy: 0.840000 original loss: 5.257120 matching loss: 0.015405\n",
            "step 1000, Validation accuracy: 0.404255\n",
            "step 1100, training accuracy: 0.850000 original loss: 5.213298 matching loss: 0.015626\n",
            "step 1100, Validation accuracy: 0.409251\n",
            "get new weight for 0.4092507\n",
            "step 1200, training accuracy: 0.790000 original loss: 5.428606 matching loss: 0.016003\n",
            "step 1200, Validation accuracy: 0.406660\n",
            "step 1300, training accuracy: 0.820000 original loss: 5.305359 matching loss: 0.016329\n",
            "step 1300, Validation accuracy: 0.401850\n",
            "step 1400, training accuracy: 0.840000 original loss: 5.267166 matching loss: 0.016425\n",
            "step 1400, Validation accuracy: 0.405920\n",
            "step 1500, training accuracy: 0.820000 original loss: 5.296649 matching loss: 0.016951\n",
            "step 1500, Validation accuracy: 0.401295\n",
            "step 1600, training accuracy: 0.780000 original loss: 5.445075 matching loss: 0.017783\n",
            "step 1600, Validation accuracy: 0.396485\n",
            "step 1700, training accuracy: 0.820000 original loss: 5.268834 matching loss: 0.017694\n",
            "step 1700, Validation accuracy: 0.406105\n",
            "step 1800, training accuracy: 0.780000 original loss: 5.396213 matching loss: 0.017639\n",
            "step 1800, Validation accuracy: 0.397595\n",
            "step 1900, training accuracy: 0.790000 original loss: 5.371990 matching loss: 0.017782\n",
            "step 1900, Validation accuracy: 0.400185\n",
            "step 1999, training accuracy: 0.850000 original loss: 5.274020 matching loss: 0.018364\n",
            "step 1999, Validation accuracy: 0.377243\n",
            "us8k/us8k_weight.npy\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Inference accuracy: 0.957600\n",
            "Inference accuracy: 0.643253\n",
            "Inference accuracy: 0.901504\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x4eae000 @  0x7f20d07fb1e7 0x7f20ce144ca1 0x7f20ce1ae9c5 0x7f20ce1af55e 0x7f20ce248a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.543100\n",
            "Inference accuracy: 0.831592\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x5c1e000 @  0x7fe6626da1e7 0x7fe660023ca1 0x7fe66008d9c5 0x7fe66008e55e 0x7fe660127a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.409251\n",
            "5-th joint optimization\n",
            "get_matching_loss\n",
            "v_train\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "step 0, training accuracy: 0.970000 original loss: 5.476813 matching loss: 0.006286\n",
            "step 0, Validation accuracy: 0.957600\n",
            "step 100, training accuracy: 0.990000 original loss: 4.694329 matching loss: 0.005656\n",
            "step 100, Validation accuracy: 0.976200\n",
            "get new weight for 0.9762\n",
            "step 200, training accuracy: 0.990000 original loss: 4.676424 matching loss: 0.005434\n",
            "step 200, Validation accuracy: 0.977700\n",
            "get new weight for 0.9777\n",
            "step 300, training accuracy: 0.990000 original loss: 4.695926 matching loss: 0.005215\n",
            "step 300, Validation accuracy: 0.978200\n",
            "get new weight for 0.9782\n",
            "step 400, training accuracy: 0.960000 original loss: 4.709019 matching loss: 0.005142\n",
            "step 400, Validation accuracy: 0.977000\n",
            "step 500, training accuracy: 0.960000 original loss: 4.761726 matching loss: 0.005106\n",
            "step 500, Validation accuracy: 0.978100\n",
            "step 600, training accuracy: 0.960000 original loss: 4.744491 matching loss: 0.004934\n",
            "step 600, Validation accuracy: 0.978800\n",
            "get new weight for 0.9788\n",
            "step 700, training accuracy: 0.970000 original loss: 4.726757 matching loss: 0.004917\n",
            "step 700, Validation accuracy: 0.979700\n",
            "get new weight for 0.9797\n",
            "step 800, training accuracy: 0.970000 original loss: 4.726502 matching loss: 0.004977\n",
            "step 800, Validation accuracy: 0.977900\n",
            "step 900, training accuracy: 0.990000 original loss: 4.653656 matching loss: 0.004960\n",
            "step 900, Validation accuracy: 0.979300\n",
            "step 1000, training accuracy: 0.960000 original loss: 4.775992 matching loss: 0.004865\n",
            "step 1000, Validation accuracy: 0.979100\n",
            "step 1100, training accuracy: 0.970000 original loss: 4.677833 matching loss: 0.004877\n",
            "step 1100, Validation accuracy: 0.980300\n",
            "get new weight for 0.9803\n",
            "step 1200, training accuracy: 0.970000 original loss: 4.768876 matching loss: 0.004868\n",
            "step 1200, Validation accuracy: 0.979100\n",
            "step 1300, training accuracy: 1.000000 original loss: 4.657693 matching loss: 0.004907\n",
            "step 1300, Validation accuracy: 0.979800\n",
            "step 1400, training accuracy: 0.970000 original loss: 4.714195 matching loss: 0.004957\n",
            "step 1400, Validation accuracy: 0.979200\n",
            "step 1500, training accuracy: 0.960000 original loss: 4.706855 matching loss: 0.004917\n",
            "step 1500, Validation accuracy: 0.979000\n",
            "step 1600, training accuracy: 0.990000 original loss: 4.692585 matching loss: 0.004916\n",
            "step 1600, Validation accuracy: 0.979400\n",
            "step 1700, training accuracy: 0.970000 original loss: 4.722012 matching loss: 0.004923\n",
            "step 1700, Validation accuracy: 0.977400\n",
            "step 1800, training accuracy: 0.980000 original loss: 4.676134 matching loss: 0.004954\n",
            "step 1800, Validation accuracy: 0.980300\n",
            "step 1900, training accuracy: 0.990000 original loss: 4.653897 matching loss: 0.004926\n",
            "step 1900, Validation accuracy: 0.979000\n",
            "step 1999, training accuracy: 0.980000 original loss: 4.655843 matching loss: 0.004920\n",
            "step 1999, Validation accuracy: 0.981400\n",
            "get new weight for 0.9814\n",
            "mnist/mnist_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "step 0, training accuracy: 0.690000 original loss: 5.967013 matching loss: 0.010954\n",
            "step 0, Validation accuracy: 0.637256\n",
            "step 100, training accuracy: 0.710000 original loss: 5.571801 matching loss: 0.013921\n",
            "step 100, Validation accuracy: 0.695866\n",
            "get new weight for 0.6958655\n",
            "step 200, training accuracy: 0.750000 original loss: 5.643405 matching loss: 0.014992\n",
            "step 200, Validation accuracy: 0.699864\n",
            "get new weight for 0.6998637\n",
            "step 300, training accuracy: 0.730000 original loss: 5.767469 matching loss: 0.015722\n",
            "step 300, Validation accuracy: 0.698773\n",
            "step 400, training accuracy: 0.790000 original loss: 5.514925 matching loss: 0.016314\n",
            "step 400, Validation accuracy: 0.709496\n",
            "get new weight for 0.70949566\n",
            "step 500, training accuracy: 0.740000 original loss: 5.487021 matching loss: 0.016588\n",
            "step 500, Validation accuracy: 0.708769\n",
            "step 600, training accuracy: 0.680000 original loss: 5.817240 matching loss: 0.017219\n",
            "step 600, Validation accuracy: 0.701499\n",
            "step 700, training accuracy: 0.730000 original loss: 5.639469 matching loss: 0.017564\n",
            "step 700, Validation accuracy: 0.711495\n",
            "get new weight for 0.7114948\n",
            "step 800, training accuracy: 0.760000 original loss: 5.699223 matching loss: 0.017715\n",
            "step 800, Validation accuracy: 0.710950\n",
            "step 900, training accuracy: 0.820000 original loss: 5.443336 matching loss: 0.018440\n",
            "step 900, Validation accuracy: 0.710223\n",
            "step 1000, training accuracy: 0.710000 original loss: 5.840685 matching loss: 0.018684\n",
            "step 1000, Validation accuracy: 0.714948\n",
            "get new weight for 0.71494776\n",
            "step 1100, training accuracy: 0.720000 original loss: 5.632394 matching loss: 0.018944\n",
            "step 1100, Validation accuracy: 0.718492\n",
            "get new weight for 0.7184916\n",
            "step 1200, training accuracy: 0.750000 original loss: 5.662585 matching loss: 0.019556\n",
            "step 1200, Validation accuracy: 0.712767\n",
            "step 1300, training accuracy: 0.750000 original loss: 5.725170 matching loss: 0.019432\n",
            "step 1300, Validation accuracy: 0.719945\n",
            "get new weight for 0.7199455\n",
            "step 1400, training accuracy: 0.730000 original loss: 5.623635 matching loss: 0.020165\n",
            "step 1400, Validation accuracy: 0.719945\n",
            "step 1500, training accuracy: 0.790000 original loss: 5.481300 matching loss: 0.020754\n",
            "step 1500, Validation accuracy: 0.714584\n",
            "step 1600, training accuracy: 0.710000 original loss: 5.613561 matching loss: 0.020908\n",
            "step 1600, Validation accuracy: 0.718219\n",
            "step 1700, training accuracy: 0.720000 original loss: 5.688372 matching loss: 0.021098\n",
            "step 1700, Validation accuracy: 0.725579\n",
            "get new weight for 0.72557926\n",
            "step 1800, training accuracy: 0.740000 original loss: 5.584455 matching loss: 0.021709\n",
            "step 1800, Validation accuracy: 0.720854\n",
            "step 1900, training accuracy: 0.760000 original loss: 5.628614 matching loss: 0.022224\n",
            "step 1900, Validation accuracy: 0.723762\n",
            "step 1999, training accuracy: 0.770000 original loss: 5.562725 matching loss: 0.022481\n",
            "step 1999, Validation accuracy: 0.719037\n",
            "gsc/gsc_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "step 0, training accuracy: 0.910000 original loss: 5.529311 matching loss: 0.018437\n",
            "step 0, Validation accuracy: 0.869913\n",
            "step 100, training accuracy: 0.980000 original loss: 4.840203 matching loss: 0.015691\n",
            "step 100, Validation accuracy: 0.927633\n",
            "get new weight for 0.92763263\n",
            "step 200, training accuracy: 0.990000 original loss: 4.835581 matching loss: 0.015059\n",
            "step 200, Validation accuracy: 0.929295\n",
            "get new weight for 0.9292953\n",
            "step 300, training accuracy: 0.980000 original loss: 4.853394 matching loss: 0.014456\n",
            "step 300, Validation accuracy: 0.931750\n",
            "get new weight for 0.9317498\n",
            "step 400, training accuracy: 1.000000 original loss: 4.745682 matching loss: 0.014255\n",
            "step 400, Validation accuracy: 0.931275\n",
            "step 500, training accuracy: 0.990000 original loss: 4.780176 matching loss: 0.014087\n",
            "step 500, Validation accuracy: 0.932146\n",
            "get new weight for 0.93214566\n",
            "step 600, training accuracy: 1.000000 original loss: 4.735982 matching loss: 0.014302\n",
            "step 600, Validation accuracy: 0.930245\n",
            "step 700, training accuracy: 0.970000 original loss: 4.842237 matching loss: 0.014466\n",
            "step 700, Validation accuracy: 0.931116\n",
            "step 800, training accuracy: 1.000000 original loss: 4.749275 matching loss: 0.014122\n",
            "step 800, Validation accuracy: 0.929850\n",
            "step 900, training accuracy: 1.000000 original loss: 4.725412 matching loss: 0.014232\n",
            "step 900, Validation accuracy: 0.934363\n",
            "get new weight for 0.93436265\n",
            "step 1000, training accuracy: 0.980000 original loss: 4.752870 matching loss: 0.014409\n",
            "step 1000, Validation accuracy: 0.932542\n",
            "step 1100, training accuracy: 1.000000 original loss: 4.698246 matching loss: 0.014315\n",
            "step 1100, Validation accuracy: 0.934283\n",
            "step 1200, training accuracy: 0.990000 original loss: 4.782733 matching loss: 0.014555\n",
            "step 1200, Validation accuracy: 0.933412\n",
            "step 1300, training accuracy: 0.970000 original loss: 4.775295 matching loss: 0.014816\n",
            "step 1300, Validation accuracy: 0.934758\n",
            "get new weight for 0.9347585\n",
            "step 1400, training accuracy: 0.990000 original loss: 4.752727 matching loss: 0.014528\n",
            "step 1400, Validation accuracy: 0.935075\n",
            "get new weight for 0.9350752\n",
            "step 1500, training accuracy: 0.970000 original loss: 4.815267 matching loss: 0.014673\n",
            "step 1500, Validation accuracy: 0.935313\n",
            "get new weight for 0.93531275\n",
            "step 1600, training accuracy: 0.990000 original loss: 4.712721 matching loss: 0.014869\n",
            "step 1600, Validation accuracy: 0.936896\n",
            "get new weight for 0.93689626\n",
            "step 1700, training accuracy: 0.990000 original loss: 4.755281 matching loss: 0.014988\n",
            "step 1700, Validation accuracy: 0.938797\n",
            "get new weight for 0.9387965\n",
            "step 1800, training accuracy: 0.960000 original loss: 4.807650 matching loss: 0.015067\n",
            "step 1800, Validation accuracy: 0.936580\n",
            "step 1900, training accuracy: 1.000000 original loss: 4.706542 matching loss: 0.015024\n",
            "step 1900, Validation accuracy: 0.935313\n",
            "step 1999, training accuracy: 1.000000 original loss: 4.699083 matching loss: 0.015225\n",
            "step 1999, Validation accuracy: 0.936342\n",
            "gtsrb/gtsrb_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x1c014000 @  0x7f5536b0f1e7 0x7f5534458ca1 0x7f55344c29c5 0x7f55344c355e 0x7f553455ca6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "step 0, training accuracy: 0.520000 original loss: 5.987710 matching loss: 0.009877\n",
            "step 0, Validation accuracy: 0.503300\n",
            "step 100, training accuracy: 0.560000 original loss: 5.829455 matching loss: 0.009528\n",
            "step 100, Validation accuracy: 0.555600\n",
            "get new weight for 0.5556\n",
            "step 200, training accuracy: 0.650000 original loss: 5.700047 matching loss: 0.009702\n",
            "step 200, Validation accuracy: 0.553700\n",
            "step 300, training accuracy: 0.520000 original loss: 5.839708 matching loss: 0.009941\n",
            "step 300, Validation accuracy: 0.562200\n",
            "get new weight for 0.5622\n",
            "step 400, training accuracy: 0.520000 original loss: 5.863746 matching loss: 0.010338\n",
            "step 400, Validation accuracy: 0.541800\n",
            "step 500, training accuracy: 0.580000 original loss: 5.701748 matching loss: 0.010513\n",
            "step 500, Validation accuracy: 0.558300\n",
            "step 600, training accuracy: 0.630000 original loss: 5.770019 matching loss: 0.010855\n",
            "step 600, Validation accuracy: 0.566900\n",
            "get new weight for 0.5669\n",
            "step 700, training accuracy: 0.560000 original loss: 5.939726 matching loss: 0.011053\n",
            "step 700, Validation accuracy: 0.553900\n",
            "step 800, training accuracy: 0.540000 original loss: 5.807122 matching loss: 0.011412\n",
            "step 800, Validation accuracy: 0.549700\n",
            "step 900, training accuracy: 0.600000 original loss: 5.900391 matching loss: 0.011653\n",
            "step 900, Validation accuracy: 0.560200\n",
            "step 1000, training accuracy: 0.550000 original loss: 5.844907 matching loss: 0.011966\n",
            "step 1000, Validation accuracy: 0.561800\n",
            "step 1100, training accuracy: 0.600000 original loss: 5.718763 matching loss: 0.012251\n",
            "step 1100, Validation accuracy: 0.563500\n",
            "step 1200, training accuracy: 0.580000 original loss: 5.795332 matching loss: 0.012641\n",
            "step 1200, Validation accuracy: 0.559700\n",
            "step 1300, training accuracy: 0.600000 original loss: 5.831108 matching loss: 0.012794\n",
            "step 1300, Validation accuracy: 0.561700\n",
            "step 1400, training accuracy: 0.610000 original loss: 5.660823 matching loss: 0.012838\n",
            "step 1400, Validation accuracy: 0.557700\n",
            "step 1500, training accuracy: 0.560000 original loss: 5.831358 matching loss: 0.013124\n",
            "step 1500, Validation accuracy: 0.562800\n",
            "step 1600, training accuracy: 0.630000 original loss: 5.751192 matching loss: 0.013570\n",
            "step 1600, Validation accuracy: 0.559200\n",
            "step 1700, training accuracy: 0.610000 original loss: 5.764826 matching loss: 0.013558\n",
            "step 1700, Validation accuracy: 0.562700\n",
            "step 1800, training accuracy: 0.580000 original loss: 5.723646 matching loss: 0.013658\n",
            "step 1800, Validation accuracy: 0.562700\n",
            "step 1900, training accuracy: 0.540000 original loss: 5.765124 matching loss: 0.014227\n",
            "step 1900, Validation accuracy: 0.563000\n",
            "step 1999, training accuracy: 0.570000 original loss: 5.808407 matching loss: 0.014501\n",
            "step 1999, Validation accuracy: 0.567300\n",
            "get new weight for 0.5673\n",
            "cifar10/cifar10_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "step 0, training accuracy: 0.860000 original loss: 6.028264 matching loss: 0.017882\n",
            "step 0, Validation accuracy: 0.818224\n",
            "step 100, training accuracy: 0.860000 original loss: 5.092586 matching loss: 0.014100\n",
            "step 100, Validation accuracy: 0.827520\n",
            "get new weight for 0.82751995\n",
            "step 200, training accuracy: 0.840000 original loss: 5.087379 matching loss: 0.013119\n",
            "step 200, Validation accuracy: 0.830555\n",
            "get new weight for 0.8305547\n",
            "step 300, training accuracy: 0.760000 original loss: 5.310442 matching loss: 0.012375\n",
            "step 300, Validation accuracy: 0.832744\n",
            "get new weight for 0.8327443\n",
            "step 400, training accuracy: 0.850000 original loss: 5.158654 matching loss: 0.012187\n",
            "step 400, Validation accuracy: 0.829518\n",
            "step 500, training accuracy: 0.860000 original loss: 5.144521 matching loss: 0.012154\n",
            "step 500, Validation accuracy: 0.830977\n",
            "step 600, training accuracy: 0.850000 original loss: 5.051317 matching loss: 0.011682\n",
            "step 600, Validation accuracy: 0.837392\n",
            "get new weight for 0.83739245\n",
            "step 700, training accuracy: 0.870000 original loss: 5.102995 matching loss: 0.011451\n",
            "step 700, Validation accuracy: 0.838699\n",
            "get new weight for 0.8386985\n",
            "step 800, training accuracy: 0.860000 original loss: 5.087399 matching loss: 0.011578\n",
            "step 800, Validation accuracy: 0.834857\n",
            "step 900, training accuracy: 0.820000 original loss: 5.272559 matching loss: 0.011464\n",
            "step 900, Validation accuracy: 0.838737\n",
            "get new weight for 0.83873695\n",
            "step 1000, training accuracy: 0.940000 original loss: 4.998063 matching loss: 0.011497\n",
            "step 1000, Validation accuracy: 0.840120\n",
            "get new weight for 0.84011984\n",
            "step 1100, training accuracy: 0.940000 original loss: 4.905830 matching loss: 0.011585\n",
            "step 1100, Validation accuracy: 0.840197\n",
            "get new weight for 0.84019667\n",
            "step 1200, training accuracy: 0.880000 original loss: 5.025381 matching loss: 0.011670\n",
            "step 1200, Validation accuracy: 0.841195\n",
            "get new weight for 0.84119546\n",
            "step 1300, training accuracy: 0.870000 original loss: 5.081019 matching loss: 0.011522\n",
            "step 1300, Validation accuracy: 0.840927\n",
            "step 1400, training accuracy: 0.870000 original loss: 5.164386 matching loss: 0.011763\n",
            "step 1400, Validation accuracy: 0.841656\n",
            "get new weight for 0.84165645\n",
            "step 1500, training accuracy: 0.890000 original loss: 4.954890 matching loss: 0.011676\n",
            "step 1500, Validation accuracy: 0.837815\n",
            "step 1600, training accuracy: 0.920000 original loss: 4.964816 matching loss: 0.012040\n",
            "step 1600, Validation accuracy: 0.841733\n",
            "get new weight for 0.8417333\n",
            "step 1700, training accuracy: 0.830000 original loss: 5.254801 matching loss: 0.012112\n",
            "step 1700, Validation accuracy: 0.836701\n",
            "step 1800, training accuracy: 0.850000 original loss: 5.095084 matching loss: 0.012024\n",
            "step 1800, Validation accuracy: 0.839544\n",
            "step 1900, training accuracy: 0.880000 original loss: 4.992664 matching loss: 0.011919\n",
            "step 1900, Validation accuracy: 0.841272\n",
            "step 1999, training accuracy: 0.870000 original loss: 5.120447 matching loss: 0.012005\n",
            "step 1999, Validation accuracy: 0.837508\n",
            "svhn/svhn_weight.npy\n",
            "get_matching_loss\n",
            "v_train\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x1c1d0000 @  0x7f7f385d91e7 0x7f7f35f22ca1 0x7f7f35f8c9c5 0x7f7f35f8d55e 0x7f7f36026a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "step 0, training accuracy: 0.790000 original loss: 5.514728 matching loss: 0.016499\n",
            "step 0, Validation accuracy: 0.407956\n",
            "step 100, training accuracy: 0.770000 original loss: 5.437430 matching loss: 0.012618\n",
            "step 100, Validation accuracy: 0.390379\n",
            "step 200, training accuracy: 0.840000 original loss: 5.240125 matching loss: 0.012892\n",
            "step 200, Validation accuracy: 0.392599\n",
            "step 300, training accuracy: 0.820000 original loss: 5.331716 matching loss: 0.013026\n",
            "step 300, Validation accuracy: 0.389639\n",
            "step 400, training accuracy: 0.850000 original loss: 5.274131 matching loss: 0.012876\n",
            "step 400, Validation accuracy: 0.409436\n",
            "get new weight for 0.40943572\n",
            "step 500, training accuracy: 0.720000 original loss: 5.404416 matching loss: 0.013068\n",
            "step 500, Validation accuracy: 0.400370\n",
            "step 600, training accuracy: 0.780000 original loss: 5.401529 matching loss: 0.013009\n",
            "step 600, Validation accuracy: 0.402035\n",
            "step 700, training accuracy: 0.850000 original loss: 5.220008 matching loss: 0.013103\n",
            "step 700, Validation accuracy: 0.399260\n",
            "step 800, training accuracy: 0.790000 original loss: 5.321453 matching loss: 0.013480\n",
            "step 800, Validation accuracy: 0.393710\n",
            "step 900, training accuracy: 0.780000 original loss: 5.320352 matching loss: 0.013784\n",
            "step 900, Validation accuracy: 0.407031\n",
            "step 1000, training accuracy: 0.760000 original loss: 5.312305 matching loss: 0.013926\n",
            "step 1000, Validation accuracy: 0.388159\n",
            "step 1100, training accuracy: 0.880000 original loss: 5.178861 matching loss: 0.014395\n",
            "step 1100, Validation accuracy: 0.398520\n",
            "step 1200, training accuracy: 0.780000 original loss: 5.352894 matching loss: 0.014439\n",
            "step 1200, Validation accuracy: 0.399630\n",
            "step 1300, training accuracy: 0.800000 original loss: 5.257141 matching loss: 0.015038\n",
            "step 1300, Validation accuracy: 0.400555\n",
            "step 1400, training accuracy: 0.810000 original loss: 5.312036 matching loss: 0.015111\n",
            "step 1400, Validation accuracy: 0.399815\n",
            "step 1500, training accuracy: 0.800000 original loss: 5.370363 matching loss: 0.015451\n",
            "step 1500, Validation accuracy: 0.401110\n",
            "step 1600, training accuracy: 0.810000 original loss: 5.249510 matching loss: 0.015776\n",
            "step 1600, Validation accuracy: 0.397780\n",
            "step 1700, training accuracy: 0.810000 original loss: 5.274717 matching loss: 0.015818\n",
            "step 1700, Validation accuracy: 0.401665\n",
            "step 1800, training accuracy: 0.810000 original loss: 5.333574 matching loss: 0.016346\n",
            "step 1800, Validation accuracy: 0.401110\n",
            "step 1900, training accuracy: 0.790000 original loss: 5.311821 matching loss: 0.016411\n",
            "step 1900, Validation accuracy: 0.404995\n",
            "step 1999, training accuracy: 0.780000 original loss: 5.282307 matching loss: 0.016540\n",
            "step 1999, Validation accuracy: 0.401665\n",
            "us8k/us8k_weight.npy\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Inference accuracy: 0.967500\n",
            "Inference accuracy: 0.667969\n",
            "Inference accuracy: 0.917815\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x6164000 @  0x7f91cc2ff1e7 0x7f91c9c48ca1 0x7f91c9cb29c5 0x7f91c9cb355e 0x7f91c9d4ca6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.554500\n",
            "Inference accuracy: 0.838814\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x5a38000 @  0x7fdeb0d741e7 0x7fdeae6bdca1 0x7fdeae7279c5 0x7fdeae72855e 0x7fdeae7c1a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.409436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVI6WqCU8hd-"
      },
      "source": [
        "###Inference Accuracy Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv5CEEiu8nYb",
        "outputId": "cfcab4f6-980b-4a17-dbdf-c620905da9c5"
      },
      "source": [
        "!python weight_virtualization.py -mode=e -vnn_name=mnist"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Inference accuracy: 0.967500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgxU3jsg-CBS",
        "outputId": "0e334cee-c0dd-4959-826b-0a10c3262915"
      },
      "source": [
        "!python weight_virtualization.py -mode=e -vnn_name=gsc"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inference accuracy: 0.667969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op-NWNsh-Bz4",
        "outputId": "5bbfd6ef-9167-465f-8ff4-553ec261cca2"
      },
      "source": [
        "!python weight_virtualization.py -mode=e -vnn_name=gtsrb"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inference accuracy: 0.917815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z14HYvDO-BpZ",
        "outputId": "31d81bbb-359b-4343-f64c-32b1f87e7e0d"
      },
      "source": [
        "!python weight_virtualization.py -mode=e -vnn_name=cifar10"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1228800000 bytes == 0x5de4000 @  0x7fb48a68e1e7 0x7fb487fd7ca1 0x7fb4880419c5 0x7fb48804255e 0x7fb4880dba6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "Inference accuracy: 0.554500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8nUhJOy-Bf0",
        "outputId": "b9bc4efc-3b85-43a1-d2f4-a7f6a0c4d002"
      },
      "source": [
        "!python weight_virtualization.py -mode=e -vnn_name=svhn"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inference accuracy: 0.838814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEFmaOc3-BGp",
        "outputId": "10c44f4b-b94e-4b3b-e5da-e368a5cf1b18"
      },
      "source": [
        "!python weight_virtualization.py -mode=e -vnn_name=us8k"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inference accuracy: 0.409436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fhb4qOlb8nru"
      },
      "source": [
        "##5. Multitask execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9NG0aZX84Lx"
      },
      "source": [
        "### In-Memory Execution of Virtualised Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoqhzb-u841P",
        "outputId": "f9e5f60d-01cd-416d-dc28-a0ed1265130e"
      },
      "source": [
        "!python in-memory_execute_6networks.py"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "virtual_weight address: 139771838988288\n",
            "init virtual_weight 7.442 ms\n",
            "[VNN 0][cifar10] init page table 4.759 ms\n",
            "[VNN 1][gsc] init page table 4.112 ms\n",
            "[VNN 2][gtsrb] init page table 3.793 ms\n",
            "[VNN 3][mnist] init page table 3.819 ms\n",
            "[VNN 4][svhn] init page table 3.841 ms\n",
            "[VNN 5][us8k] init page table 3.794 ms\n",
            "tf.global_variables_initializer 1194.832 ms\n",
            "[Executing] gsc\n",
            "weights load time : 0.348 ms\n",
            "DNN execution time: 1770.960 ms\n",
            "Inference accuracy: 0.667969\n",
            "tcmalloc: large alloc 1914986496 bytes == 0x8b67a000 @  0x7f1fd02471e7 0x7f1fcddd0ca1 0x7f1fcde3a9c5 0x7f1fcde3b55e 0x7f1fcded4a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "[Executing] us8k\n",
            "weights load time : 0.316 ms\n",
            "DNN execution time: 652.916 ms\n",
            "Inference accuracy: 0.409436\n",
            "[Executing] us8k\n",
            "weights load time : 0.201 ms\n",
            "DNN execution time: 124.243 ms\n",
            "Inference accuracy: 0.409436\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "[Executing] mnist\n",
            "weights load time : 0.308 ms\n",
            "DNN execution time: 409.361 ms\n",
            "Inference accuracy: 0.967500\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x125a7e000 @  0x7f1fd02471e7 0x7f1fcddd0ca1 0x7f1fcde3a9c5 0x7f1fcde3b55e 0x7f1fcded4a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "[Executing] cifar10\n",
            "weights load time : 0.347 ms\n",
            "DNN execution time: 510.526 ms\n",
            "Inference accuracy: 0.554500\n",
            "[Executing] mnist\n",
            "weights load time : 0.205 ms\n",
            "DNN execution time: 41.193 ms\n",
            "Inference accuracy: 0.967500\n",
            "[Executing] cifar10\n",
            "weights load time : 0.201 ms\n",
            "DNN execution time: 102.529 ms\n",
            "Inference accuracy: 0.554500\n",
            "[Executing] gsc\n",
            "weights load time : 0.303 ms\n",
            "DNN execution time: 46.467 ms\n",
            "Inference accuracy: 0.667969\n",
            "[Executing] gsc\n",
            "weights load time : 0.185 ms\n",
            "DNN execution time: 44.283 ms\n",
            "Inference accuracy: 0.667969\n",
            "[Executing] gsc\n",
            "weights load time : 0.203 ms\n",
            "DNN execution time: 44.737 ms\n",
            "Inference accuracy: 0.667969\n",
            "[Executing] mnist\n",
            "weights load time : 0.256 ms\n",
            "DNN execution time: 38.426 ms\n",
            "Inference accuracy: 0.967500\n",
            "[Executing] cifar10\n",
            "weights load time : 0.201 ms\n",
            "DNN execution time: 101.482 ms\n",
            "Inference accuracy: 0.554500\n",
            "[Executing] gsc\n",
            "weights load time : 0.181 ms\n",
            "DNN execution time: 45.798 ms\n",
            "Inference accuracy: 0.667969\n",
            "[Executing] cifar10\n",
            "weights load time : 0.200 ms\n",
            "DNN execution time: 101.693 ms\n",
            "Inference accuracy: 0.554500\n",
            "[Executing] svhn\n",
            "weights load time : 0.244 ms\n",
            "DNN execution time: 813.224 ms\n",
            "Inference accuracy: 0.838814\n",
            "[Executing] us8k\n",
            "weights load time : 0.221 ms\n",
            "DNN execution time: 165.793 ms\n",
            "Inference accuracy: 0.409436\n",
            "[Executing] mnist\n",
            "weights load time : 0.213 ms\n",
            "DNN execution time: 43.071 ms\n",
            "Inference accuracy: 0.967500\n",
            "[Executing] svhn\n",
            "weights load time : 0.215 ms\n",
            "DNN execution time: 157.014 ms\n",
            "Inference accuracy: 0.838814\n",
            "[Executing] svhn\n",
            "weights load time : 0.208 ms\n",
            "DNN execution time: 152.159 ms\n",
            "Inference accuracy: 0.838814\n",
            "[Executing] cifar10\n",
            "weights load time : 0.225 ms\n",
            "DNN execution time: 112.924 ms\n",
            "Inference accuracy: 0.554500\n",
            "[Executing] gsc\n",
            "weights load time : 0.218 ms\n",
            "DNN execution time: 45.280 ms\n",
            "Inference accuracy: 0.667969\n",
            "[Executing] mnist\n",
            "weights load time : 0.199 ms\n",
            "DNN execution time: 38.259 ms\n",
            "Inference accuracy: 0.967500\n",
            "[Executing] us8k\n",
            "weights load time : 0.200 ms\n",
            "DNN execution time: 126.989 ms\n",
            "Inference accuracy: 0.409436\n",
            "[Executing] mnist\n",
            "weights load time : 0.270 ms\n",
            "DNN execution time: 38.826 ms\n",
            "Inference accuracy: 0.967500\n",
            "[Executing] mnist\n",
            "weights load time : 0.198 ms\n",
            "DNN execution time: 38.578 ms\n",
            "Inference accuracy: 0.967500\n",
            "[Executing] cifar10\n",
            "weights load time : 0.203 ms\n",
            "DNN execution time: 104.694 ms\n",
            "Inference accuracy: 0.554500\n",
            "[Executing] svhn\n",
            "weights load time : 0.204 ms\n",
            "DNN execution time: 152.774 ms\n",
            "Inference accuracy: 0.838814\n",
            "[Executing] cifar10\n",
            "weights load time : 0.211 ms\n",
            "DNN execution time: 108.020 ms\n",
            "Inference accuracy: 0.554500\n",
            "[Executing] mnist\n",
            "weights load time : 0.202 ms\n",
            "DNN execution time: 38.824 ms\n",
            "Inference accuracy: 0.967500\n",
            "[Executing] gtsrb\n",
            "weights load time : 0.250 ms\n",
            "DNN execution time: 585.190 ms\n",
            "Inference accuracy: 0.917815\n",
            "total weights load time : 6.935 ms\n",
            "total DNN execution time: 6756.233 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-dwSnRQ85FF"
      },
      "source": [
        "### Baseline execution of Non-Virtualised Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXq85g9Z5ARv",
        "outputId": "4f412a4b-fecc-49cb-ab8b-887d9427a05a"
      },
      "source": [
        "!python baseline_execute_6networks.py "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Executing] gtsrb\n",
            "weights load time : 81.458 ms\n",
            "DNN execution time: 2300.652 ms\n",
            "Inference accuracy: 0.928029\n",
            "[Executing] gsc\n",
            "weights load time : 54.258 ms\n",
            "DNN execution time: 334.219 ms\n",
            "Inference accuracy: 0.694684\n",
            "[Executing] gsc\n",
            "weights load time : 51.548 ms\n",
            "DNN execution time: 68.493 ms\n",
            "Inference accuracy: 0.694684\n",
            "tcmalloc: large alloc 1914986496 bytes == 0xa358c000 @  0x7fe8f8d6b1e7 0x7fe8f68f4ca1 0x7fe8f695e9c5 0x7fe8f695f55e 0x7fe8f69f8a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "[Executing] us8k\n",
            "weights load time : 75.508 ms\n",
            "DNN execution time: 576.677 ms\n",
            "Inference accuracy: 0.439408\n",
            "[Executing] svhn\n",
            "weights load time : 135.840 ms\n",
            "DNN execution time: 745.806 ms\n",
            "Inference accuracy: 0.814843\n",
            "[Executing] gtsrb\n",
            "weights load time : 57.349 ms\n",
            "DNN execution time: 130.823 ms\n",
            "Inference accuracy: 0.928029\n",
            "[Executing] us8k\n",
            "weights load time : 62.979 ms\n",
            "DNN execution time: 175.273 ms\n",
            "Inference accuracy: 0.439408\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x16c5da000 @  0x7fe8f8d6b1e7 0x7fe8f68f4ca1 0x7fe8f695e9c5 0x7fe8f695f55e 0x7fe8f69f8a6e 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x516069 0x566fae 0x510e51 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "[Executing] cifar10\n",
            "weights load time : 74.564 ms\n",
            "DNN execution time: 400.610 ms\n",
            "Inference accuracy: 0.555200\n",
            "[Executing] gtsrb\n",
            "weights load time : 50.400 ms\n",
            "DNN execution time: 112.908 ms\n",
            "Inference accuracy: 0.928029\n",
            "[Executing] us8k\n",
            "weights load time : 69.606 ms\n",
            "DNN execution time: 158.412 ms\n",
            "Inference accuracy: 0.439408\n",
            "[Executing] us8k\n",
            "weights load time : 65.900 ms\n",
            "DNN execution time: 155.179 ms\n",
            "Inference accuracy: 0.439408\n",
            "[Executing] cifar10\n",
            "weights load time : 67.209 ms\n",
            "DNN execution time: 132.763 ms\n",
            "Inference accuracy: 0.555200\n",
            "[Executing] cifar10\n",
            "weights load time : 67.031 ms\n",
            "DNN execution time: 138.861 ms\n",
            "Inference accuracy: 0.555200\n",
            "[Executing] gtsrb\n",
            "weights load time : 51.667 ms\n",
            "DNN execution time: 109.283 ms\n",
            "Inference accuracy: 0.928029\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "[Executing] mnist\n",
            "weights load time : 71.726 ms\n",
            "DNN execution time: 270.680 ms\n",
            "Inference accuracy: 0.980800\n",
            "[Executing] gtsrb\n",
            "weights load time : 54.219 ms\n",
            "DNN execution time: 112.917 ms\n",
            "Inference accuracy: 0.928029\n",
            "[Executing] mnist\n",
            "weights load time : 66.554 ms\n",
            "DNN execution time: 68.669 ms\n",
            "Inference accuracy: 0.980800\n",
            "[Executing] gtsrb\n",
            "weights load time : 57.037 ms\n",
            "DNN execution time: 112.671 ms\n",
            "Inference accuracy: 0.928029\n",
            "[Executing] svhn\n",
            "weights load time : 129.914 ms\n",
            "DNN execution time: 202.935 ms\n",
            "Inference accuracy: 0.814843\n",
            "[Executing] gtsrb\n",
            "weights load time : 50.973 ms\n",
            "DNN execution time: 109.405 ms\n",
            "Inference accuracy: 0.928029\n",
            "[Executing] us8k\n",
            "weights load time : 71.342 ms\n",
            "DNN execution time: 159.205 ms\n",
            "Inference accuracy: 0.439408\n",
            "[Executing] cifar10\n",
            "weights load time : 77.424 ms\n",
            "DNN execution time: 141.993 ms\n",
            "Inference accuracy: 0.555200\n",
            "[Executing] gsc\n",
            "weights load time : 52.272 ms\n",
            "DNN execution time: 76.535 ms\n",
            "Inference accuracy: 0.694684\n",
            "[Executing] svhn\n",
            "weights load time : 144.790 ms\n",
            "DNN execution time: 210.379 ms\n",
            "Inference accuracy: 0.814843\n",
            "[Executing] svhn\n",
            "weights load time : 134.140 ms\n",
            "DNN execution time: 201.941 ms\n",
            "Inference accuracy: 0.814843\n",
            "[Executing] cifar10\n",
            "weights load time : 69.036 ms\n",
            "DNN execution time: 135.891 ms\n",
            "Inference accuracy: 0.555200\n",
            "[Executing] us8k\n",
            "weights load time : 75.308 ms\n",
            "DNN execution time: 158.559 ms\n",
            "Inference accuracy: 0.439408\n",
            "[Executing] svhn\n",
            "weights load time : 137.981 ms\n",
            "DNN execution time: 204.349 ms\n",
            "Inference accuracy: 0.814843\n",
            "[Executing] gtsrb\n",
            "weights load time : 48.580 ms\n",
            "DNN execution time: 110.517 ms\n",
            "Inference accuracy: 0.928029\n",
            "[Executing] svhn\n",
            "weights load time : 137.178 ms\n",
            "DNN execution time: 204.861 ms\n",
            "Inference accuracy: 0.814843\n",
            "total weights load time : 2343.790 ms\n",
            "total DNN execution time: 8021.468 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwEMlTrS-qDY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}